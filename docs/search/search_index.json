{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Bienvenue Bienvenue sur Hardware & Software ! Ici nous allons apprendre \u00e0 programmer des logiciels ( softwares en anglais), depuis les bases jusqu'au d\u00e9veloppement d'applications complexes. Pour le c\u00f4t\u00e9 ludique, je te proposerai principalement de d\u00e9velopper des jeux. Ils seront tr\u00e8s simples au d\u00e9but puis nous irons ensemble voir comment en cr\u00e9er en 2D et m\u00eame en 3D. Avec cela, je pourrai aussi t'expliquer la partie mat\u00e9rielle ( hardware en anglais) tel que le fonctionnement d'une carte graphique ou d'un processeur.","title":"Accueil"},{"location":"#bienvenue","text":"Bienvenue sur Hardware & Software ! Ici nous allons apprendre \u00e0 programmer des logiciels ( softwares en anglais), depuis les bases jusqu'au d\u00e9veloppement d'applications complexes. Pour le c\u00f4t\u00e9 ludique, je te proposerai principalement de d\u00e9velopper des jeux. Ils seront tr\u00e8s simples au d\u00e9but puis nous irons ensemble voir comment en cr\u00e9er en 2D et m\u00eame en 3D. Avec cela, je pourrai aussi t'expliquer la partie mat\u00e9rielle ( hardware en anglais) tel que le fonctionnement d'une carte graphique ou d'un processeur.","title":"Bienvenue"},{"location":"bases/functions/","text":"","title":"Functions"},{"location":"bases/history/","text":"Des cailloux \u00e0 l'informatique Avant de voir comment programmer un ordinateur, revenons un moment sur la raison pour laquelle et la fa\u00e7on dont les ordinateurs sont apparus. Cela nous aidera pour la suite de cette initiation. Notion de nombres et calculs Dans le r\u00e8gne animal, la num\u00e9rosit\u00e9 semble assez r\u00e9pandue. Chez l'Homme comme chez le chien, un syst\u00e8me cognitif a pu \u00eatre mis en \u00e9vidence lors d'\u00e9tudes (non invasives) sur l'activit\u00e9 c\u00e9r\u00e9brale : le syst\u00e8me de nombres approximatifs . Ce syst\u00e8me permet, pour simplifier, d'estimer \"\u00e0 la louche\" la quantit\u00e9 d'\u00e9l\u00e9ments dans un groupe. Il n'implique aucun symbole pour repr\u00e9senter les nombres. C'est gr\u00e2ce \u00e0 lui qu'un chien pourra choisir la gamelle contenant \"le plus\" de croquettes. Il n'y a donc pas de comptage pr\u00e9cis, juste une estimation sur la quantit\u00e9 et permet une comparaison des quantit\u00e9s entre diff\u00e9rents lots. On pense donc que les premiers Hommes ne savaient pas compter. Au mieux il pouvait avoir une id\u00e9e sur des quantit\u00e9s comme l'unit\u00e9 ou la multitude, voire mesurer grossi\u00e8rement diff\u00e9rents niveaux de multiplicit\u00e9 (\"un seul\", \"quelques uns\", \"beaucoup\"). Cependant, la n\u00e9cessit\u00e9 de compter est apparue avec les besoins. Le mot calcul vient du latin calculus signifiant \"caillou\". Plusieurs origines peuvent expliquer ce lien entre le calcul math\u00e9matique et les cailloux. Une l\u00e9gende veut que le berger pla\u00e7ait un petit caillou dans un pot pour chaque mouton qui sortait de la bergerie. Il retirait les cailloux un \u00e0 un pour chaque mouton qui y rentrait. Il pouvait alors savoir si un ou des moutons n'\u00e9taient pas revenus. De la m\u00eame mani\u00e8re, et avant l'apparition des nombres romains, les soldats romains pouvaient lancer un caillou dans une urne avant de partir au combat puis r\u00e9cup\u00e9rait un caillou du r\u00e9cipient en revenant. Le nombre de cailloux restant servaient \u00e0 compter combien de soldats \u00e9taient tomb\u00e9s lors de l'affrontement. Les premiers calculs se sont donc faits sur des nombres entiers pour d\u00e9nombrer des soldats dans une arm\u00e9e, des animaux dans un troupeau ou pour des transactions financi\u00e8res. Les nombres d\u00e9cimaux appara\u00eetront plus tard dans l'histoire de l'Humanit\u00e9. Le premier outil pour compter et faire des calculs est \u00e9videmment la main . Certaines cultures se sont bas\u00e9es sur les dix doigts de la main, donnant naissance \u00e0 la base 10 que nous utilisons encore de nos jours gr\u00e2ce au syst\u00e8me num\u00e9rique arabe utilis\u00e9 en Occident. D'autres civilisations comme celle des azt\u00e8ques se sont bas\u00e9es sur les doigts des mains et des pieds ce qui leur permettait d'utiliser une base 20. Pour rappel, une base arithm\u00e9tique N d\u00e9finit le nombre de chiffres disponibles allant de 0 \u00e0 N -1. Pour aller au-del\u00e0 de la valeur du plus grand chiffre, il faut ajouter une puissance. Concr\u00e8tement, prenons l'exemple de la base 10 que nous utilisons quotidiennement. Nous avons dix chiffres - dix, comme la base donc - allant de 0 \u00e0 9. Puis, pour passer \u00e0 la valeur apr\u00e8s 9, nous ajoutons une puissance : la dizaine . On passe alors de 9 \u00e0 10, un nombre constitu\u00e9 de deux chiffres. Nous restons \u00e0 deux chiffres jusqu'\u00e0 99 o\u00f9, pour passer \u00e0 la valeur suivante, nous ajoutons encore une puissance : la centaine . Voici le sch\u00e9ma que nous obtenons : 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [...] 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 [...] 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 .... Cependant la main a un d\u00e9faut : elle ne permet pas de conserver le r\u00e9sultat interm\u00e9diaire d'un calcul. Il est donc n\u00e9cessaire de s'en souvenir ce qui n'est pas toujours une mince affaire quand on manipule des nombres mentalement. Les cailloux ou encore les b\u00e2tons de marquage ont bien s\u00fbr \u00e9t\u00e9 un premier moyen de \"stocker\" un r\u00e9sultat comme nous l'avons vu pour les moutons et les soldats, ou aussi pour des marchandises. Cependant, ces moyens ont certaines limitations dont le nombre n\u00e9cessaire pour repr\u00e9senter de grandes valeurs. Par ailleurs, s'il est facile et rapide de compter de petites quantit\u00e9s de cailloux ou d'entailles sur un b\u00e2ton, il devient beaucoup plus difficile de compter un grand nombre d'entre eux. Les premi\u00e8res machines \u00e0 calculer analogiques Avec les calculs sur des nombres plus grands, il est donc devenu n\u00e9cessaire d'inventer des outils d'aide au calcul. Les plus connus sont l' abaque et le boulier (2000 av J.-C.). Plus tard, au premier si\u00e8cle avant J\u00e9sus Christ, la machine d'Anticyth\u00e8re permet de calculer \u00e0 l'avance la date et l'heure des \u00e9clipses solaires et lunaires pour les si\u00e8cles \u00e0 venir. D'autres outils de calcul astronomique ont \u00e9t\u00e9 invent\u00e9s durant les si\u00e8cles suivants comme l' astrolabe grec ou le planisph\u00e8re de Al-B\u012br\u016bn\u012b au XI\u00e8me si\u00e8cle. En 1642, Blaise Pascal pr\u00e9sente sa pascaline , une machine \u00e0 calculer m\u00e9canique num\u00e9rique permettant d'effectuer des additions, soustractions directement, ainsi que des multiplications et divisions par r\u00e9p\u00e9titions. Pascal l'avait con\u00e7ue \u00e0 l'origine pour aider son p\u00e8re, nouvellement surintendant de Haute-Normandie, dans la lourde t\u00e2che de remettre d'aplomb les recettes fiscales de cette province. Malgr\u00e9 la praticit\u00e9 de la machine, son prix \u00e9lev\u00e9 ne lui a pas permis de se d\u00e9mocratiser. La pascaline f\u00fbt donc, h\u00e9las, un \u00e9chec commercial. Bien que Pascal voulait corriger sa premi\u00e8re pascaline en la simplifiant et donc la rendre moins ch\u00e8re, un accident de carrosse l'a totalement d\u00e9tourn\u00e9 de la recherche scientifique. Il a alors abandonn\u00e9 son projet pour se consacrer \u00e0 la philosophie et la religion. Pr\u00e9mices de l'automatisation En 1725, Basile Bouchon programme un m\u00e9tier \u00e0 tisser par la lecture d'un ruban perfor\u00e9 , inspir\u00e9 des bo\u00eetes \u00e0 musiques, pour automatiser la t\u00e2che r\u00e9p\u00e9titive du tissage. C'est la premi\u00e8re fois qu'une machine semi-automatique est utilis\u00e9e \u00e0 des fins industrielles. L'id\u00e9e sera ensuite perfectionn\u00e9e sur plusieurs it\u00e9rations jusqu'au succ\u00e8s mondial du m\u00e9tier \u00e0 tisser de Jacquard . Ada Lovelace et la machine analytique Le m\u00e9tier \u00e0 tisser de Jacquard inspire Charles Babbage . En 1833, celui-ci propose une machine \u00e0 calculer programmable encore m\u00e9canique, la machine analytique . La complexit\u00e9 et les changements de plan \u00e0 r\u00e9p\u00e9tition avortent le projet du calculateur. Cependant, entre 1842 et 1843, Ada Lovelace qui collaborait avec Charles Babbage commen\u00e7ait \u00e0 concevoir des cartes perfor\u00e9es pour cette machine, autrement dit les premiers programmes en langage binaire (pr\u00e9sence ou absence de trou). Ada Lovelace est donc la premi\u00e8re programmeuse de l'Histoire de l'Humanit\u00e9, tous sexes confondus . Plus tard, les avanc\u00e9es sur la connaissance sur l'\u00e9lectricit\u00e9 permettent de remplacer certaines parties m\u00e9caniques des calculateurs. On parle alors d' \u00e9lectrom\u00e9canique . A la fin du XIX\u00e8me si\u00e8cle, le m\u00e9tier \u00e0 tisser de Jacquard est utilis\u00e9 en combinaison avec les cartes perfor\u00e9es par Herman Hellorith, pour effectuer le recensement de la population am\u00e9ricaine. Hellorith fonde la Tabulating Machine Company en 1896, qui fusionnera en 1911 avec Computing Scale Company. Cette fusion donne alors naissance \u00e0 une nouvelle entreprise, la Computing- Tabulating- Recording Co. En 1924 elle est renomm\u00e9e en International Business Machine Corporation , mieux connue sous le sigle IBM . La Seconde Guerre Mondiale et les d\u00e9buts de l'informatique Au d\u00e9but du XX\u00e8me si\u00e8cle, avant la Seconde Guerre Mondiale, les calculateurs analogiques servaient \u00e0 r\u00e9soudre des \u00e9quations diff\u00e9rentielles, notamment gr\u00e2ce \u00e0 leur capacit\u00e9 \u00e0 faire des int\u00e9grations. Les valeurs d'entr\u00e9e \u00e9taient des grandeurs physiques (temp\u00e9rature, tension, etc, par analogie ) et donnaient en retour des valeurs chiffr\u00e9es plus ou moins pr\u00e9cises. Ces calculateurs ont le gros inconv\u00e9nient d'\u00eatre sp\u00e9cifiques \u00e0 un probl\u00e8me donn\u00e9 et doivent alors \u00eatre reprogramm\u00e9s manuellement pour r\u00e9soudre un autre probl\u00e8me. Le num\u00e9rique s'est peu \u00e0 peu impos\u00e9, notamment gr\u00e2ce \u00e0 sa programmabilit\u00e9. A cette \u00e9poque, et jusqu'au milieu du XX\u00e8me si\u00e8cle, les calculateurs et les premiers ordinateurs fonctionnaient \u00e0 l'aide de tubes \u00e0 vide apr\u00e8s l'invention de la triode en 1906. Pour d\u00e9crire bri\u00e8vement le fonctionnement de tels tubes, un corps conducteur servant de cathode (\u00e9lectrode n\u00e9gative) est chauff\u00e9 \u00e0 tr\u00e8s haute temp\u00e9rature. Cela permet aux \u00e9lectrons de s'en d\u00e9tacher. Les \u00e9lectrons sont des particules charg\u00e9es n\u00e9gativement et leur d\u00e9placement g\u00e9n\u00e8re un courant \u00e9lectrique. Les \u00e9lectrons parcourent du vide ou un gaz inerte en sens unique jusqu'\u00e0 rencontrer un autre corps conducteur, l'anode (\u00e9lectrode positive). Ainsi, si on fait suffisamment chauffer la cathode, on peut propager un courant \u00e9lectrique. Ce courant \u00e9lectrique sert ensuite dans un langage binaire : il y a du courant ou il n'y en a pas . Les tubes \u00e0 vide pr\u00e9sentent plusieurs inconv\u00e9nients, d'une part l'importante consommation d'\u00e9nergie mais aussi leur fiabilit\u00e9 m\u00e9diocre. Il n'\u00e9tait pas rare que des tubes grillent occasionnant des pannes sur les machines en fonctionnement. Les tubes \u00e0 vide sont cependant encore utilis\u00e9s comme dans les fours \u00e0 micro-ondes. Ils pr\u00e9sentent aussi l'int\u00e9r\u00eat de ne pas \u00eatre sensibles aux impulsions \u00e9lectromagn\u00e9tiques. La Seconde Guerre Mondiale est un \u00e9v\u00e9nement majeur y compris dans l'histoire de l'informatique. Les communications \u00e9crites \u00e9taient transmises par t\u00e9l\u00e9scripteur en code Baudot , un ancien code plus vieux que l'ASCII. Le code Baudot permettait de repr\u00e9senter chaque carat\u00e8re (lettre, chiffre, ponctuation) sur 5 bits. Le bit ne pouvant prendre que deux valeurs, 0 ou 1, le code Baudot n'offrait que 32 combinaisons diff\u00e9rentes et donc pas assez pour repr\u00e9senter les 26 lettres de l'alphabet, les 10 chiffres et d'autres caract\u00e8res comme les sauts de ligne. Deux codes binaires \u00e9taient alors d\u00e9di\u00e9s au passage du mode \"alphabet\" au mode \"chiffre\". Les codes suivants \u00e9taient alors interpr\u00e9t\u00e9s soit comme une lettre, soit comme un chiffre, soit comme un caract\u00e8re sp\u00e9cial suivant le mode utilis\u00e9. Cependant, en temps de guerre, les communications \u00e9crites n'\u00e9taient pas transmises en clair. Autrement dit, pour \u00e9viter que l'ennemi ne puisse lire les communications, elles \u00e9taient chiffr\u00e9es et, th\u00e9oriquement , seul le destinataire de la communication pouvait les d\u00e9chiffrer. Un chiffrement connu, bien que tr\u00e8s basique, est celui qu'utilisait Jules C\u00e9sar qui d\u00e9calait les lettres dans l'alphabet. Depuis, la cryptographie s'est consid\u00e9rablement am\u00e9lior\u00e9e pour \u00e9viter que les chiffrements ne soient cass\u00e9s trop facilement. Durant la Seconde Guerre Mondiale, les t\u00e9l\u00e9scripteurs envoyaient donc des messages chiffr\u00e9s. On peut par exemple \u00e9voquer les machines de Lorenz utilis\u00e9es par l'Allemagne nazie pour chiffrer ses communications. Le Colossus \u00e9tait un ordinateur num\u00e9rique construit tr\u00e8s secr\u00e8tement entre 1942 et 1943 \u00e0 Londres, et servait \u00e0 la cryptanalyse du code Lorenz pour pouvoir d\u00e9chiffrer les communications allemandes. Le Colossus n'\u00e9tait pas le seul ordinateur, num\u00e9rique ou \u00e9lectrom\u00e9canique, \u00e0 avoir \u00e9t\u00e9 d\u00e9velopp\u00e9 durant le conflit. L'un de ces ordinateurs qui est encore tr\u00e8s c\u00e9l\u00e8bre n'est autre que l' ENIAC , pour Electronic Numerical Integrator And Computer . Il est d\u00e9velopp\u00e9 pour le calcul balistique dans un premier temps puis sert aux probl\u00e8mes de physique nucl\u00e9aire et de m\u00e9t\u00e9orologie. Il s'agit d'une \u00e9norme machine pesant 30 tonnes et occupant une salle enti\u00e8re avec une consommation estim\u00e9e \u00e0 environ 150kW ou plus. L'ENIAC est une machine qu'on programme par c\u00e2blage. Cela fait que le calculateur ne travaille pas durant de longs moments, le temps qu'il soit programm\u00e9. Le math\u00e9maticien John von Neumann comprend qu'il s'agit l\u00e0 d'un frein important pour exploiter tout le potentiel de la machine. En 1946, il publie un rapport qui d\u00e9crit l' architecture dite de von Neumann , le mod\u00e8le de ce qu'on appelle un ordinateur . Cette architecture comprend plusieurs \u00e9l\u00e9ments : Une unit\u00e9 arithm\u00e9tique et logique , aussi appell\u00e9e ALU en anglais, pour effectuer des op\u00e9rations de base (addition, soustraction, multiplication, division et des op\u00e9rations binaires) ; Une unit\u00e9 de contr\u00f4le qui sert \u00e0 donner la succession des instructions \u00e0 l'ALU ; De la m\u00e9moire interne pour y stocker le programme, c'est-\u00e0-dire l'ensemble des instructions, et les donn\u00e9es. Cette m\u00e9moire est le coeur m\u00eame de l'id\u00e9e de von Neumann pour am\u00e9liorer les performances de la machine ; Et des dispositifs d'entr\u00e9e et de sortie qui permettent \u00e0 la machine d'interagir avec l'\u00eatre humain. En 1948, l'ENIAC sera am\u00e9lior\u00e9 avec une m\u00e9moire en lecture seule pour stocker le programme et les informations. De fait, il devient Turing-complet , d'apr\u00e8s l'id\u00e9e de la machine universelle du math\u00e9maticien et cryptologue Alan Turing . Qu'est-ce que la m\u00e9moire informatique ? Le rapport de John von Neumann constitue \u00e0 la fois un v\u00e9ritable bon en avant pour l'informatique mais ouvre en contrepartie la question de savoir ce qu'est la m\u00e9moire d'une machine. Plusieurs id\u00e9es ont \u00e9merg\u00e9 pour concevoir une m\u00e9moire vive , comme des lignes de d\u00e9lai au mercure. Parmi les d\u00e9fauts de cette m\u00e9moire, elle ne permettait pas un acc\u00e8s al\u00e9atoire aux donn\u00e9es. Le but d'une m\u00e9moire \u00e0 acc\u00e8s al\u00e9atoire ( Random Access Memory ou RAM en anglais) est de pouvoir acc\u00e9der directement \u00e0 une information quelque soit son emplacement . Une m\u00e9moire s\u00e9quentielle comme une bande magn\u00e9tique n\u00e9cessite de parcourir toute la m\u00e9moire jusqu'\u00e0 l'emplacement voulu, et donc fait perdre \u00e9norm\u00e9ment de temps. Un exemple assez parlant est celui de la K7 audio qui n\u00e9cessite de faire d\u00e9filer la bande jusqu'au d\u00e9but d'une chanson. Au contraire, un CD permet un acc\u00e8s direct au d\u00e9but d'une chanson. Le premier prototype d'ordinateur bas\u00e9 sur l'architecture de von Neumann voit le jour en 1948. C'est le Small-Scale Experimental Machine (SSEM), construit \u00e0 l'universit\u00e9 Victoria de Manchester. La m\u00e9moire vive emploie un tube de Williams, un tube cathodique stockant chaque bit sous la forme de point (0) ou de trait (1). Le SSEM n'a pas de r\u00e9elle utilit\u00e9 calculatoire, il se limite \u00e0 des op\u00e9rations math\u00e9matiques sans grande importance mais suffisamment longues pour effectuer l'exp\u00e9rimentation. Le but de cette machine est de v\u00e9rifier le bon fonctionnement d'un ordinateur tel que d\u00e9crit par von Neumann. Le SSEM montre bien la faisabilit\u00e9 du concept de von Neumann, ce qui ouvre la voie \u00e0 la construction de plusieurs gros ordinateurs au d\u00e9but des ann\u00e9es 1950 \u00e0 travers le monde. L'av\u00e8nement des ordinateurs Les calculateurs analogiques et les ordinateurs coexisteront durant quelques d\u00e9cennies. En effet, les ordinateurs sont encore tr\u00e8s chers et leur fonctionnement num\u00e9rique, diff\u00e9rent, n'est pas adapt\u00e9 \u00e0 tous les probl\u00e8mes rencontr\u00e9s. Cependant, les grands calculateurs analogiques tomberont en d\u00e9su\u00e9tude autour des ann\u00e9es 80. Toutefois, un regain d'int\u00e9r\u00eat pour certains calculs s'op\u00e8re avec des calculateurs analogiques/num\u00e9riques. Les premiers ordinateurs sont d\u00e9velopp\u00e9s dans des laboratoires universitaires mais tr\u00e8s vite, l'industrie s'y int\u00e9resse. Par exemple, IBM produit l'IBM 701 de 1952 \u00e0 1954 pour le calcul scientifique et l'IBM 702 en 1953, moins performant, \u00e0 usage commercial. Ce dernier utilise un stockage sous forme de d\u00e9rouleur de bandes magn\u00e9tiques pour concurrencer l'UNIVAC I. En 1953 toujours, IBM lance l'IBM 650 avec une m\u00e9moire de masse magn\u00e9tique \u00e0 tambour, une technologie concurrente aux disques durs magn\u00e9tiques. Un tournant important dans l'histoire des ordinateurs s'effectue \u00e0 la fin des ann\u00e9es 50. En effet, la premi\u00e8re g\u00e9n\u00e9ration d'ordinateurs, comme les calculateurs analogiques, utilisent des tubes \u00e0 vide pour les unit\u00e9s de calcul. Ces tubes sont encombrants, consomment \u00e9norm\u00e9ment d'\u00e9nergie mais sont aussi tr\u00e8s peu fiables provoquant d'innombrables pannes. Le transistor est invent\u00e9 en 1947 par John Bardeen, William Shockley et Walter Brattain alors qu'ils voulaient amplifier les communications t\u00e9l\u00e9phoniques longue distance en rempla\u00e7ant les tubes \u00e0 vide trop fragiles. Le transistor est un dispositif semi-conducteur, c'est-\u00e0-dire qu'on peut contr\u00f4ler s'il laisse passer ou non les \u00e9lectrons. Le transistor peut ainsi \u00eatre vu comme un interrupteur \u00e9lectronique. Quelques ann\u00e9es apr\u00e8s sa d\u00e9couverte, le transistor est utilis\u00e9 commercialement avec les premiers postes dits \u00e0 transistors. C'est encore un peu apr\u00e8s qu'il vient remplacer le tube \u00e0 vide dans les ordinateurs, leur permettant notamment de consommer moins, d'\u00eatre plus fiables et plus compacts. En 1954, Bell Labs produit le TRADIC, le tout premier ordinateur \u00e0 transistors qui en contenait 700. En 1958, Jack Kilby, nouvellement employ\u00e9 chez Texas Instruments, invente le circuit int\u00e9gr\u00e9 permettant la miniaturisation et faisant rentrer l'informatique dans l'\u00e8re moderne. Il recevra d'ailleurs le prix Nobel de physique en 2000 pour cette invention. Kilby a commenc\u00e9 par prototyper un tel circuit en reliant \u00e0 la main les transistors avant que l'id\u00e9e soit industrialis\u00e9e. Elle donnera les bo\u00eetiers contenant des centaines de transistors, enfermant en son sein tout ce qui permet de r\u00e9aliser des calculs et de la m\u00e9moire, et accessibles par des \u00e9l\u00e9ments d'entr\u00e9es et sorties \u00e0 l'aide de pattes en p\u00e9riph\u00e9rie. La premi\u00e8re utilisation des ordinateurs bas\u00e9s sur des circuits int\u00e9gr\u00e9s, l\u00e9gers et fiables, est faite avec le programme de missiles ballistiques Minuteman II, puis le c\u00e9l\u00e8bre programme de missions Apollo pour la conqu\u00eate de la Lune. Les programmes militaires et spatiaux sont parmi ceux, si ce ne sont ceux, qui font le plus avancer la science et la technologie. Bien qu'il soit difficile de d\u00e9partager lesquelles ont le plus d\u00e9mocratiser l'informatique entre les missions ballistiques et spatiales, elles y ont toutes contribu\u00e9. La conception de fus\u00e9e par exemple n\u00e9cessite une perfection absolue dans l'usinage des pi\u00e8ces en m\u00e9tallurgie, ce qui aidera \u00e0 la pr\u00e9cision lors de la fabrication de composants \u00e9lectroniques. De meme les instruments de mesure doivent \u00eatre extr\u00eamement fiables et pr\u00e9cis. La gestion de projet s'est aussi consid\u00e9rablement d\u00e9velopp\u00e9e et am\u00e9lior\u00e9e pour devenir ce qu'elle est aujourd'hui dans tous les domaines. Le programme Apollo a par ailleurs permis l'essor de l'informatique et l'a scind\u00e9 en deux p\u00f4les : le mat\u00e9riel ( hardware en anglais) et le logiciel ( software en anglais). Outre la fiabilit\u00e9 du mat\u00e9riel, la politique de test des logiciels s'est aussi d\u00e9velopp\u00e9e pour \u00e9viter les d\u00e9faillances des programmes. Le circuit int\u00e9gr\u00e9 a permis de miniaturiser les \u00e9l\u00e9ments d'un ordinateur. Cependant, les diff\u00e9rents composants sont des entit\u00e9s s\u00e9par\u00e9es occasionnant des lenteurs et des probl\u00e8mes li\u00e9s \u00e0 la fiabilit\u00e9 dans la connexion entre ces composants. C'est en 1971 que ces probl\u00e8mes sont corrig\u00e9s car sort le tout premier microprocesseur, le Intel 4004, un processeur 4 bits. En ne mesurant pas plus de 11mm\u00b2, il a une puissance de calcul \u00e9quivalente \u00e0 celle de l'ENIAC . Il est suivi l'ann\u00e9e suivant du 8008 qui peut traiter jusqu'\u00e0 8 bits simultan\u00e9ment. Le processeur mythique d'Intel sortira en 1974, le Intel 8080 lui aussi en 8 bits. Il aura de nombreux concurrents comme le Zilog Z80 qui \u00e9tait d'ailleurs compatible avec le processeur d'Intel, ou encore le Motorola 6800. L'Intel 8080 a \u00e9t\u00e9 am\u00e9lior\u00e9 les ann\u00e9es suivantes donnant par exemple le 8085. Les premiers ordinateurs personnels grand public sortent en 1977. Il s'agit de : l'Apple II avec un processeur MOS Technology 6502 8 bit (1 MHz) et 4 ko de RAM (jusqu'\u00e0 64 ko), le TRS-80 (Tandy RadioShack) \u00e9quip\u00e9 d'un Zilog Z80 (1.77 MHz) et 4 ko de RAM. et le Commodore PET 2001 dot\u00e9 d'un MOS Technology 6502 8 bit (1 MHz) et 4 ou 8 ko de RAM, vendu pour l'\u00e9quivalent de 3555 dollars en 2021. Il n'est \u00e9videmment pas possible de parler de l'enti\u00e8ret\u00e9 des microprocesseurs ayant exist\u00e9 et de leurs sp\u00e9cificit\u00e9s. La suite de cet historique se concentre essentiellement sur ceux des marques qui sont les plus connues \u00e0 l'heure actuelle. Le Intel 8086 sorti en 1978 est le premier processeur 16 bits et sera aussi le tout premier processeur de la famille x86 , la plus r\u00e9pandue de nos jours pour les ordinateurs personnels, serveurs et stations de travail. Pour son 80286, Intel a d\u00fb demander \u00e0 une autre entreprise de produire des clones de ses processeurs car IBM exigeait de ses clients deux sources d'approvionnement. C'est ainsi qu' AMD a commenc\u00e9 \u00e0 produire l'Am286 en 1982, bien que totalement con\u00e7u par Intel. AMD continuera de produire des processeurs pour Intel pendant quelques ann\u00e9es. Le Intel 80386 publi\u00e9 en 1986 est le premier microprocesseur 32 bits et impl\u00e9mente l'architecture IA-32 (Intel Architecture 32 bits) qu'on retrouve partout de nos jours. Intel assure la r\u00e9trocompatibilit\u00e9 des nouveaux processeurs avec les anciens afin que les programmes d\u00e9j\u00e0 \u00e9crits puissent continuer \u00e0 fonctionner. A noter qu'\u00e0 cette \u00e9poque encore, pour des raisons techniques et de co\u00fbt, les microprocesseurs n'int\u00e8grent pas d'unit\u00e9 de calcul en virgule flottante ( floating point unit ou FPU en anglais), c'est-\u00e0-dire pour r\u00e9aliser des op\u00e9rations sur des nombres \u00e0 virgule. Ils doivent donc \u00eatre coupl\u00e9s \u00e0 des coprocesseurs d\u00e9di\u00e9s \u00e0 de tels calculs pour y parvenir. Il faudra attendre le 80486 d'Intel sorti en 1989 pour voir le premier microprocesseur int\u00e9grant - en option - une FPU. En 1993 sortent les Intel Pentium. Ils int\u00e8grent comme nouveaut\u00e9 un jeu d' instructions vectorielles appel\u00e9 MMX permettant de traiter plusieurs donn\u00e9es simultan\u00e9ment en une seule instruction. Cela accro\u00eet les performances des processeurs sur les applications multim\u00e9dia. Intel r\u00e9utilisera sur plusieurs ann\u00e9es la marque Pentium pour ses processeurs grand public ainsi que leur jumeaux d\u00e9di\u00e9s aux professionnels sous la marque Xeon. En 1995, AMD introduit son premier processeur x86 ind\u00e9pendemment d'Intel , l'AMD-K5. La concurrence entre Intel et AMD a donc commenc\u00e9. L'argument de vente en ce temps \u00e9tait la fr\u00e9quence. Les premiers processeurs \u00e0 passer le cap symbolique du GHz sont l'Athlon (AMD) et le Pentium III (Intel). Avec son Xeon Northwood, Intel introduit l' hyper-threading qui duplique certains \u00e9l\u00e9ments du c\u0153ur du processeur comme les registres. Cette technologie permet d'am\u00e9liorer en th\u00e9orie les performances d'applications dites multithread\u00e9es, \u00e9xecutant plusieurs instructions en parall\u00e8le. Les Pentium 4 h\u00e9riteront de l'hyper-threading mais leur microarchitecture con\u00e7ue pour la course \u00e0 la fr\u00e9quence entra\u00eene une consommation et une dissipation de chaleur tr\u00e8s importantes. La course \u00e0 la fr\u00e9quence a donc atteint ses limites... Intel et AMD changent leur fusil d'\u00e9paule pour partir \u00e0 la conqu\u00eate du nombre de c\u0153urs. Alors que l'AMD Athlon 64 sorti en 2003 est le tout premier processeur 64 bits (tout en \u00e9tant compatible avec les programmes 32 bits), l'AMD Athlon X2 et le Pentium Extreme Edition sont, eux, les premiers mod\u00e8les dot\u00e9s de deux c\u0153urs en 2005. Ce dernier est compl\u00e9t\u00e9 par de l'hyper-threading donnant un total de deux c\u0153urs physiques et quatres processeurs logiques. Les performances des processeur multic\u0153urs font un bon en avant alors que leur fr\u00e9quence est plus faible. Les ann\u00e9es qui suivent jusqu'\u00e0 nos jours voient le nombre de c\u0153urs toujours plus grand chez Intel et AMD. Au fil du temps, la finesse de gravure s'est consid\u00e9rablement r\u00e9duite. Elle correspond \u00e0 la taille des transistors composant les microprocesseurs. Plus ces transistors sont petits, plus il est possible d'en avoir dans un processeur. Le Intel 4004 \u00e9tait grav\u00e9 avec une finesse de 10\u00b5m (soit 10000nm) et \u00e9tait compos\u00e9 de 2300 transistors. Trente ans plus tard, en 2001, le Pentium III Tualatin avait une finesse de gravure de 130nm et poss\u00e9dait 45 millions de transistors. Le marketing a \u00e9norm\u00e9ment pris le relai sur la taille r\u00e9elle des transistors. Les chiffres annonc\u00e9s de 5nm pour les processeurs les plus r\u00e9cents ne refl\u00e8tent plus la r\u00e9alit\u00e9 gr\u00e2ce \u00e0 des astuces ing\u00e9nieuses comme des transistors en 3D. En marge des deux leaders sur les microarchitectures IA-32 puis AMD64/IA-64, une autre soci\u00e9t\u00e9 d\u00e9veloppe des architectures de processeurs 32 et 64 bits. Il s'agit de ARM, dont il n'est pas possible d'acheter un microprocesseur seul : ils sont int\u00e9gr\u00e9s dans des syst\u00e8mes sur puce ( system on a chip ou SoC en anglais). On retrouve les SoC ARM dans de nombreux produits, en particulier mobiles (t\u00e9l\u00e9phones et smartphones, ordinateurs et consoles portables, tablettes, etc), car les architectures arm sont simples et optimisent la consommation \u00e9lectrique. Cependant, on retrouve \u00e9galement des supercalculateurs \u00e9quip\u00e9s de SoC con\u00e7us par ARM, comme le supercalculateur japonais Fugaku. En 2020, Apple annonce le M1, une puce ARM 64 bits qui \u00e9quipe ses nouveaux produits tels que les tablettes, ordinateurs mobiles et de bureau. En 2021, Apple lance les puces M1 Pro et M1 Max encore plus puissantes et le M2 sort en 2022 pla\u00e7ant la barre toujours plus haute. Il existe \u00e9galement des microcontr\u00f4leurs, ou MCU pour microcontroller unit en anglais, qu'on retrouve dans \u00e9norm\u00e9ment d'appareils \u00e9lectroniques dans des syst\u00e8mes embarqu\u00e9s. Les MCU sont \u00e9galement des circuits int\u00e9gr\u00e9s rassemblant un processeur, de la m\u00e9moire (vive et morte), des entr\u00e9es et sorties, etc. Souvent d\u00e9di\u00e9s \u00e0 des t\u00e2ches sp\u00e9cifiques, ils sont tr\u00e8s peu chers car leurs capacit\u00e9s en calculs sont limit\u00e9es ; ils consomment peu avec une fr\u00e9quence faible et leurs sp\u00e9cificit\u00e9s limit\u00e9es font qu'ils ne sont pas aussi polyvalents que les microprocesseurs des ordinateurs personnels. Maintenant que cet historique nous a conduit jusqu'\u00e0 quelques technologies de nos processeurs modernes, je te propose de voir comment ces derniers fonctionnent. Sources https://hmn.wiki/fr/Approximate_number_system https://www.numerama.com/sciences/594706-les-nombres-activent-la-meme-zone-du-cerveau-chez-votre-chien-que-chez-vous.html https://www.larousse.fr/dictionnaires/francais/informatique/42996 https://www.franceculture.fr/emissions/la-methode-scientifique/quand-lhumanite-t-elle-appris-compter http://revue.sesamath.net/spip.php?article891 https://www.youtube.com/watch?v=gLzHlA33rqw https://journals.openedition.org/bibnum/548 https://www.historyofinformation.com/detail.php?id=4727 https://www.youtube.com/watch?v=-2604CHuIyk http://claude-gimenes.fr/electronique/semi-conducteurs/-vii-tube-a-vide-electronique-ancetre-du-transistor-amplificateur https://www.futura-sciences.com/tech/actualites/technologie-tubes-vide-futur-nanoelectronique-40058/ https://aconit.inria.fr/omeka/exhibits/show/histoire-machines.1.html https://www.ibm.com/ibm/history/history/history_intro.html https://www.youtube.com/watch?v=dcN9QXxmRqk https://www.techno-science.net/definition/2400.html http://www.numdam.org/article/ASCFM_1962__8_2_131_0.pdf https://gallica.bnf.fr/ark:/12148/bpt6k24678x/f535.item ( Les merveilles de la science, ou Description populaire des inventions modernes. 5-6, Suppl\u00e9ments. 5 par Louis Figuier, Chapitre IV - LE T\u00c9L\u00c9GRAPHE BAUDOT, A TRANSMISSION MULTIPLE. ark:/12148/bpt6k24678x) https://www.futura-sciences.com/sciences/questions-reponses/mathematiques-quest-ce-chiffrement-cesar-8032/ https://www.britannica.com/technology/ENIAC https://www.universalis.fr/encyclopedie/e-n-i-a-c/ https://www.histoire-informatique.org/grandes_dates/2_3.html https://www.futura-sciences.com/sciences/personnalites/matiere-john-von-neumann-256/ https://history-computer.com/ssem-complete-history-of-the-small-scale-experimental-machine/ https://info.blaisepascal.fr/transistor https://www.cairn.info/revue-le-temps-des-medias-2004-2-page-118.htm https://www.digikey.fr/fr/articles/transistor-basics https://couleur-science.eu/?d=775902--cest-quoi-un-transistor-comment-ca-marche https://www.irif.fr/~carton/Enseignement/Architecture/Cours/Historic/tradic.html https://www.lmd.jussieu.fr/~hourdin/COURS/FORTRAN/Fortran/ https://www.webtimemedias.com/article/le-deces-de-jack-kilby-inventeur-du-circuit-integre","title":"Historique"},{"location":"bases/history/#des-cailloux-a-linformatique","text":"Avant de voir comment programmer un ordinateur, revenons un moment sur la raison pour laquelle et la fa\u00e7on dont les ordinateurs sont apparus. Cela nous aidera pour la suite de cette initiation.","title":"Des cailloux \u00e0 l'informatique"},{"location":"bases/history/#notion-de-nombres-et-calculs","text":"Dans le r\u00e8gne animal, la num\u00e9rosit\u00e9 semble assez r\u00e9pandue. Chez l'Homme comme chez le chien, un syst\u00e8me cognitif a pu \u00eatre mis en \u00e9vidence lors d'\u00e9tudes (non invasives) sur l'activit\u00e9 c\u00e9r\u00e9brale : le syst\u00e8me de nombres approximatifs . Ce syst\u00e8me permet, pour simplifier, d'estimer \"\u00e0 la louche\" la quantit\u00e9 d'\u00e9l\u00e9ments dans un groupe. Il n'implique aucun symbole pour repr\u00e9senter les nombres. C'est gr\u00e2ce \u00e0 lui qu'un chien pourra choisir la gamelle contenant \"le plus\" de croquettes. Il n'y a donc pas de comptage pr\u00e9cis, juste une estimation sur la quantit\u00e9 et permet une comparaison des quantit\u00e9s entre diff\u00e9rents lots. On pense donc que les premiers Hommes ne savaient pas compter. Au mieux il pouvait avoir une id\u00e9e sur des quantit\u00e9s comme l'unit\u00e9 ou la multitude, voire mesurer grossi\u00e8rement diff\u00e9rents niveaux de multiplicit\u00e9 (\"un seul\", \"quelques uns\", \"beaucoup\"). Cependant, la n\u00e9cessit\u00e9 de compter est apparue avec les besoins. Le mot calcul vient du latin calculus signifiant \"caillou\". Plusieurs origines peuvent expliquer ce lien entre le calcul math\u00e9matique et les cailloux. Une l\u00e9gende veut que le berger pla\u00e7ait un petit caillou dans un pot pour chaque mouton qui sortait de la bergerie. Il retirait les cailloux un \u00e0 un pour chaque mouton qui y rentrait. Il pouvait alors savoir si un ou des moutons n'\u00e9taient pas revenus. De la m\u00eame mani\u00e8re, et avant l'apparition des nombres romains, les soldats romains pouvaient lancer un caillou dans une urne avant de partir au combat puis r\u00e9cup\u00e9rait un caillou du r\u00e9cipient en revenant. Le nombre de cailloux restant servaient \u00e0 compter combien de soldats \u00e9taient tomb\u00e9s lors de l'affrontement. Les premiers calculs se sont donc faits sur des nombres entiers pour d\u00e9nombrer des soldats dans une arm\u00e9e, des animaux dans un troupeau ou pour des transactions financi\u00e8res. Les nombres d\u00e9cimaux appara\u00eetront plus tard dans l'histoire de l'Humanit\u00e9. Le premier outil pour compter et faire des calculs est \u00e9videmment la main . Certaines cultures se sont bas\u00e9es sur les dix doigts de la main, donnant naissance \u00e0 la base 10 que nous utilisons encore de nos jours gr\u00e2ce au syst\u00e8me num\u00e9rique arabe utilis\u00e9 en Occident. D'autres civilisations comme celle des azt\u00e8ques se sont bas\u00e9es sur les doigts des mains et des pieds ce qui leur permettait d'utiliser une base 20. Pour rappel, une base arithm\u00e9tique N d\u00e9finit le nombre de chiffres disponibles allant de 0 \u00e0 N -1. Pour aller au-del\u00e0 de la valeur du plus grand chiffre, il faut ajouter une puissance. Concr\u00e8tement, prenons l'exemple de la base 10 que nous utilisons quotidiennement. Nous avons dix chiffres - dix, comme la base donc - allant de 0 \u00e0 9. Puis, pour passer \u00e0 la valeur apr\u00e8s 9, nous ajoutons une puissance : la dizaine . On passe alors de 9 \u00e0 10, un nombre constitu\u00e9 de deux chiffres. Nous restons \u00e0 deux chiffres jusqu'\u00e0 99 o\u00f9, pour passer \u00e0 la valeur suivante, nous ajoutons encore une puissance : la centaine . Voici le sch\u00e9ma que nous obtenons : 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [...] 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 [...] 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 .... Cependant la main a un d\u00e9faut : elle ne permet pas de conserver le r\u00e9sultat interm\u00e9diaire d'un calcul. Il est donc n\u00e9cessaire de s'en souvenir ce qui n'est pas toujours une mince affaire quand on manipule des nombres mentalement. Les cailloux ou encore les b\u00e2tons de marquage ont bien s\u00fbr \u00e9t\u00e9 un premier moyen de \"stocker\" un r\u00e9sultat comme nous l'avons vu pour les moutons et les soldats, ou aussi pour des marchandises. Cependant, ces moyens ont certaines limitations dont le nombre n\u00e9cessaire pour repr\u00e9senter de grandes valeurs. Par ailleurs, s'il est facile et rapide de compter de petites quantit\u00e9s de cailloux ou d'entailles sur un b\u00e2ton, il devient beaucoup plus difficile de compter un grand nombre d'entre eux.","title":"Notion de nombres et calculs"},{"location":"bases/history/#les-premieres-machines-a-calculer-analogiques","text":"Avec les calculs sur des nombres plus grands, il est donc devenu n\u00e9cessaire d'inventer des outils d'aide au calcul. Les plus connus sont l' abaque et le boulier (2000 av J.-C.). Plus tard, au premier si\u00e8cle avant J\u00e9sus Christ, la machine d'Anticyth\u00e8re permet de calculer \u00e0 l'avance la date et l'heure des \u00e9clipses solaires et lunaires pour les si\u00e8cles \u00e0 venir. D'autres outils de calcul astronomique ont \u00e9t\u00e9 invent\u00e9s durant les si\u00e8cles suivants comme l' astrolabe grec ou le planisph\u00e8re de Al-B\u012br\u016bn\u012b au XI\u00e8me si\u00e8cle. En 1642, Blaise Pascal pr\u00e9sente sa pascaline , une machine \u00e0 calculer m\u00e9canique num\u00e9rique permettant d'effectuer des additions, soustractions directement, ainsi que des multiplications et divisions par r\u00e9p\u00e9titions. Pascal l'avait con\u00e7ue \u00e0 l'origine pour aider son p\u00e8re, nouvellement surintendant de Haute-Normandie, dans la lourde t\u00e2che de remettre d'aplomb les recettes fiscales de cette province. Malgr\u00e9 la praticit\u00e9 de la machine, son prix \u00e9lev\u00e9 ne lui a pas permis de se d\u00e9mocratiser. La pascaline f\u00fbt donc, h\u00e9las, un \u00e9chec commercial. Bien que Pascal voulait corriger sa premi\u00e8re pascaline en la simplifiant et donc la rendre moins ch\u00e8re, un accident de carrosse l'a totalement d\u00e9tourn\u00e9 de la recherche scientifique. Il a alors abandonn\u00e9 son projet pour se consacrer \u00e0 la philosophie et la religion.","title":"Les premi\u00e8res machines \u00e0 calculer analogiques"},{"location":"bases/history/#premices-de-lautomatisation","text":"En 1725, Basile Bouchon programme un m\u00e9tier \u00e0 tisser par la lecture d'un ruban perfor\u00e9 , inspir\u00e9 des bo\u00eetes \u00e0 musiques, pour automatiser la t\u00e2che r\u00e9p\u00e9titive du tissage. C'est la premi\u00e8re fois qu'une machine semi-automatique est utilis\u00e9e \u00e0 des fins industrielles. L'id\u00e9e sera ensuite perfectionn\u00e9e sur plusieurs it\u00e9rations jusqu'au succ\u00e8s mondial du m\u00e9tier \u00e0 tisser de Jacquard .","title":"Pr\u00e9mices de l'automatisation"},{"location":"bases/history/#ada-lovelace-et-la-machine-analytique","text":"Le m\u00e9tier \u00e0 tisser de Jacquard inspire Charles Babbage . En 1833, celui-ci propose une machine \u00e0 calculer programmable encore m\u00e9canique, la machine analytique . La complexit\u00e9 et les changements de plan \u00e0 r\u00e9p\u00e9tition avortent le projet du calculateur. Cependant, entre 1842 et 1843, Ada Lovelace qui collaborait avec Charles Babbage commen\u00e7ait \u00e0 concevoir des cartes perfor\u00e9es pour cette machine, autrement dit les premiers programmes en langage binaire (pr\u00e9sence ou absence de trou). Ada Lovelace est donc la premi\u00e8re programmeuse de l'Histoire de l'Humanit\u00e9, tous sexes confondus . Plus tard, les avanc\u00e9es sur la connaissance sur l'\u00e9lectricit\u00e9 permettent de remplacer certaines parties m\u00e9caniques des calculateurs. On parle alors d' \u00e9lectrom\u00e9canique . A la fin du XIX\u00e8me si\u00e8cle, le m\u00e9tier \u00e0 tisser de Jacquard est utilis\u00e9 en combinaison avec les cartes perfor\u00e9es par Herman Hellorith, pour effectuer le recensement de la population am\u00e9ricaine. Hellorith fonde la Tabulating Machine Company en 1896, qui fusionnera en 1911 avec Computing Scale Company. Cette fusion donne alors naissance \u00e0 une nouvelle entreprise, la Computing- Tabulating- Recording Co. En 1924 elle est renomm\u00e9e en International Business Machine Corporation , mieux connue sous le sigle IBM .","title":"Ada Lovelace et la machine analytique"},{"location":"bases/history/#la-seconde-guerre-mondiale-et-les-debuts-de-linformatique","text":"Au d\u00e9but du XX\u00e8me si\u00e8cle, avant la Seconde Guerre Mondiale, les calculateurs analogiques servaient \u00e0 r\u00e9soudre des \u00e9quations diff\u00e9rentielles, notamment gr\u00e2ce \u00e0 leur capacit\u00e9 \u00e0 faire des int\u00e9grations. Les valeurs d'entr\u00e9e \u00e9taient des grandeurs physiques (temp\u00e9rature, tension, etc, par analogie ) et donnaient en retour des valeurs chiffr\u00e9es plus ou moins pr\u00e9cises. Ces calculateurs ont le gros inconv\u00e9nient d'\u00eatre sp\u00e9cifiques \u00e0 un probl\u00e8me donn\u00e9 et doivent alors \u00eatre reprogramm\u00e9s manuellement pour r\u00e9soudre un autre probl\u00e8me. Le num\u00e9rique s'est peu \u00e0 peu impos\u00e9, notamment gr\u00e2ce \u00e0 sa programmabilit\u00e9. A cette \u00e9poque, et jusqu'au milieu du XX\u00e8me si\u00e8cle, les calculateurs et les premiers ordinateurs fonctionnaient \u00e0 l'aide de tubes \u00e0 vide apr\u00e8s l'invention de la triode en 1906. Pour d\u00e9crire bri\u00e8vement le fonctionnement de tels tubes, un corps conducteur servant de cathode (\u00e9lectrode n\u00e9gative) est chauff\u00e9 \u00e0 tr\u00e8s haute temp\u00e9rature. Cela permet aux \u00e9lectrons de s'en d\u00e9tacher. Les \u00e9lectrons sont des particules charg\u00e9es n\u00e9gativement et leur d\u00e9placement g\u00e9n\u00e8re un courant \u00e9lectrique. Les \u00e9lectrons parcourent du vide ou un gaz inerte en sens unique jusqu'\u00e0 rencontrer un autre corps conducteur, l'anode (\u00e9lectrode positive). Ainsi, si on fait suffisamment chauffer la cathode, on peut propager un courant \u00e9lectrique. Ce courant \u00e9lectrique sert ensuite dans un langage binaire : il y a du courant ou il n'y en a pas . Les tubes \u00e0 vide pr\u00e9sentent plusieurs inconv\u00e9nients, d'une part l'importante consommation d'\u00e9nergie mais aussi leur fiabilit\u00e9 m\u00e9diocre. Il n'\u00e9tait pas rare que des tubes grillent occasionnant des pannes sur les machines en fonctionnement. Les tubes \u00e0 vide sont cependant encore utilis\u00e9s comme dans les fours \u00e0 micro-ondes. Ils pr\u00e9sentent aussi l'int\u00e9r\u00eat de ne pas \u00eatre sensibles aux impulsions \u00e9lectromagn\u00e9tiques. La Seconde Guerre Mondiale est un \u00e9v\u00e9nement majeur y compris dans l'histoire de l'informatique. Les communications \u00e9crites \u00e9taient transmises par t\u00e9l\u00e9scripteur en code Baudot , un ancien code plus vieux que l'ASCII. Le code Baudot permettait de repr\u00e9senter chaque carat\u00e8re (lettre, chiffre, ponctuation) sur 5 bits. Le bit ne pouvant prendre que deux valeurs, 0 ou 1, le code Baudot n'offrait que 32 combinaisons diff\u00e9rentes et donc pas assez pour repr\u00e9senter les 26 lettres de l'alphabet, les 10 chiffres et d'autres caract\u00e8res comme les sauts de ligne. Deux codes binaires \u00e9taient alors d\u00e9di\u00e9s au passage du mode \"alphabet\" au mode \"chiffre\". Les codes suivants \u00e9taient alors interpr\u00e9t\u00e9s soit comme une lettre, soit comme un chiffre, soit comme un caract\u00e8re sp\u00e9cial suivant le mode utilis\u00e9. Cependant, en temps de guerre, les communications \u00e9crites n'\u00e9taient pas transmises en clair. Autrement dit, pour \u00e9viter que l'ennemi ne puisse lire les communications, elles \u00e9taient chiffr\u00e9es et, th\u00e9oriquement , seul le destinataire de la communication pouvait les d\u00e9chiffrer. Un chiffrement connu, bien que tr\u00e8s basique, est celui qu'utilisait Jules C\u00e9sar qui d\u00e9calait les lettres dans l'alphabet. Depuis, la cryptographie s'est consid\u00e9rablement am\u00e9lior\u00e9e pour \u00e9viter que les chiffrements ne soient cass\u00e9s trop facilement. Durant la Seconde Guerre Mondiale, les t\u00e9l\u00e9scripteurs envoyaient donc des messages chiffr\u00e9s. On peut par exemple \u00e9voquer les machines de Lorenz utilis\u00e9es par l'Allemagne nazie pour chiffrer ses communications. Le Colossus \u00e9tait un ordinateur num\u00e9rique construit tr\u00e8s secr\u00e8tement entre 1942 et 1943 \u00e0 Londres, et servait \u00e0 la cryptanalyse du code Lorenz pour pouvoir d\u00e9chiffrer les communications allemandes. Le Colossus n'\u00e9tait pas le seul ordinateur, num\u00e9rique ou \u00e9lectrom\u00e9canique, \u00e0 avoir \u00e9t\u00e9 d\u00e9velopp\u00e9 durant le conflit. L'un de ces ordinateurs qui est encore tr\u00e8s c\u00e9l\u00e8bre n'est autre que l' ENIAC , pour Electronic Numerical Integrator And Computer . Il est d\u00e9velopp\u00e9 pour le calcul balistique dans un premier temps puis sert aux probl\u00e8mes de physique nucl\u00e9aire et de m\u00e9t\u00e9orologie. Il s'agit d'une \u00e9norme machine pesant 30 tonnes et occupant une salle enti\u00e8re avec une consommation estim\u00e9e \u00e0 environ 150kW ou plus. L'ENIAC est une machine qu'on programme par c\u00e2blage. Cela fait que le calculateur ne travaille pas durant de longs moments, le temps qu'il soit programm\u00e9. Le math\u00e9maticien John von Neumann comprend qu'il s'agit l\u00e0 d'un frein important pour exploiter tout le potentiel de la machine. En 1946, il publie un rapport qui d\u00e9crit l' architecture dite de von Neumann , le mod\u00e8le de ce qu'on appelle un ordinateur . Cette architecture comprend plusieurs \u00e9l\u00e9ments : Une unit\u00e9 arithm\u00e9tique et logique , aussi appell\u00e9e ALU en anglais, pour effectuer des op\u00e9rations de base (addition, soustraction, multiplication, division et des op\u00e9rations binaires) ; Une unit\u00e9 de contr\u00f4le qui sert \u00e0 donner la succession des instructions \u00e0 l'ALU ; De la m\u00e9moire interne pour y stocker le programme, c'est-\u00e0-dire l'ensemble des instructions, et les donn\u00e9es. Cette m\u00e9moire est le coeur m\u00eame de l'id\u00e9e de von Neumann pour am\u00e9liorer les performances de la machine ; Et des dispositifs d'entr\u00e9e et de sortie qui permettent \u00e0 la machine d'interagir avec l'\u00eatre humain. En 1948, l'ENIAC sera am\u00e9lior\u00e9 avec une m\u00e9moire en lecture seule pour stocker le programme et les informations. De fait, il devient Turing-complet , d'apr\u00e8s l'id\u00e9e de la machine universelle du math\u00e9maticien et cryptologue Alan Turing .","title":"La Seconde Guerre Mondiale et les d\u00e9buts de l'informatique"},{"location":"bases/history/#quest-ce-que-la-memoire-informatique","text":"Le rapport de John von Neumann constitue \u00e0 la fois un v\u00e9ritable bon en avant pour l'informatique mais ouvre en contrepartie la question de savoir ce qu'est la m\u00e9moire d'une machine. Plusieurs id\u00e9es ont \u00e9merg\u00e9 pour concevoir une m\u00e9moire vive , comme des lignes de d\u00e9lai au mercure. Parmi les d\u00e9fauts de cette m\u00e9moire, elle ne permettait pas un acc\u00e8s al\u00e9atoire aux donn\u00e9es. Le but d'une m\u00e9moire \u00e0 acc\u00e8s al\u00e9atoire ( Random Access Memory ou RAM en anglais) est de pouvoir acc\u00e9der directement \u00e0 une information quelque soit son emplacement . Une m\u00e9moire s\u00e9quentielle comme une bande magn\u00e9tique n\u00e9cessite de parcourir toute la m\u00e9moire jusqu'\u00e0 l'emplacement voulu, et donc fait perdre \u00e9norm\u00e9ment de temps. Un exemple assez parlant est celui de la K7 audio qui n\u00e9cessite de faire d\u00e9filer la bande jusqu'au d\u00e9but d'une chanson. Au contraire, un CD permet un acc\u00e8s direct au d\u00e9but d'une chanson. Le premier prototype d'ordinateur bas\u00e9 sur l'architecture de von Neumann voit le jour en 1948. C'est le Small-Scale Experimental Machine (SSEM), construit \u00e0 l'universit\u00e9 Victoria de Manchester. La m\u00e9moire vive emploie un tube de Williams, un tube cathodique stockant chaque bit sous la forme de point (0) ou de trait (1). Le SSEM n'a pas de r\u00e9elle utilit\u00e9 calculatoire, il se limite \u00e0 des op\u00e9rations math\u00e9matiques sans grande importance mais suffisamment longues pour effectuer l'exp\u00e9rimentation. Le but de cette machine est de v\u00e9rifier le bon fonctionnement d'un ordinateur tel que d\u00e9crit par von Neumann. Le SSEM montre bien la faisabilit\u00e9 du concept de von Neumann, ce qui ouvre la voie \u00e0 la construction de plusieurs gros ordinateurs au d\u00e9but des ann\u00e9es 1950 \u00e0 travers le monde.","title":"Qu'est-ce que la m\u00e9moire informatique ?"},{"location":"bases/history/#lavenement-des-ordinateurs","text":"Les calculateurs analogiques et les ordinateurs coexisteront durant quelques d\u00e9cennies. En effet, les ordinateurs sont encore tr\u00e8s chers et leur fonctionnement num\u00e9rique, diff\u00e9rent, n'est pas adapt\u00e9 \u00e0 tous les probl\u00e8mes rencontr\u00e9s. Cependant, les grands calculateurs analogiques tomberont en d\u00e9su\u00e9tude autour des ann\u00e9es 80. Toutefois, un regain d'int\u00e9r\u00eat pour certains calculs s'op\u00e8re avec des calculateurs analogiques/num\u00e9riques. Les premiers ordinateurs sont d\u00e9velopp\u00e9s dans des laboratoires universitaires mais tr\u00e8s vite, l'industrie s'y int\u00e9resse. Par exemple, IBM produit l'IBM 701 de 1952 \u00e0 1954 pour le calcul scientifique et l'IBM 702 en 1953, moins performant, \u00e0 usage commercial. Ce dernier utilise un stockage sous forme de d\u00e9rouleur de bandes magn\u00e9tiques pour concurrencer l'UNIVAC I. En 1953 toujours, IBM lance l'IBM 650 avec une m\u00e9moire de masse magn\u00e9tique \u00e0 tambour, une technologie concurrente aux disques durs magn\u00e9tiques. Un tournant important dans l'histoire des ordinateurs s'effectue \u00e0 la fin des ann\u00e9es 50. En effet, la premi\u00e8re g\u00e9n\u00e9ration d'ordinateurs, comme les calculateurs analogiques, utilisent des tubes \u00e0 vide pour les unit\u00e9s de calcul. Ces tubes sont encombrants, consomment \u00e9norm\u00e9ment d'\u00e9nergie mais sont aussi tr\u00e8s peu fiables provoquant d'innombrables pannes. Le transistor est invent\u00e9 en 1947 par John Bardeen, William Shockley et Walter Brattain alors qu'ils voulaient amplifier les communications t\u00e9l\u00e9phoniques longue distance en rempla\u00e7ant les tubes \u00e0 vide trop fragiles. Le transistor est un dispositif semi-conducteur, c'est-\u00e0-dire qu'on peut contr\u00f4ler s'il laisse passer ou non les \u00e9lectrons. Le transistor peut ainsi \u00eatre vu comme un interrupteur \u00e9lectronique. Quelques ann\u00e9es apr\u00e8s sa d\u00e9couverte, le transistor est utilis\u00e9 commercialement avec les premiers postes dits \u00e0 transistors. C'est encore un peu apr\u00e8s qu'il vient remplacer le tube \u00e0 vide dans les ordinateurs, leur permettant notamment de consommer moins, d'\u00eatre plus fiables et plus compacts. En 1954, Bell Labs produit le TRADIC, le tout premier ordinateur \u00e0 transistors qui en contenait 700. En 1958, Jack Kilby, nouvellement employ\u00e9 chez Texas Instruments, invente le circuit int\u00e9gr\u00e9 permettant la miniaturisation et faisant rentrer l'informatique dans l'\u00e8re moderne. Il recevra d'ailleurs le prix Nobel de physique en 2000 pour cette invention. Kilby a commenc\u00e9 par prototyper un tel circuit en reliant \u00e0 la main les transistors avant que l'id\u00e9e soit industrialis\u00e9e. Elle donnera les bo\u00eetiers contenant des centaines de transistors, enfermant en son sein tout ce qui permet de r\u00e9aliser des calculs et de la m\u00e9moire, et accessibles par des \u00e9l\u00e9ments d'entr\u00e9es et sorties \u00e0 l'aide de pattes en p\u00e9riph\u00e9rie. La premi\u00e8re utilisation des ordinateurs bas\u00e9s sur des circuits int\u00e9gr\u00e9s, l\u00e9gers et fiables, est faite avec le programme de missiles ballistiques Minuteman II, puis le c\u00e9l\u00e8bre programme de missions Apollo pour la conqu\u00eate de la Lune. Les programmes militaires et spatiaux sont parmi ceux, si ce ne sont ceux, qui font le plus avancer la science et la technologie. Bien qu'il soit difficile de d\u00e9partager lesquelles ont le plus d\u00e9mocratiser l'informatique entre les missions ballistiques et spatiales, elles y ont toutes contribu\u00e9. La conception de fus\u00e9e par exemple n\u00e9cessite une perfection absolue dans l'usinage des pi\u00e8ces en m\u00e9tallurgie, ce qui aidera \u00e0 la pr\u00e9cision lors de la fabrication de composants \u00e9lectroniques. De meme les instruments de mesure doivent \u00eatre extr\u00eamement fiables et pr\u00e9cis. La gestion de projet s'est aussi consid\u00e9rablement d\u00e9velopp\u00e9e et am\u00e9lior\u00e9e pour devenir ce qu'elle est aujourd'hui dans tous les domaines. Le programme Apollo a par ailleurs permis l'essor de l'informatique et l'a scind\u00e9 en deux p\u00f4les : le mat\u00e9riel ( hardware en anglais) et le logiciel ( software en anglais). Outre la fiabilit\u00e9 du mat\u00e9riel, la politique de test des logiciels s'est aussi d\u00e9velopp\u00e9e pour \u00e9viter les d\u00e9faillances des programmes. Le circuit int\u00e9gr\u00e9 a permis de miniaturiser les \u00e9l\u00e9ments d'un ordinateur. Cependant, les diff\u00e9rents composants sont des entit\u00e9s s\u00e9par\u00e9es occasionnant des lenteurs et des probl\u00e8mes li\u00e9s \u00e0 la fiabilit\u00e9 dans la connexion entre ces composants. C'est en 1971 que ces probl\u00e8mes sont corrig\u00e9s car sort le tout premier microprocesseur, le Intel 4004, un processeur 4 bits. En ne mesurant pas plus de 11mm\u00b2, il a une puissance de calcul \u00e9quivalente \u00e0 celle de l'ENIAC . Il est suivi l'ann\u00e9e suivant du 8008 qui peut traiter jusqu'\u00e0 8 bits simultan\u00e9ment. Le processeur mythique d'Intel sortira en 1974, le Intel 8080 lui aussi en 8 bits. Il aura de nombreux concurrents comme le Zilog Z80 qui \u00e9tait d'ailleurs compatible avec le processeur d'Intel, ou encore le Motorola 6800. L'Intel 8080 a \u00e9t\u00e9 am\u00e9lior\u00e9 les ann\u00e9es suivantes donnant par exemple le 8085. Les premiers ordinateurs personnels grand public sortent en 1977. Il s'agit de : l'Apple II avec un processeur MOS Technology 6502 8 bit (1 MHz) et 4 ko de RAM (jusqu'\u00e0 64 ko), le TRS-80 (Tandy RadioShack) \u00e9quip\u00e9 d'un Zilog Z80 (1.77 MHz) et 4 ko de RAM. et le Commodore PET 2001 dot\u00e9 d'un MOS Technology 6502 8 bit (1 MHz) et 4 ou 8 ko de RAM, vendu pour l'\u00e9quivalent de 3555 dollars en 2021. Il n'est \u00e9videmment pas possible de parler de l'enti\u00e8ret\u00e9 des microprocesseurs ayant exist\u00e9 et de leurs sp\u00e9cificit\u00e9s. La suite de cet historique se concentre essentiellement sur ceux des marques qui sont les plus connues \u00e0 l'heure actuelle. Le Intel 8086 sorti en 1978 est le premier processeur 16 bits et sera aussi le tout premier processeur de la famille x86 , la plus r\u00e9pandue de nos jours pour les ordinateurs personnels, serveurs et stations de travail. Pour son 80286, Intel a d\u00fb demander \u00e0 une autre entreprise de produire des clones de ses processeurs car IBM exigeait de ses clients deux sources d'approvionnement. C'est ainsi qu' AMD a commenc\u00e9 \u00e0 produire l'Am286 en 1982, bien que totalement con\u00e7u par Intel. AMD continuera de produire des processeurs pour Intel pendant quelques ann\u00e9es. Le Intel 80386 publi\u00e9 en 1986 est le premier microprocesseur 32 bits et impl\u00e9mente l'architecture IA-32 (Intel Architecture 32 bits) qu'on retrouve partout de nos jours. Intel assure la r\u00e9trocompatibilit\u00e9 des nouveaux processeurs avec les anciens afin que les programmes d\u00e9j\u00e0 \u00e9crits puissent continuer \u00e0 fonctionner. A noter qu'\u00e0 cette \u00e9poque encore, pour des raisons techniques et de co\u00fbt, les microprocesseurs n'int\u00e8grent pas d'unit\u00e9 de calcul en virgule flottante ( floating point unit ou FPU en anglais), c'est-\u00e0-dire pour r\u00e9aliser des op\u00e9rations sur des nombres \u00e0 virgule. Ils doivent donc \u00eatre coupl\u00e9s \u00e0 des coprocesseurs d\u00e9di\u00e9s \u00e0 de tels calculs pour y parvenir. Il faudra attendre le 80486 d'Intel sorti en 1989 pour voir le premier microprocesseur int\u00e9grant - en option - une FPU. En 1993 sortent les Intel Pentium. Ils int\u00e8grent comme nouveaut\u00e9 un jeu d' instructions vectorielles appel\u00e9 MMX permettant de traiter plusieurs donn\u00e9es simultan\u00e9ment en une seule instruction. Cela accro\u00eet les performances des processeurs sur les applications multim\u00e9dia. Intel r\u00e9utilisera sur plusieurs ann\u00e9es la marque Pentium pour ses processeurs grand public ainsi que leur jumeaux d\u00e9di\u00e9s aux professionnels sous la marque Xeon. En 1995, AMD introduit son premier processeur x86 ind\u00e9pendemment d'Intel , l'AMD-K5. La concurrence entre Intel et AMD a donc commenc\u00e9. L'argument de vente en ce temps \u00e9tait la fr\u00e9quence. Les premiers processeurs \u00e0 passer le cap symbolique du GHz sont l'Athlon (AMD) et le Pentium III (Intel). Avec son Xeon Northwood, Intel introduit l' hyper-threading qui duplique certains \u00e9l\u00e9ments du c\u0153ur du processeur comme les registres. Cette technologie permet d'am\u00e9liorer en th\u00e9orie les performances d'applications dites multithread\u00e9es, \u00e9xecutant plusieurs instructions en parall\u00e8le. Les Pentium 4 h\u00e9riteront de l'hyper-threading mais leur microarchitecture con\u00e7ue pour la course \u00e0 la fr\u00e9quence entra\u00eene une consommation et une dissipation de chaleur tr\u00e8s importantes. La course \u00e0 la fr\u00e9quence a donc atteint ses limites... Intel et AMD changent leur fusil d'\u00e9paule pour partir \u00e0 la conqu\u00eate du nombre de c\u0153urs. Alors que l'AMD Athlon 64 sorti en 2003 est le tout premier processeur 64 bits (tout en \u00e9tant compatible avec les programmes 32 bits), l'AMD Athlon X2 et le Pentium Extreme Edition sont, eux, les premiers mod\u00e8les dot\u00e9s de deux c\u0153urs en 2005. Ce dernier est compl\u00e9t\u00e9 par de l'hyper-threading donnant un total de deux c\u0153urs physiques et quatres processeurs logiques. Les performances des processeur multic\u0153urs font un bon en avant alors que leur fr\u00e9quence est plus faible. Les ann\u00e9es qui suivent jusqu'\u00e0 nos jours voient le nombre de c\u0153urs toujours plus grand chez Intel et AMD. Au fil du temps, la finesse de gravure s'est consid\u00e9rablement r\u00e9duite. Elle correspond \u00e0 la taille des transistors composant les microprocesseurs. Plus ces transistors sont petits, plus il est possible d'en avoir dans un processeur. Le Intel 4004 \u00e9tait grav\u00e9 avec une finesse de 10\u00b5m (soit 10000nm) et \u00e9tait compos\u00e9 de 2300 transistors. Trente ans plus tard, en 2001, le Pentium III Tualatin avait une finesse de gravure de 130nm et poss\u00e9dait 45 millions de transistors. Le marketing a \u00e9norm\u00e9ment pris le relai sur la taille r\u00e9elle des transistors. Les chiffres annonc\u00e9s de 5nm pour les processeurs les plus r\u00e9cents ne refl\u00e8tent plus la r\u00e9alit\u00e9 gr\u00e2ce \u00e0 des astuces ing\u00e9nieuses comme des transistors en 3D. En marge des deux leaders sur les microarchitectures IA-32 puis AMD64/IA-64, une autre soci\u00e9t\u00e9 d\u00e9veloppe des architectures de processeurs 32 et 64 bits. Il s'agit de ARM, dont il n'est pas possible d'acheter un microprocesseur seul : ils sont int\u00e9gr\u00e9s dans des syst\u00e8mes sur puce ( system on a chip ou SoC en anglais). On retrouve les SoC ARM dans de nombreux produits, en particulier mobiles (t\u00e9l\u00e9phones et smartphones, ordinateurs et consoles portables, tablettes, etc), car les architectures arm sont simples et optimisent la consommation \u00e9lectrique. Cependant, on retrouve \u00e9galement des supercalculateurs \u00e9quip\u00e9s de SoC con\u00e7us par ARM, comme le supercalculateur japonais Fugaku. En 2020, Apple annonce le M1, une puce ARM 64 bits qui \u00e9quipe ses nouveaux produits tels que les tablettes, ordinateurs mobiles et de bureau. En 2021, Apple lance les puces M1 Pro et M1 Max encore plus puissantes et le M2 sort en 2022 pla\u00e7ant la barre toujours plus haute. Il existe \u00e9galement des microcontr\u00f4leurs, ou MCU pour microcontroller unit en anglais, qu'on retrouve dans \u00e9norm\u00e9ment d'appareils \u00e9lectroniques dans des syst\u00e8mes embarqu\u00e9s. Les MCU sont \u00e9galement des circuits int\u00e9gr\u00e9s rassemblant un processeur, de la m\u00e9moire (vive et morte), des entr\u00e9es et sorties, etc. Souvent d\u00e9di\u00e9s \u00e0 des t\u00e2ches sp\u00e9cifiques, ils sont tr\u00e8s peu chers car leurs capacit\u00e9s en calculs sont limit\u00e9es ; ils consomment peu avec une fr\u00e9quence faible et leurs sp\u00e9cificit\u00e9s limit\u00e9es font qu'ils ne sont pas aussi polyvalents que les microprocesseurs des ordinateurs personnels. Maintenant que cet historique nous a conduit jusqu'\u00e0 quelques technologies de nos processeurs modernes, je te propose de voir comment ces derniers fonctionnent. Sources https://hmn.wiki/fr/Approximate_number_system https://www.numerama.com/sciences/594706-les-nombres-activent-la-meme-zone-du-cerveau-chez-votre-chien-que-chez-vous.html https://www.larousse.fr/dictionnaires/francais/informatique/42996 https://www.franceculture.fr/emissions/la-methode-scientifique/quand-lhumanite-t-elle-appris-compter http://revue.sesamath.net/spip.php?article891 https://www.youtube.com/watch?v=gLzHlA33rqw https://journals.openedition.org/bibnum/548 https://www.historyofinformation.com/detail.php?id=4727 https://www.youtube.com/watch?v=-2604CHuIyk http://claude-gimenes.fr/electronique/semi-conducteurs/-vii-tube-a-vide-electronique-ancetre-du-transistor-amplificateur https://www.futura-sciences.com/tech/actualites/technologie-tubes-vide-futur-nanoelectronique-40058/ https://aconit.inria.fr/omeka/exhibits/show/histoire-machines.1.html https://www.ibm.com/ibm/history/history/history_intro.html https://www.youtube.com/watch?v=dcN9QXxmRqk https://www.techno-science.net/definition/2400.html http://www.numdam.org/article/ASCFM_1962__8_2_131_0.pdf https://gallica.bnf.fr/ark:/12148/bpt6k24678x/f535.item ( Les merveilles de la science, ou Description populaire des inventions modernes. 5-6, Suppl\u00e9ments. 5 par Louis Figuier, Chapitre IV - LE T\u00c9L\u00c9GRAPHE BAUDOT, A TRANSMISSION MULTIPLE. ark:/12148/bpt6k24678x) https://www.futura-sciences.com/sciences/questions-reponses/mathematiques-quest-ce-chiffrement-cesar-8032/ https://www.britannica.com/technology/ENIAC https://www.universalis.fr/encyclopedie/e-n-i-a-c/ https://www.histoire-informatique.org/grandes_dates/2_3.html https://www.futura-sciences.com/sciences/personnalites/matiere-john-von-neumann-256/ https://history-computer.com/ssem-complete-history-of-the-small-scale-experimental-machine/ https://info.blaisepascal.fr/transistor https://www.cairn.info/revue-le-temps-des-medias-2004-2-page-118.htm https://www.digikey.fr/fr/articles/transistor-basics https://couleur-science.eu/?d=775902--cest-quoi-un-transistor-comment-ca-marche https://www.irif.fr/~carton/Enseignement/Architecture/Cours/Historic/tradic.html https://www.lmd.jussieu.fr/~hourdin/COURS/FORTRAN/Fortran/ https://www.webtimemedias.com/article/le-deces-de-jack-kilby-inventeur-du-circuit-integre","title":"L'av\u00e8nement des ordinateurs"},{"location":"bases/languages/","text":"Historique des langages de programmation Note importante Le but de cet historique n'est pas d'\u00eatre exhaustif en pr\u00e9sentant l'int\u00e9gralit\u00e9 des langages de programmation qui ont exist\u00e9. Ce serait une t\u00e2che absolument impossible et sans grand int\u00e9r\u00eat. Plut\u00f4t que cela, je te propose de passer en revue les diff\u00e9rentes \u00e9volutions qui sont apparues au fil du temps ainsi que la naissance des principaux langages utilis\u00e9s de nos jours. Je m'excuse par avance de ne peut-\u00eatre pas parler de ton langage pr\u00e9f\u00e9r\u00e9... Comme nous l'avons vu dans la section \" Des cailloux \u00e0 l'informatique \", la premi\u00e8re personne \u00e0 programmer au monde \u00e9tait Ada Lovelace. Elle a programm\u00e9 la machine analytique de Charles Babbage. Les notes qu'elle a ajout\u00e9es pour pouvoir calculer les nombres de Bernouilli ont permis d'\u00e9tablir qu'il s'agissait du tout premier programme informatique jamais cr\u00e9\u00e9. De plus, jusque l\u00e0, les autres machines programm\u00e9es ex\u00e9cutaient leur \"code\" s\u00e9quentiellement. Le programme d'Ada Lovelace contenait quant \u00e0 lui la toute premi\u00e8re boucle conditionnelle , un concept propre \u00e0 la programmation informatique. Les machines con\u00e7ues jusque l\u00e0 sont d\u00e9di\u00e9es \u00e0 une r\u00e9soudre un probl\u00e8me sp\u00e9cifique. Pour un autre probl\u00e8me, il fallait constuire une nouvelle machine. En 1936, Alan Turing pose le concept abstrait de machine de Turing . Il s'agit, pour r\u00e9sumer, d'une machine th\u00e9orique capable de lire un code qu'on lui soumet pour r\u00e9soudre un probl\u00e8me donn\u00e9. Il n'y a plus besoin de construire une nouvelle machine pour r\u00e9soudre un autre probl\u00e8me, on change le code fournit \u00e0 la machine pour qu'elle r\u00e9solve ce nouveau probl\u00e8me. De nos jours, ce code est ce qu'on appelle un algorithme . La premi\u00e8re machine au monde \u00e0 devenir Turing-complet est l'ENIAC en 1945 gr\u00e2ce \u00e0 l'ajout d'une m\u00e9moire morte primitive contenant le code \u00e0 ex\u00e9cuter. Au lieu de refaire les c\u00e2blages pendant plusieurs jours pour reprogrammer l'ENIAC, il ne faut plus que quelques heures pour le faire travailler sur un nouveau probl\u00e8me. Durant la Seconde Guerre Mondiale, l'ing\u00e9nieur allemand Konrad Zuse con\u00e7oit Plankalk\u00fcl qu'il consid\u00e8re comme \u00e9tant le premier langage de programmation de haut niveau . Sa conception ne fait pas beaucoup d'\u00e9cho, par temps de guerre et la pr\u00e9occupation de Zuse \u00e0 vendre son ordinateur, le Zuse 3. Ainsi, la premi\u00e8re publication \u00e0 propos de Plankalk\u00fcl ne sort qu'en 1948. Malgr\u00e9 l'innovation importante qu'il repr\u00e9sente, le langage restera inconnu. Plankalk\u00fcl n'a \u00e9t\u00e9 impl\u00e9ment\u00e9 qu'en 1975 et le premier compilateur pour ce langage n'est finalis\u00e9 qu'en l'an 2000. Compilation et langages modernes Un compilateur permet de transformer un code source , \u00e9crit dans un langage de programmation de haut niveau (facilement compr\u00e9hensible par un \u00eatre humain) vers un code objet , g\u00e9n\u00e9ralement en langage machine compr\u00e9hensible par une machine (processeur) cible. Le premier compilateur, ou en tout cas l'anc\u00eatre d'un compilateur \u00e0 proprement parler, est le A-0 System ( Arithmetic Language version 0 ) \u00e9crit par Grace Hopper en 1951 pour l'UNIVAC I. Grace Hopper r\u00e9alise que, au-del\u00e0 des calculs, l'ordinateur peut lui-m\u00eame assembler des suites d'instructions isol\u00e9es, les sous-programmes ou subroutines en anglais, pour constituer un programme complet. Dans le cadre du A-0 System , les sous-programmes pouvaient convertir du code symbolique math\u00e9matique en langage machine. Grace Hopper a enregistr\u00e9 ces subroutines sur une bande magn\u00e9tique et les a identifi\u00e9 de fa\u00e7on unique avec un code. Apr\u00e8s le code de la subroutine , on entrait les param\u00e8tres d'entr\u00e9e. Le programme \u00e0 \u00e9crire consistait alors en une succession de codes identifiant les subroutines avec leurs param\u00e8tres respectifs. Lors de l'ex\u00e9cution, la machine allait chercher les instructions \u00e0 ex\u00e9cuter en les retrouvant sur la bande magn\u00e9tique. Il y aura plusieurs it\u00e9rations pour am\u00e9liorer cet anc\u00eatre du compilateur, jusqu'au B-0 ( Business Language Version 0 ) renomm\u00e9 FLOW-MATIC . Pour celui-ci, Grace Hopper a eu la brillante id\u00e9e d\u00e8s 1955 qu'un programme informatique peut \u00eatre \u00e9crit en anglais car les lettres \u00e9taient d'autres symboles que l'ordinateur pouvait reconna\u00eetre et convertir en code machine. D\u00e9di\u00e9 \u00e0 des applications m\u00e9tiers, le FLOW-MATIC a permis \u00e0 l'UNIVAC I de comprendre 20 mots-cl\u00e9s inspir\u00e9s de l'anglais de 1955 \u00e0 1959. En 1957, le FORTRAN ( mathematical FORmula TRANslating system ) est d\u00e9ploy\u00e9. C'est un langage de programmation de haut niveau initialement propos\u00e9 en 1953 par John Backus pour faciliter les calculs de nombres en virgule flottante sur l'IBM 704. Bien que ses auteurs n'aient pas eu l'id\u00e9e d'employer des mots-cl\u00e9s en anglais pour faciliter le d\u00e9veloppement de programmes informatiques, le FORTRAN sera l'un des premiers, si ce n'est le premier, langages informatiques \u00e0 mettre cette id\u00e9e en pratique. Fortran est un langage g\u00e9n\u00e9raliste qui continue d'\u00eatre mis \u00e0 jour. Sa derni\u00e8re version est le Fortran 2018 en attendant une version Fortran 202x. Selon l'index TIOBE (juin 2022), Fortran occupe la 26\u00e8me place des langages les plus populaires. Deux autres langages de haut niveau ont \u00e9t\u00e9 con\u00e7us dans les ann\u00e9es 50 : Le Lisp ( list processing ) qui est \u00e0 la fois le premier langage fonctionnel mais aussi le premier langage moderne interpr\u00e9t\u00e9 ; Le COBOL ( COmmon Business Oriented Language ), initialement con\u00e7u pour la programmation d'applications de gestion et de nos jours essentiellement utilis\u00e9 dans les secteurs des banques, assurances, etc. Fortran, Lisp et Cobol ont inspir\u00e9 la plupart des langages qui sont apparus ensuite jusqu'\u00e0 nos jours, directement et indirectement. American Standard Code for Information Interchange Comme nous l'avons vu dans le chapitre qui lui est consacr\u00e9, le microprocesseur ne sait traiter que des donn\u00e9es num\u00e9riques : des nombres entiers et des nombres \u00e0 virgule flottante. En aucun cas, le CPU n'est capable de lire un texte directement. Pour y parvenir, il faut cr\u00e9er une table d'association entre un caract\u00e8re (lettre, ponctuation, etc) et une valeur num\u00e9rique. Par exemple, il est possible de faire en sorte que le CPU reconnaisse la valeur num\u00e9rique 14 comme \u00e9tant la lettre F , ou encore la valeur num\u00e9rique 3 pour le point d'interrogation ? . Puisque les premiers langages modernes utilisaient des mots-cl\u00e9s tir\u00e9s de l'anglais, et donc \u00e9crits \u00e0 l'aide de l'alphabet latin, il a fallu standardiser la fa\u00e7on dont les textes \u00e9taient repr\u00e9sent\u00e9s pour les ordinateurs. En effet, avant la standardisation, il existait de nombreux codages de caract\u00e8res incompatibles entre eux : chaque machine poss\u00e9dait sa propre table d'association. Ainsi, en 1960, l'Organisation Internationale de Normalisation ( International Organization for Standardization ou ISO en anglais) cr\u00e9e un comit\u00e9 technique dont le but est de sortir un code standard de transmission de donn\u00e9es. En 1963, la premi\u00e8re version du code am\u00e9ricain normalis\u00e9 pour l'\u00e9change d'information ( American Standard Code for Information Interchange ou ASCII) appara\u00eet. Des mises \u00e0 jour de ce code seront effectu\u00e9es pour ajouter de nouveaux symboles \u00e0 des emplacements pr\u00e9vus mais vides jusqu'en 1986, ann\u00e9e de la derni\u00e8re version de l'ASCII en vigueur de nos jours. Gr\u00e2ce \u00e0 cette standardisation, la lecture de donn\u00e9es textuelles peut se faire sans avoir besoin de les convertir au pr\u00e9alable pour une nouvelle machine. L'ASCII code les caract\u00e8res sur 7 bits et permet donc de repr\u00e9senter un total de 128 caract\u00e8res diff\u00e9rents, dont 95 caract\u00e8res imprimables : les 26 lettres de l'alphabet latin, chacune en minuscules et en majuscules ; les 10 chiffres arabes ; des symboles math\u00e9matiques, des symboles de ponctuation ; des symboles sp\u00e9ciaux comme l'esperluette (&) ou le dollar am\u00e9ricain ($). Et pour les autres caract\u00e8res ? Avec seulement 128 caract\u00e8res cod\u00e9s, l'ASCII ne peut repr\u00e9senter que les caract\u00e8res de la langue anglaise. Plusieurs m\u00e9thodes ont \u00e9merg\u00e9 pour ajouter de nouveaux caract\u00e8res et c'est le standard Unicode qui s'est impos\u00e9 \u00e0 l'\u00e9chelle internationale, notamment dans sa forme UTF-8. La premi\u00e8re version du standard Unicode date de 1991 et de nouveaux caract\u00e8res sont r\u00e9guli\u00e8rement ajout\u00e9s. L'Unicode 14.0 est publi\u00e9 le 9 septembre 2021 et contient 144 697 caract\u00e8res diff\u00e9rents. Simula et la notion de classe Simula ( SIMple Universal LAnguage ) est un langage m\u00e9connu et pourtant qui va initier une r\u00e9volution dans la programmation. Si Lisp a introduit la programmation fonctionelle, Simula apporte quant \u00e0 lui la notion de classe . Il est en effet le premier langage \u00e0 impl\u00e9menter le mod\u00e8le de classe de Hoare ( record classes ) en 1967, d'apr\u00e8s les travaux de Charles Antony Richard Hoare. Une record class permet de cr\u00e9er des references selon Hoare, chaque r\u00e9f\u00e9rence \u00e9tant unique dans le programme avec ses propres valeurs. Par exemple, une classe Voiture permet de cr\u00e9er une multitude de Voitures, chacune \u00e9tant dot\u00e9e d'une couleur ou d'une motorisation qui lui est propre. Les classe peuvent \u00eatre h\u00e9rit\u00e9e et mises en relation les unes avec les autres. La programmation orient\u00e9e objet Simula 67 ne permet pas encore la programmation orient\u00e9e objet \u00e0 proprement parler, mais il impl\u00e9mente d\u00e9j\u00e0 les principaux concepts de ce paradigme de programmation. Alan Kay sera l'auteur de la programmation orient\u00e9e objet avec le langage Flex qui donnera ensuite le Smalltalk , initi\u00e9 en 1969 et publi\u00e9 en 1980. Les record classes d\u00e9nomm\u00e9es par Hoare sont ici nomm\u00e9es classes d'objets et les references sont quant \u00e0 elles baptis\u00e9es objets dans Smalltalk. Smalltalk a inspir\u00e9 plusieurs langages dont les plus connus sont Ruby , Objective-C ou encore Java . Ce dernier a lui-m\u00eame fortement inspir\u00e9 le langage C# que nous allons justement \u00e9tudier \u00e0 partir du prochain chapitre. Entre temps... De nombreux autres langages sont apparus entre la publication de Simula et celle de Smalltalk. S'il n'est pas possible de parler de tous ces langages, il est n\u00e9anmoins faisable d'en pr\u00e9senter rapidement ceux qui sont encore tr\u00e8s utilis\u00e9s de nos jours. C'est le cas notamment du langage C , invent\u00e9 en 1972 par Dennis Ritchie et rectifi\u00e9 par Brian Kernighan. La version stabilis\u00e9e du langage est publi\u00e9e en 1978. C est un langage g\u00e9n\u00e9raliste dit de bas niveau car il offre des outils pour une gestion tr\u00e8s fine de la m\u00e9moire ou encore la possibilit\u00e9 d'inclure du code directement en langage assembleur. De fait, C est particuli\u00e8rement adapt\u00e9 \u00e0 l'\u00e9criture de programmes intimement li\u00e9 au mat\u00e9riel informatique tels que des pilotes ( drivers , logiciels communiquant directement avec un mat\u00e9riel donn\u00e9), des compilateurs, des syst\u00e8mes d'exploitation et bien d'autres encore. C occupe la deuxi\u00e8me place du classement TIOBE en juin 2022. Bjarne Stroustrup commence \u00e0 travailler sur une \u00e9volution du langage C intitul\u00e9e C with classes ( C avec des classes ) en 1979, \u00e0 l'\u00e9poque o\u00f9 lui et Ritchie travaillent chez Bell. A ce moment-l\u00e0, le langage C n'est pas encore tr\u00e8s connu et son utilisation pour de gros programmes est assez compliqu\u00e9e. Si Simula offre des possibilit\u00e9s int\u00e9ressantes d'un point de vue programmatique pour \u00e9crire de longs programmes, gr\u00e2ce \u00e0 la notion de classes, il souffre de plusieurs d\u00e9fauts dont une vitesse d'ex\u00e9cution assez lente. Stroustrup s'inspire ainsi de Simula pour apporter la notion de classe au langage C et le rendre plus facile \u00e0 programmer. En 1983, le langage est renomm\u00e9 en C++ pour symboliser l'am\u00e9lioration du langage C et s'enrichie de nombreuses nouvelles fonctionnalit\u00e9s. Le langage est commercialis\u00e9 pour la premi\u00e8re fois en 1985 mais sans \u00eatre standardis\u00e9. Il faudra attendre 1998 pour que le langage soit standardis\u00e9 par l'ISO face \u00e0 la popularit\u00e9 grandissante du langage en devenant le C++98 . De nouveaux standards ont \u00e9t\u00e9 publi\u00e9s depuis, ajoutant de nouvelles fonctionnalit\u00e9s \u00e9galement dans sa biblioth\u00e8que standard. C++ occupe la quatri\u00e8me place du classement TIOBE en juin 2022. Et de nos jours ? Le langage Python est le dernier langage du top 5 dans le classement TIOBE dont je n'ai pas encore parl\u00e9 dans cet historique. C'est m\u00eame le langage le plus populaire en juin 2022 ! A la fin des ann\u00e9es 1980, le d\u00e9veloppeur Guido van Rossum travaille sur le syst\u00e8me d'exploitation distribu\u00e9 Amoeba. Amoeba utilisait le Bourne shell ( bsh ) comme interface utilisateur en ligne de commandes mais les appels syst\u00e8mes \u00e9taient difficilement interfa\u00e7ables avec ce shell . Guido van Rossum, qui a \u00e9galement particip\u00e9 au d\u00e9veloppement du langage ABC pour Amoeba, s'inspire de ce dernier pour d\u00e9velopper un nouveau langage de script sur son temps libre. Le nom de ce projet est tir\u00e9 de la s\u00e9rie t\u00e9l\u00e9vis\u00e9e britannique Monty Python's Flying Circus . Van Rossum est rest\u00e9 le d\u00e9veloppeur principal du projet jusqu'au 12 juillet 2018, date \u00e0 partir de laquelle il est n\u00e9anmoins leader du projet (\" Benevolent Dictator for Life \"). Comme pour ABC, Python utilise l'indentation comme syntaxe. D'autres sources ont permis de forger le langage tel que la gestion des exceptions de Modula-3 ou encore le langage C. Python est un langage de haut niveau d'abstraction, c'est-\u00e0-dire qu'il masque les d\u00e9tails du mat\u00e9riel informatique au d\u00e9veloppeur. Cet avantage coupl\u00e9 \u00e0 sa syntaxe facile \u00e0 appr\u00e9hender rend non seulement le d\u00e9veloppement plus rapide mais permet en plus de s'initier \u00e0 la programmation. Python est un langage dit multi-paradigme puisqu'il permet la programmation imp\u00e9rative structur\u00e9e, orient\u00e9e objet et fonctionnelle. Il s'agit \u00e9galement d'un langage interpr\u00e9t\u00e9 , en opposition aux langages compil\u00e9s . La cr\u00e9ation de nouveaux langages ne s'arr\u00eate pas l\u00e0 ! Chaque d\u00e9cennie voit appara\u00eetre plusieurs nouveaux langages. S'il est encore un peu t\u00f4t pour parler de langages de la d\u00e9cennie en cours, entre 2010 et 2019 quelques langages int\u00e9ressants sont apparus. Le langage Rust par exemple en est un des meilleurs exemples car il gagne en popularit\u00e9 notamment gr\u00e2ce \u00e0 sa rapidit\u00e9 d'ex\u00e9cution, sa fiabilit\u00e9 et son \u00e9cosyst\u00e8me pratique. Cat\u00e9gorisation des langages de programmation Les langages de programmation sont tr\u00e8s nombreux. C'est pourquoi cette page ne peut pas tous les pr\u00e9senter ind\u00e9pendamment et n'a pas du tout pour but d'en \u00eatre une liste exhaustive. La quantit\u00e9 de langages diff\u00e9rents, chacun avec ses particularit\u00e9s, a entra\u00een\u00e9 la cr\u00e9ation de cat\u00e9gories. Chaque langage se retrouve dans une et m\u00eame souvent plusieurs cat\u00e9gories diff\u00e9rentes \u00e0 la fois. Je vais t'en pr\u00e9senter quelques unes rapidement. Langages interpr\u00e9t\u00e9s et compil\u00e9s Comme nous l'avons vu pour Python, il s'agit d'un langage dit \"interpr\u00e9t\u00e9\". Cette cat\u00e9gorie s'oppose \u00e0 une autre, celle des langages dits \"compil\u00e9s\". Un langage compil\u00e9 va \u00eatre traduit en langage machine, avec les instructions binaires qui sont directement comprises par le processeur. Il faut donc un ensemble d'outils pour obtenir ce qu'on appelle un ex\u00e9cutable dont le compilateur qui s'occupe de cette traduction. Le code binaire obtenu est intimement li\u00e9 au jeu d'instructions du processeur et donc son architecture. Comme le code est directement traduit en langage machine, le programme s'ex\u00e9cutera tr\u00e8s rapidement. En revanche, cela signifie aussi qu'un processeur de la famille x86 ne peut pas ex\u00e9cuter un programme compil\u00e9 pour un processeur d'architecture ARMv8 (et vice-versa). Un langage interpr\u00e9t\u00e9 n'est pas directement converti en langage machine. Il va passer par un programme interm\u00e9diaire dont le r\u00f4le est de traduire le code source en langage machine au fil de l'ex\u00e9cution. Dans certains cas, l'interpr\u00e9teur utilise un code interm\u00e9diaire appel\u00e9 bytecode . Ce programme interm\u00e9diaire est l' interpr\u00e9teur . Le premier langage interpr\u00e9t\u00e9 est le Lisp. Cela pr\u00e9sente donc l'avantage de se passer d'une \u00e9tape potentiellement longue de compilation. Un autre avantage de taille est que le code peut \u00eatre ex\u00e9cut\u00e9 indiff\u00e9remment quelque soit l'architecture du processeur. En effet, c'est \u00e0 l'interpr\u00e9teur d'\u00eatre adapt\u00e9 \u00e0 l'architecture. La contrepartie est cependant une vitesse d'ex\u00e9cution plus lente par rapport \u00e0 un programme compil\u00e9 en langage machine. Cependant, il est \u00e0 noter que de gros efforts sont faits pour r\u00e9duire l'\u00e9cart entre les deux types de proc\u00e9d\u00e9s. Certains langages vont encore plus loin en utilisant une machine virtuelle . C'est le cas de Java et de C# par exemple. Les programmes sont traduits en bytecode , un langage machine pour la machine virtuelle. La machine virtuelle a ensuite le r\u00f4le de traduire le bytecode en langage machine pour le processeur-cible. Il est alors possible de distribuer un programme en bytecode et de l'ex\u00e9cuter sur n'importe quel processeur. Note Les notions de \"langage compil\u00e9\" et \"langage interpr\u00e9t\u00e9\" sont un peu abusives. Le langage lui-m\u00eame n'est ni compil\u00e9, ni interpr\u00e9t\u00e9. C'est la fa\u00e7on dont le code source est converti en langage machine qui importe. Si le langage C est usuellement compil\u00e9, rien n'emp\u00eache d'\u00e9crire un interpr\u00e9teur de langage C. A l'inverse, il est tout \u00e0 fait possible de compiler du Python en langage machine comme c'est le cas avec Pyjion. Paradigmes Les langages sont aussi class\u00e9s par rapport aux paradigmes qu'ils permettent d'employer. Nous avons d\u00e9j\u00e0 eu l'occasion d'aborder cette notion sans encore l'expliquer. Pour faire simple, en programmation, un paradigme est une fa\u00e7on dont un langage va nous permettre d'\u00e9crire un programme (tout ou partie). Certains langages comme le C ne proposent qu'un seul paradigme, la programmation proc\u00e9durale. D'autres langages vont proposer plusieurs paradigmes qu'il se possible de m\u00e9langer dans un m\u00eame programme selon les besoins. Par exemple le Rust permet entre autres la programmation proc\u00e9durale, fonctionnelle ou encore - un peu - orient\u00e9e objet. Sources https://www.computinghistory.org.uk/det/5487/Grace-Hopper-completes-the-A-0-Compiler/ https://www.lemonde.fr/blog/binaire/2015/03/08/la-petulante-grace-hopper/ https://www.tiobe.com/tiobe-index/ http://www.unicode.org/versions/Unicode14.0.0/ https://medium.com/%C3%A9cosyst%C3%A8me-des-langages-de-programmation/simula-le-language-de-lombre-db04c7feb715 http://progwww.vub.ac.be/~tjdhondt/ESL/Simula_to_Smalltalk_files/Record-Handling-Hoare.pdf https://amturing.acm.org/award_winners/kay_3972189.cfm https://www.stroustrup.com/ https://interstices.info/bjarne-stroustrup-le-pere-de-c-un-langage-qui-a-de-la-classe/ https://www.fil.univ-lille1.fr/~marvie/python/introduction.html https://www.rust-lang.org/ https://www.trypyjion.com/","title":"Evolution des langages de programmation"},{"location":"bases/languages/#historique-des-langages-de-programmation","text":"Note importante Le but de cet historique n'est pas d'\u00eatre exhaustif en pr\u00e9sentant l'int\u00e9gralit\u00e9 des langages de programmation qui ont exist\u00e9. Ce serait une t\u00e2che absolument impossible et sans grand int\u00e9r\u00eat. Plut\u00f4t que cela, je te propose de passer en revue les diff\u00e9rentes \u00e9volutions qui sont apparues au fil du temps ainsi que la naissance des principaux langages utilis\u00e9s de nos jours. Je m'excuse par avance de ne peut-\u00eatre pas parler de ton langage pr\u00e9f\u00e9r\u00e9... Comme nous l'avons vu dans la section \" Des cailloux \u00e0 l'informatique \", la premi\u00e8re personne \u00e0 programmer au monde \u00e9tait Ada Lovelace. Elle a programm\u00e9 la machine analytique de Charles Babbage. Les notes qu'elle a ajout\u00e9es pour pouvoir calculer les nombres de Bernouilli ont permis d'\u00e9tablir qu'il s'agissait du tout premier programme informatique jamais cr\u00e9\u00e9. De plus, jusque l\u00e0, les autres machines programm\u00e9es ex\u00e9cutaient leur \"code\" s\u00e9quentiellement. Le programme d'Ada Lovelace contenait quant \u00e0 lui la toute premi\u00e8re boucle conditionnelle , un concept propre \u00e0 la programmation informatique. Les machines con\u00e7ues jusque l\u00e0 sont d\u00e9di\u00e9es \u00e0 une r\u00e9soudre un probl\u00e8me sp\u00e9cifique. Pour un autre probl\u00e8me, il fallait constuire une nouvelle machine. En 1936, Alan Turing pose le concept abstrait de machine de Turing . Il s'agit, pour r\u00e9sumer, d'une machine th\u00e9orique capable de lire un code qu'on lui soumet pour r\u00e9soudre un probl\u00e8me donn\u00e9. Il n'y a plus besoin de construire une nouvelle machine pour r\u00e9soudre un autre probl\u00e8me, on change le code fournit \u00e0 la machine pour qu'elle r\u00e9solve ce nouveau probl\u00e8me. De nos jours, ce code est ce qu'on appelle un algorithme . La premi\u00e8re machine au monde \u00e0 devenir Turing-complet est l'ENIAC en 1945 gr\u00e2ce \u00e0 l'ajout d'une m\u00e9moire morte primitive contenant le code \u00e0 ex\u00e9cuter. Au lieu de refaire les c\u00e2blages pendant plusieurs jours pour reprogrammer l'ENIAC, il ne faut plus que quelques heures pour le faire travailler sur un nouveau probl\u00e8me. Durant la Seconde Guerre Mondiale, l'ing\u00e9nieur allemand Konrad Zuse con\u00e7oit Plankalk\u00fcl qu'il consid\u00e8re comme \u00e9tant le premier langage de programmation de haut niveau . Sa conception ne fait pas beaucoup d'\u00e9cho, par temps de guerre et la pr\u00e9occupation de Zuse \u00e0 vendre son ordinateur, le Zuse 3. Ainsi, la premi\u00e8re publication \u00e0 propos de Plankalk\u00fcl ne sort qu'en 1948. Malgr\u00e9 l'innovation importante qu'il repr\u00e9sente, le langage restera inconnu. Plankalk\u00fcl n'a \u00e9t\u00e9 impl\u00e9ment\u00e9 qu'en 1975 et le premier compilateur pour ce langage n'est finalis\u00e9 qu'en l'an 2000.","title":"Historique des langages de programmation"},{"location":"bases/languages/#compilation-et-langages-modernes","text":"Un compilateur permet de transformer un code source , \u00e9crit dans un langage de programmation de haut niveau (facilement compr\u00e9hensible par un \u00eatre humain) vers un code objet , g\u00e9n\u00e9ralement en langage machine compr\u00e9hensible par une machine (processeur) cible. Le premier compilateur, ou en tout cas l'anc\u00eatre d'un compilateur \u00e0 proprement parler, est le A-0 System ( Arithmetic Language version 0 ) \u00e9crit par Grace Hopper en 1951 pour l'UNIVAC I. Grace Hopper r\u00e9alise que, au-del\u00e0 des calculs, l'ordinateur peut lui-m\u00eame assembler des suites d'instructions isol\u00e9es, les sous-programmes ou subroutines en anglais, pour constituer un programme complet. Dans le cadre du A-0 System , les sous-programmes pouvaient convertir du code symbolique math\u00e9matique en langage machine. Grace Hopper a enregistr\u00e9 ces subroutines sur une bande magn\u00e9tique et les a identifi\u00e9 de fa\u00e7on unique avec un code. Apr\u00e8s le code de la subroutine , on entrait les param\u00e8tres d'entr\u00e9e. Le programme \u00e0 \u00e9crire consistait alors en une succession de codes identifiant les subroutines avec leurs param\u00e8tres respectifs. Lors de l'ex\u00e9cution, la machine allait chercher les instructions \u00e0 ex\u00e9cuter en les retrouvant sur la bande magn\u00e9tique. Il y aura plusieurs it\u00e9rations pour am\u00e9liorer cet anc\u00eatre du compilateur, jusqu'au B-0 ( Business Language Version 0 ) renomm\u00e9 FLOW-MATIC . Pour celui-ci, Grace Hopper a eu la brillante id\u00e9e d\u00e8s 1955 qu'un programme informatique peut \u00eatre \u00e9crit en anglais car les lettres \u00e9taient d'autres symboles que l'ordinateur pouvait reconna\u00eetre et convertir en code machine. D\u00e9di\u00e9 \u00e0 des applications m\u00e9tiers, le FLOW-MATIC a permis \u00e0 l'UNIVAC I de comprendre 20 mots-cl\u00e9s inspir\u00e9s de l'anglais de 1955 \u00e0 1959. En 1957, le FORTRAN ( mathematical FORmula TRANslating system ) est d\u00e9ploy\u00e9. C'est un langage de programmation de haut niveau initialement propos\u00e9 en 1953 par John Backus pour faciliter les calculs de nombres en virgule flottante sur l'IBM 704. Bien que ses auteurs n'aient pas eu l'id\u00e9e d'employer des mots-cl\u00e9s en anglais pour faciliter le d\u00e9veloppement de programmes informatiques, le FORTRAN sera l'un des premiers, si ce n'est le premier, langages informatiques \u00e0 mettre cette id\u00e9e en pratique. Fortran est un langage g\u00e9n\u00e9raliste qui continue d'\u00eatre mis \u00e0 jour. Sa derni\u00e8re version est le Fortran 2018 en attendant une version Fortran 202x. Selon l'index TIOBE (juin 2022), Fortran occupe la 26\u00e8me place des langages les plus populaires. Deux autres langages de haut niveau ont \u00e9t\u00e9 con\u00e7us dans les ann\u00e9es 50 : Le Lisp ( list processing ) qui est \u00e0 la fois le premier langage fonctionnel mais aussi le premier langage moderne interpr\u00e9t\u00e9 ; Le COBOL ( COmmon Business Oriented Language ), initialement con\u00e7u pour la programmation d'applications de gestion et de nos jours essentiellement utilis\u00e9 dans les secteurs des banques, assurances, etc. Fortran, Lisp et Cobol ont inspir\u00e9 la plupart des langages qui sont apparus ensuite jusqu'\u00e0 nos jours, directement et indirectement.","title":"Compilation et langages modernes"},{"location":"bases/languages/#american-standard-code-for-information-interchange","text":"Comme nous l'avons vu dans le chapitre qui lui est consacr\u00e9, le microprocesseur ne sait traiter que des donn\u00e9es num\u00e9riques : des nombres entiers et des nombres \u00e0 virgule flottante. En aucun cas, le CPU n'est capable de lire un texte directement. Pour y parvenir, il faut cr\u00e9er une table d'association entre un caract\u00e8re (lettre, ponctuation, etc) et une valeur num\u00e9rique. Par exemple, il est possible de faire en sorte que le CPU reconnaisse la valeur num\u00e9rique 14 comme \u00e9tant la lettre F , ou encore la valeur num\u00e9rique 3 pour le point d'interrogation ? . Puisque les premiers langages modernes utilisaient des mots-cl\u00e9s tir\u00e9s de l'anglais, et donc \u00e9crits \u00e0 l'aide de l'alphabet latin, il a fallu standardiser la fa\u00e7on dont les textes \u00e9taient repr\u00e9sent\u00e9s pour les ordinateurs. En effet, avant la standardisation, il existait de nombreux codages de caract\u00e8res incompatibles entre eux : chaque machine poss\u00e9dait sa propre table d'association. Ainsi, en 1960, l'Organisation Internationale de Normalisation ( International Organization for Standardization ou ISO en anglais) cr\u00e9e un comit\u00e9 technique dont le but est de sortir un code standard de transmission de donn\u00e9es. En 1963, la premi\u00e8re version du code am\u00e9ricain normalis\u00e9 pour l'\u00e9change d'information ( American Standard Code for Information Interchange ou ASCII) appara\u00eet. Des mises \u00e0 jour de ce code seront effectu\u00e9es pour ajouter de nouveaux symboles \u00e0 des emplacements pr\u00e9vus mais vides jusqu'en 1986, ann\u00e9e de la derni\u00e8re version de l'ASCII en vigueur de nos jours. Gr\u00e2ce \u00e0 cette standardisation, la lecture de donn\u00e9es textuelles peut se faire sans avoir besoin de les convertir au pr\u00e9alable pour une nouvelle machine. L'ASCII code les caract\u00e8res sur 7 bits et permet donc de repr\u00e9senter un total de 128 caract\u00e8res diff\u00e9rents, dont 95 caract\u00e8res imprimables : les 26 lettres de l'alphabet latin, chacune en minuscules et en majuscules ; les 10 chiffres arabes ; des symboles math\u00e9matiques, des symboles de ponctuation ; des symboles sp\u00e9ciaux comme l'esperluette (&) ou le dollar am\u00e9ricain ($). Et pour les autres caract\u00e8res ? Avec seulement 128 caract\u00e8res cod\u00e9s, l'ASCII ne peut repr\u00e9senter que les caract\u00e8res de la langue anglaise. Plusieurs m\u00e9thodes ont \u00e9merg\u00e9 pour ajouter de nouveaux caract\u00e8res et c'est le standard Unicode qui s'est impos\u00e9 \u00e0 l'\u00e9chelle internationale, notamment dans sa forme UTF-8. La premi\u00e8re version du standard Unicode date de 1991 et de nouveaux caract\u00e8res sont r\u00e9guli\u00e8rement ajout\u00e9s. L'Unicode 14.0 est publi\u00e9 le 9 septembre 2021 et contient 144 697 caract\u00e8res diff\u00e9rents.","title":"American Standard Code for Information Interchange"},{"location":"bases/languages/#simula-et-la-notion-de-classe","text":"Simula ( SIMple Universal LAnguage ) est un langage m\u00e9connu et pourtant qui va initier une r\u00e9volution dans la programmation. Si Lisp a introduit la programmation fonctionelle, Simula apporte quant \u00e0 lui la notion de classe . Il est en effet le premier langage \u00e0 impl\u00e9menter le mod\u00e8le de classe de Hoare ( record classes ) en 1967, d'apr\u00e8s les travaux de Charles Antony Richard Hoare. Une record class permet de cr\u00e9er des references selon Hoare, chaque r\u00e9f\u00e9rence \u00e9tant unique dans le programme avec ses propres valeurs. Par exemple, une classe Voiture permet de cr\u00e9er une multitude de Voitures, chacune \u00e9tant dot\u00e9e d'une couleur ou d'une motorisation qui lui est propre. Les classe peuvent \u00eatre h\u00e9rit\u00e9e et mises en relation les unes avec les autres.","title":"Simula et la notion de classe"},{"location":"bases/languages/#la-programmation-orientee-objet","text":"Simula 67 ne permet pas encore la programmation orient\u00e9e objet \u00e0 proprement parler, mais il impl\u00e9mente d\u00e9j\u00e0 les principaux concepts de ce paradigme de programmation. Alan Kay sera l'auteur de la programmation orient\u00e9e objet avec le langage Flex qui donnera ensuite le Smalltalk , initi\u00e9 en 1969 et publi\u00e9 en 1980. Les record classes d\u00e9nomm\u00e9es par Hoare sont ici nomm\u00e9es classes d'objets et les references sont quant \u00e0 elles baptis\u00e9es objets dans Smalltalk. Smalltalk a inspir\u00e9 plusieurs langages dont les plus connus sont Ruby , Objective-C ou encore Java . Ce dernier a lui-m\u00eame fortement inspir\u00e9 le langage C# que nous allons justement \u00e9tudier \u00e0 partir du prochain chapitre.","title":"La programmation orient\u00e9e objet"},{"location":"bases/languages/#entre-temps","text":"De nombreux autres langages sont apparus entre la publication de Simula et celle de Smalltalk. S'il n'est pas possible de parler de tous ces langages, il est n\u00e9anmoins faisable d'en pr\u00e9senter rapidement ceux qui sont encore tr\u00e8s utilis\u00e9s de nos jours. C'est le cas notamment du langage C , invent\u00e9 en 1972 par Dennis Ritchie et rectifi\u00e9 par Brian Kernighan. La version stabilis\u00e9e du langage est publi\u00e9e en 1978. C est un langage g\u00e9n\u00e9raliste dit de bas niveau car il offre des outils pour une gestion tr\u00e8s fine de la m\u00e9moire ou encore la possibilit\u00e9 d'inclure du code directement en langage assembleur. De fait, C est particuli\u00e8rement adapt\u00e9 \u00e0 l'\u00e9criture de programmes intimement li\u00e9 au mat\u00e9riel informatique tels que des pilotes ( drivers , logiciels communiquant directement avec un mat\u00e9riel donn\u00e9), des compilateurs, des syst\u00e8mes d'exploitation et bien d'autres encore. C occupe la deuxi\u00e8me place du classement TIOBE en juin 2022. Bjarne Stroustrup commence \u00e0 travailler sur une \u00e9volution du langage C intitul\u00e9e C with classes ( C avec des classes ) en 1979, \u00e0 l'\u00e9poque o\u00f9 lui et Ritchie travaillent chez Bell. A ce moment-l\u00e0, le langage C n'est pas encore tr\u00e8s connu et son utilisation pour de gros programmes est assez compliqu\u00e9e. Si Simula offre des possibilit\u00e9s int\u00e9ressantes d'un point de vue programmatique pour \u00e9crire de longs programmes, gr\u00e2ce \u00e0 la notion de classes, il souffre de plusieurs d\u00e9fauts dont une vitesse d'ex\u00e9cution assez lente. Stroustrup s'inspire ainsi de Simula pour apporter la notion de classe au langage C et le rendre plus facile \u00e0 programmer. En 1983, le langage est renomm\u00e9 en C++ pour symboliser l'am\u00e9lioration du langage C et s'enrichie de nombreuses nouvelles fonctionnalit\u00e9s. Le langage est commercialis\u00e9 pour la premi\u00e8re fois en 1985 mais sans \u00eatre standardis\u00e9. Il faudra attendre 1998 pour que le langage soit standardis\u00e9 par l'ISO face \u00e0 la popularit\u00e9 grandissante du langage en devenant le C++98 . De nouveaux standards ont \u00e9t\u00e9 publi\u00e9s depuis, ajoutant de nouvelles fonctionnalit\u00e9s \u00e9galement dans sa biblioth\u00e8que standard. C++ occupe la quatri\u00e8me place du classement TIOBE en juin 2022.","title":"Entre temps..."},{"location":"bases/languages/#et-de-nos-jours","text":"Le langage Python est le dernier langage du top 5 dans le classement TIOBE dont je n'ai pas encore parl\u00e9 dans cet historique. C'est m\u00eame le langage le plus populaire en juin 2022 ! A la fin des ann\u00e9es 1980, le d\u00e9veloppeur Guido van Rossum travaille sur le syst\u00e8me d'exploitation distribu\u00e9 Amoeba. Amoeba utilisait le Bourne shell ( bsh ) comme interface utilisateur en ligne de commandes mais les appels syst\u00e8mes \u00e9taient difficilement interfa\u00e7ables avec ce shell . Guido van Rossum, qui a \u00e9galement particip\u00e9 au d\u00e9veloppement du langage ABC pour Amoeba, s'inspire de ce dernier pour d\u00e9velopper un nouveau langage de script sur son temps libre. Le nom de ce projet est tir\u00e9 de la s\u00e9rie t\u00e9l\u00e9vis\u00e9e britannique Monty Python's Flying Circus . Van Rossum est rest\u00e9 le d\u00e9veloppeur principal du projet jusqu'au 12 juillet 2018, date \u00e0 partir de laquelle il est n\u00e9anmoins leader du projet (\" Benevolent Dictator for Life \"). Comme pour ABC, Python utilise l'indentation comme syntaxe. D'autres sources ont permis de forger le langage tel que la gestion des exceptions de Modula-3 ou encore le langage C. Python est un langage de haut niveau d'abstraction, c'est-\u00e0-dire qu'il masque les d\u00e9tails du mat\u00e9riel informatique au d\u00e9veloppeur. Cet avantage coupl\u00e9 \u00e0 sa syntaxe facile \u00e0 appr\u00e9hender rend non seulement le d\u00e9veloppement plus rapide mais permet en plus de s'initier \u00e0 la programmation. Python est un langage dit multi-paradigme puisqu'il permet la programmation imp\u00e9rative structur\u00e9e, orient\u00e9e objet et fonctionnelle. Il s'agit \u00e9galement d'un langage interpr\u00e9t\u00e9 , en opposition aux langages compil\u00e9s . La cr\u00e9ation de nouveaux langages ne s'arr\u00eate pas l\u00e0 ! Chaque d\u00e9cennie voit appara\u00eetre plusieurs nouveaux langages. S'il est encore un peu t\u00f4t pour parler de langages de la d\u00e9cennie en cours, entre 2010 et 2019 quelques langages int\u00e9ressants sont apparus. Le langage Rust par exemple en est un des meilleurs exemples car il gagne en popularit\u00e9 notamment gr\u00e2ce \u00e0 sa rapidit\u00e9 d'ex\u00e9cution, sa fiabilit\u00e9 et son \u00e9cosyst\u00e8me pratique.","title":"Et de nos jours ?"},{"location":"bases/languages/#categorisation-des-langages-de-programmation","text":"Les langages de programmation sont tr\u00e8s nombreux. C'est pourquoi cette page ne peut pas tous les pr\u00e9senter ind\u00e9pendamment et n'a pas du tout pour but d'en \u00eatre une liste exhaustive. La quantit\u00e9 de langages diff\u00e9rents, chacun avec ses particularit\u00e9s, a entra\u00een\u00e9 la cr\u00e9ation de cat\u00e9gories. Chaque langage se retrouve dans une et m\u00eame souvent plusieurs cat\u00e9gories diff\u00e9rentes \u00e0 la fois. Je vais t'en pr\u00e9senter quelques unes rapidement.","title":"Cat\u00e9gorisation des langages de programmation"},{"location":"bases/languages/#langages-interpretes-et-compiles","text":"Comme nous l'avons vu pour Python, il s'agit d'un langage dit \"interpr\u00e9t\u00e9\". Cette cat\u00e9gorie s'oppose \u00e0 une autre, celle des langages dits \"compil\u00e9s\". Un langage compil\u00e9 va \u00eatre traduit en langage machine, avec les instructions binaires qui sont directement comprises par le processeur. Il faut donc un ensemble d'outils pour obtenir ce qu'on appelle un ex\u00e9cutable dont le compilateur qui s'occupe de cette traduction. Le code binaire obtenu est intimement li\u00e9 au jeu d'instructions du processeur et donc son architecture. Comme le code est directement traduit en langage machine, le programme s'ex\u00e9cutera tr\u00e8s rapidement. En revanche, cela signifie aussi qu'un processeur de la famille x86 ne peut pas ex\u00e9cuter un programme compil\u00e9 pour un processeur d'architecture ARMv8 (et vice-versa). Un langage interpr\u00e9t\u00e9 n'est pas directement converti en langage machine. Il va passer par un programme interm\u00e9diaire dont le r\u00f4le est de traduire le code source en langage machine au fil de l'ex\u00e9cution. Dans certains cas, l'interpr\u00e9teur utilise un code interm\u00e9diaire appel\u00e9 bytecode . Ce programme interm\u00e9diaire est l' interpr\u00e9teur . Le premier langage interpr\u00e9t\u00e9 est le Lisp. Cela pr\u00e9sente donc l'avantage de se passer d'une \u00e9tape potentiellement longue de compilation. Un autre avantage de taille est que le code peut \u00eatre ex\u00e9cut\u00e9 indiff\u00e9remment quelque soit l'architecture du processeur. En effet, c'est \u00e0 l'interpr\u00e9teur d'\u00eatre adapt\u00e9 \u00e0 l'architecture. La contrepartie est cependant une vitesse d'ex\u00e9cution plus lente par rapport \u00e0 un programme compil\u00e9 en langage machine. Cependant, il est \u00e0 noter que de gros efforts sont faits pour r\u00e9duire l'\u00e9cart entre les deux types de proc\u00e9d\u00e9s. Certains langages vont encore plus loin en utilisant une machine virtuelle . C'est le cas de Java et de C# par exemple. Les programmes sont traduits en bytecode , un langage machine pour la machine virtuelle. La machine virtuelle a ensuite le r\u00f4le de traduire le bytecode en langage machine pour le processeur-cible. Il est alors possible de distribuer un programme en bytecode et de l'ex\u00e9cuter sur n'importe quel processeur. Note Les notions de \"langage compil\u00e9\" et \"langage interpr\u00e9t\u00e9\" sont un peu abusives. Le langage lui-m\u00eame n'est ni compil\u00e9, ni interpr\u00e9t\u00e9. C'est la fa\u00e7on dont le code source est converti en langage machine qui importe. Si le langage C est usuellement compil\u00e9, rien n'emp\u00eache d'\u00e9crire un interpr\u00e9teur de langage C. A l'inverse, il est tout \u00e0 fait possible de compiler du Python en langage machine comme c'est le cas avec Pyjion.","title":"Langages interpr\u00e9t\u00e9s et compil\u00e9s"},{"location":"bases/languages/#paradigmes","text":"Les langages sont aussi class\u00e9s par rapport aux paradigmes qu'ils permettent d'employer. Nous avons d\u00e9j\u00e0 eu l'occasion d'aborder cette notion sans encore l'expliquer. Pour faire simple, en programmation, un paradigme est une fa\u00e7on dont un langage va nous permettre d'\u00e9crire un programme (tout ou partie). Certains langages comme le C ne proposent qu'un seul paradigme, la programmation proc\u00e9durale. D'autres langages vont proposer plusieurs paradigmes qu'il se possible de m\u00e9langer dans un m\u00eame programme selon les besoins. Par exemple le Rust permet entre autres la programmation proc\u00e9durale, fonctionnelle ou encore - un peu - orient\u00e9e objet. Sources https://www.computinghistory.org.uk/det/5487/Grace-Hopper-completes-the-A-0-Compiler/ https://www.lemonde.fr/blog/binaire/2015/03/08/la-petulante-grace-hopper/ https://www.tiobe.com/tiobe-index/ http://www.unicode.org/versions/Unicode14.0.0/ https://medium.com/%C3%A9cosyst%C3%A8me-des-langages-de-programmation/simula-le-language-de-lombre-db04c7feb715 http://progwww.vub.ac.be/~tjdhondt/ESL/Simula_to_Smalltalk_files/Record-Handling-Hoare.pdf https://amturing.acm.org/award_winners/kay_3972189.cfm https://www.stroustrup.com/ https://interstices.info/bjarne-stroustrup-le-pere-de-c-un-langage-qui-a-de-la-classe/ https://www.fil.univ-lille1.fr/~marvie/python/introduction.html https://www.rust-lang.org/ https://www.trypyjion.com/","title":"Paradigmes"},{"location":"bases/data/","text":"Variabilit\u00e9 et typage Les donn\u00e9es utilis\u00e9es par un ordinateur peuvent \u00eatre cat\u00e9goris\u00e9es de diff\u00e9rentes mani\u00e8res. Le premier consiste en la notion de variabilit\u00e9 : Une variable est une donn\u00e9e qui pourra \u00eatre cr\u00e9\u00e9e avec une valeur de d\u00e9part qui modifiable durant toute l'ex\u00e9cution du programme. Durant un match de foot, nous pourrions avoir deux variables assez \u00e9videntes : le score de chacune des deux \u00e9quipes qui s'affrontent. A l'inverse, une donn\u00e9e qui ne variera jamais sera appel\u00e9e une constante . Dans notre match de foot, il pourrait s'agit du nombre de joueurs sur le terrain. Au-del\u00e0 de cette distinction, quel type de donn\u00e9e un ordinateur pourrait-il \u00eatre amen\u00e9 \u00e0 utiliser ? Il faut se rappeler que l'ordinateur, et le calculateur avant lui, avaient pour mission initiale d'aider l'Homme dans des calculs longs et r\u00e9barbatifs. Il est tout naturel de trouver de quoi faire des calculs et donc des nombres !","title":"Variabilit\u00e9 et typage"},{"location":"bases/data/#variabilite-et-typage","text":"Les donn\u00e9es utilis\u00e9es par un ordinateur peuvent \u00eatre cat\u00e9goris\u00e9es de diff\u00e9rentes mani\u00e8res. Le premier consiste en la notion de variabilit\u00e9 : Une variable est une donn\u00e9e qui pourra \u00eatre cr\u00e9\u00e9e avec une valeur de d\u00e9part qui modifiable durant toute l'ex\u00e9cution du programme. Durant un match de foot, nous pourrions avoir deux variables assez \u00e9videntes : le score de chacune des deux \u00e9quipes qui s'affrontent. A l'inverse, une donn\u00e9e qui ne variera jamais sera appel\u00e9e une constante . Dans notre match de foot, il pourrait s'agit du nombre de joueurs sur le terrain. Au-del\u00e0 de cette distinction, quel type de donn\u00e9e un ordinateur pourrait-il \u00eatre amen\u00e9 \u00e0 utiliser ? Il faut se rappeler que l'ordinateur, et le calculateur avant lui, avaient pour mission initiale d'aider l'Homme dans des calculs longs et r\u00e9barbatifs. Il est tout naturel de trouver de quoi faire des calculs et donc des nombres !","title":"Variabilit\u00e9 et typage"},{"location":"bases/data/types/binary/","text":"Le binaire Avant d'aborder le sujet des nombres utilis\u00e9s dans un programme, parlons un peu de la repr\u00e9sentation de ceux-ci en binaire. Un ordinateur fonctionne \u00e0 l'\u00e9lectricit\u00e9. Or, l'\u00e9lectricit\u00e9 n'a pas d'autre possibilit\u00e9 de varier qu'entre deux \u00e9tats : il y a du courant (0), ou il n'y en a pas (1). Ces valeurs binaires, 0 et 1 , sont les bits , pour binary digits en anglais. Bien s\u00fbr, limiter un ordinateur \u00e0 compter jusqu'\u00e0 1 serait inutile pour des calculs scientifiques complexes ! Il devient plus int\u00e9ressant de grouper les bits pour obtenir des nombres plus grands. Revenons sur la fa\u00e7on dont nous comptons en tant qu'humains. Tout syst\u00e8me de calcul utilise ce qu'on appelle une base, qui d\u00e9finit - pour simplifier au maximum - \u00e0 partir de quand on ajoute une puissance. Concr\u00e8tement, prenons l'exemple de la base 10 que nous utilisons quotidiennement. Nous avons dix chiffres - dix, comme la base donc - allant de 0 \u00e0 9. Puis, pour passer \u00e0 la valeur apr\u00e8s 9, nous ajoutons une puissance : la dizaine. On passe alors de 9 \u00e0 10, un nombre constitu\u00e9 de deux chiffres. Nous restons \u00e0 deux chiffres jusqu'\u00e0 99 o\u00f9, pour passer \u00e0 la valeur suivante, nous ajoutons encore une puissance : la centaine. Voici le sch\u00e9ma que nous obtenons : 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [...] 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 [...] 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 .... Maintenant, appliquons le m\u00eame principe dans le cas o\u00f9 nous ne pouvons plus compter jusqu'\u00e0 9 mais uniquement jusqu'\u00e0 1 avant d'augmenter la puissance. C'est-\u00e0-dire que nous nous comptons en base 2, puisque nous n'avons droit qu'\u00e0 deux chiffres : 0 et 1. D\u00e8s que nous voudrons compter apr\u00e8s 1, il faudra alors ajouter une puissance ! Nous obtiendons (10) 2 , puis (11) 2 , puis (100) 2 , (101) 2 , etc... Voici les nombres allant de 0 \u00e0 15 en binaire : 0 1 10 11 100 101 110 111 1000 1001 1010 1011 1100 1101 1110 1111 Remarques Les nombres pairs finissent toujours par 0 et les nombres impairs par 1. Pour distinguer un nombre \u00e9crit dans une base autre que la base 10, nous l'\u00e9crivons entre parenth\u00e8ses avec la base en indice. Pour conna\u00eetre le nombre de valeurs codables sur un groupe de bits, on utilise tout simplement la formule 2 n (2 \u00e0 la puissance n ) o\u00f9 n est le nombre de bits. Par exemple, pour savoir combien de valeur nous pouvons coder sur 2 bits, nous calculons 2 2 = 4. En effet, nous pouvons coder les valeurs suivantes : 0 ( 00 ), 1 ( 01 ), (10) 2 et (11) 2 .","title":"Le binaire"},{"location":"bases/data/types/binary/#le-binaire","text":"Avant d'aborder le sujet des nombres utilis\u00e9s dans un programme, parlons un peu de la repr\u00e9sentation de ceux-ci en binaire. Un ordinateur fonctionne \u00e0 l'\u00e9lectricit\u00e9. Or, l'\u00e9lectricit\u00e9 n'a pas d'autre possibilit\u00e9 de varier qu'entre deux \u00e9tats : il y a du courant (0), ou il n'y en a pas (1). Ces valeurs binaires, 0 et 1 , sont les bits , pour binary digits en anglais. Bien s\u00fbr, limiter un ordinateur \u00e0 compter jusqu'\u00e0 1 serait inutile pour des calculs scientifiques complexes ! Il devient plus int\u00e9ressant de grouper les bits pour obtenir des nombres plus grands. Revenons sur la fa\u00e7on dont nous comptons en tant qu'humains. Tout syst\u00e8me de calcul utilise ce qu'on appelle une base, qui d\u00e9finit - pour simplifier au maximum - \u00e0 partir de quand on ajoute une puissance. Concr\u00e8tement, prenons l'exemple de la base 10 que nous utilisons quotidiennement. Nous avons dix chiffres - dix, comme la base donc - allant de 0 \u00e0 9. Puis, pour passer \u00e0 la valeur apr\u00e8s 9, nous ajoutons une puissance : la dizaine. On passe alors de 9 \u00e0 10, un nombre constitu\u00e9 de deux chiffres. Nous restons \u00e0 deux chiffres jusqu'\u00e0 99 o\u00f9, pour passer \u00e0 la valeur suivante, nous ajoutons encore une puissance : la centaine. Voici le sch\u00e9ma que nous obtenons : 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [...] 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 [...] 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 .... Maintenant, appliquons le m\u00eame principe dans le cas o\u00f9 nous ne pouvons plus compter jusqu'\u00e0 9 mais uniquement jusqu'\u00e0 1 avant d'augmenter la puissance. C'est-\u00e0-dire que nous nous comptons en base 2, puisque nous n'avons droit qu'\u00e0 deux chiffres : 0 et 1. D\u00e8s que nous voudrons compter apr\u00e8s 1, il faudra alors ajouter une puissance ! Nous obtiendons (10) 2 , puis (11) 2 , puis (100) 2 , (101) 2 , etc... Voici les nombres allant de 0 \u00e0 15 en binaire : 0 1 10 11 100 101 110 111 1000 1001 1010 1011 1100 1101 1110 1111 Remarques Les nombres pairs finissent toujours par 0 et les nombres impairs par 1. Pour distinguer un nombre \u00e9crit dans une base autre que la base 10, nous l'\u00e9crivons entre parenth\u00e8ses avec la base en indice. Pour conna\u00eetre le nombre de valeurs codables sur un groupe de bits, on utilise tout simplement la formule 2 n (2 \u00e0 la puissance n ) o\u00f9 n est le nombre de bits. Par exemple, pour savoir combien de valeur nous pouvons coder sur 2 bits, nous calculons 2 2 = 4. En effet, nous pouvons coder les valeurs suivantes : 0 ( 00 ), 1 ( 01 ), (10) 2 et (11) 2 .","title":"Le binaire"},{"location":"bases/data/types/booleans/","text":"Les bool\u00e9ens Les bool\u00e9ens sont un dernier type de donn\u00e9es de base utilisable dans un programme, assez peu connus sous ce nom en dehors de l'informatique principalement. Il s'agit du type de donn\u00e9es pouvant avoir seulement deux valeurs, celles de v\u00e9rit\u00e9 de la logique \u00e0 savoir VRAI ou FAUX . Les bool\u00e9ens doivent leur nom au logicien, math\u00e9maticien et philosophe britannique George Bool . Pour un calcul math\u00e9matique, nous utilisons des op\u00e9rateurs tels que l'addition ou la multiplication. Avec les bool\u00e9ens, nous pouvons \u00e9galement utiliser des op\u00e9rateurs logiques. On peut alors parler d' alg\u00e8bre bool\u00e9enne . Puisque les bool\u00e9ens ne peuvent prendre que deux valeurs, VRAI ou FAUX, ils sont tr\u00e8s simples \u00e0 repr\u00e9senter pour un ordinateur. Le bit 0 repr\u00e9sente FAUX, le bit 1 vaudra VRAI. Remarque sur la taille d'un bool\u00e9en Les bool\u00e9ens ne peuvent prendre que deux valeurs possibles, VRAI ou FAUX. Ils pourraient donc se coder sur un seul bit. Cependant, la plus petite unit\u00e9 utilisable et adressable par un ordinateur contemporain est l' octet . Les bool\u00e9ens sont donc cod\u00e9s sur 8 bits bien qu'ils n'en utilisent qu'un seul. Nous l'avons vu plus t\u00f4t, la m\u00e9moire RAM en particulier est compos\u00e9e de cases m\u00e9moires faisant chacune un octet (8 bits). Les donn\u00e9es qu'elle stocke doivent donc \u00eatre r\u00e9parties sur des multiples de 8 bits, des octets donc, pour \u00eatre adressables. D'autres contraintes mat\u00e9rielles pour l'optimisation des performances entrent \u00e9galement en jeu comme l' alignement en m\u00e9moire . Op\u00e9rateurs logiques Quant aux op\u00e9rateurs logiques, nous en avons plusieurs : ET (AND) : le r\u00e9sultat n'est VRAI que si toutes les valeurs sont VRAIES ; OU (OR) : le r\u00e9sultat est VRAI si au moins une des valeurs est VRAIE ; NON (NOT) : le r\u00e9sultat est l'inverse de la valeur initiale (le VRAI devient FAUX et vice versa) ; OU EXCLUSIF (XOR) : le r\u00e9sultat est VRAI si une et une seule des deux valeurs est VRAIE. Il est possible de dresser un tableau r\u00e9capitulatif. a b NON a NON b a ET b a OU b a XOR b 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0 Exemples en fran\u00e7ais Exemple avec ET Je pourrai acheter du pain si la boulangerie est ouverte ET que j'ai assez de monnaie . Ici on comprend bien que les deux conditions doivent \u00eatre remplies. Si la boulangerie est ouverte mais qu'on n'a pas assez d'argent, on ne pourra pas acheter le pain. De m\u00eame si on a suffisamment de monnaie mais que la boulangerie est, h\u00e9las, d\u00e9j\u00e0 ferm\u00e9e. Exemple avec OU Pour rentrer chez moi, je peux prendre le bus de la ligne 28 OU le tramway . Deux choix possibles s'offrent \u00e0 cette personne. Qu'importe le moyen choisi, elle pourra rentrer chez elle m\u00eame si les deux arrivent en m\u00eame temps. Ouf, nous voil\u00e0 rassur\u00e9s ! Exemple avec OU EXCLUSIF Mince, je n'ai plus assez d'argent sur moi. Je dois choisir entre les bonbons OU les biscuits . Ici aussi, on a deux choix. Cependant, il sera impossible de satisfaire les deux \u00e0 la fois. On ne rentrera \u00e0 la maison que soit avec le paquet de bonbons, soit celui de biscuits. Comment obtenir des bool\u00e9ens en informatique ? La premi\u00e8re fa\u00e7on d'avoir une valeur bool\u00e9enne en informatique est tout simplement de l'\u00e9crire comme \u00e9tant VRAIE ou FAUSSE. Mais c'est loin d'\u00eatre la seule ! Au-del\u00e0 de l'utilisation des op\u00e9rateurs logiques que nous venons de voir, l'ordinateur est aussi apte \u00e0 faire des comparaisons entre deux nombres. Ainsi, si on demande \u00e0 savoir si 2 est strictement inf\u00e9rieur \u00e0 3, on pourra r\u00e9cup\u00e9rer VRAI. A l'inverse, si on veut savoir si 1/3 est sup\u00e9rieur ou \u00e9gal \u00e0 Pi, il nous indiquera FAUX. Etant donn\u00e9 que le texte se base sur des associations entre les caract\u00e8res et des nombres, l'ordinateur est l\u00e0 encore capable de v\u00e9rifier si deux textes sont identiques : il v\u00e9rifiera que chaque lettre est, une \u00e0 une, identique \u00e0 position \u00e9gale entre les deux cha\u00eenes de caract\u00e8res. Si on prend les deux paronymes douceur et douleur , tous deux contiennent le m\u00eame nombre de lettres. Cependant, si le d\u00e9but est identique, ils se diff\u00e9rencient \u00e0 la quatri\u00e8me lettre : l'un contient un c quand l'autre contient un l . Les deux lettres n'ont pas la m\u00eame valeur num\u00e9rique pour l'ordinateur, les mots sont donc diff\u00e9rents. A noter que la comparaison entre deux anagrammes donnera FAUX car les lettres, bien qu'identiques mais m\u00e9lang\u00e9es, ne sont pas \u00e0 la m\u00eame position. Ainsi imaginer et migraine seront bien vus comme deux mots diff\u00e9rents d\u00e8s la premi\u00e8re lettre : i et m ne sont pas les m\u00eames caract\u00e8res ! Remarque sur la sensibilit\u00e9 \u00e0 la casse Dans un programme informatique, comparer deux mots identiques mais \u00e9crits avec une casse diff\u00e9rente (majuscule ou minuscule) donnera FAUX. En effet, le code associ\u00e9 \u00e0 une lettre en majuscule est diff\u00e9rent de celui pour la m\u00eame lettre en minuscule. Le caract\u00e8re A est diff\u00e9rent du caract\u00e8re a pour un ordinateur ! On parle de sensibilit\u00e9 \u00e0 la casse , ou case sensitivity en anglais. Pour s'affranchir de cette diff\u00e9rence si on en a besoin, on pourra basculer les textes \u00e0 comparer tout en minuscules, par exemple, avant de v\u00e9rifier s'ils sont identiques. Les syst\u00e8mes d'exploitation Microsoft Windows appliquent cette solution pour les chemins des fichiers : on peut les \u00e9crire aussi bien avec ou sans les majuscules. A l'inverse, les syst\u00e8mes comme Linux sont, eux, sensibles \u00e0 la casse.","title":"Les bool\u00e9ens"},{"location":"bases/data/types/booleans/#les-booleens","text":"Les bool\u00e9ens sont un dernier type de donn\u00e9es de base utilisable dans un programme, assez peu connus sous ce nom en dehors de l'informatique principalement. Il s'agit du type de donn\u00e9es pouvant avoir seulement deux valeurs, celles de v\u00e9rit\u00e9 de la logique \u00e0 savoir VRAI ou FAUX . Les bool\u00e9ens doivent leur nom au logicien, math\u00e9maticien et philosophe britannique George Bool . Pour un calcul math\u00e9matique, nous utilisons des op\u00e9rateurs tels que l'addition ou la multiplication. Avec les bool\u00e9ens, nous pouvons \u00e9galement utiliser des op\u00e9rateurs logiques. On peut alors parler d' alg\u00e8bre bool\u00e9enne . Puisque les bool\u00e9ens ne peuvent prendre que deux valeurs, VRAI ou FAUX, ils sont tr\u00e8s simples \u00e0 repr\u00e9senter pour un ordinateur. Le bit 0 repr\u00e9sente FAUX, le bit 1 vaudra VRAI. Remarque sur la taille d'un bool\u00e9en Les bool\u00e9ens ne peuvent prendre que deux valeurs possibles, VRAI ou FAUX. Ils pourraient donc se coder sur un seul bit. Cependant, la plus petite unit\u00e9 utilisable et adressable par un ordinateur contemporain est l' octet . Les bool\u00e9ens sont donc cod\u00e9s sur 8 bits bien qu'ils n'en utilisent qu'un seul. Nous l'avons vu plus t\u00f4t, la m\u00e9moire RAM en particulier est compos\u00e9e de cases m\u00e9moires faisant chacune un octet (8 bits). Les donn\u00e9es qu'elle stocke doivent donc \u00eatre r\u00e9parties sur des multiples de 8 bits, des octets donc, pour \u00eatre adressables. D'autres contraintes mat\u00e9rielles pour l'optimisation des performances entrent \u00e9galement en jeu comme l' alignement en m\u00e9moire .","title":"Les bool\u00e9ens"},{"location":"bases/data/types/booleans/#operateurs-logiques","text":"Quant aux op\u00e9rateurs logiques, nous en avons plusieurs : ET (AND) : le r\u00e9sultat n'est VRAI que si toutes les valeurs sont VRAIES ; OU (OR) : le r\u00e9sultat est VRAI si au moins une des valeurs est VRAIE ; NON (NOT) : le r\u00e9sultat est l'inverse de la valeur initiale (le VRAI devient FAUX et vice versa) ; OU EXCLUSIF (XOR) : le r\u00e9sultat est VRAI si une et une seule des deux valeurs est VRAIE. Il est possible de dresser un tableau r\u00e9capitulatif. a b NON a NON b a ET b a OU b a XOR b 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 0","title":"Op\u00e9rateurs logiques"},{"location":"bases/data/types/booleans/#exemples-en-francais","text":"Exemple avec ET Je pourrai acheter du pain si la boulangerie est ouverte ET que j'ai assez de monnaie . Ici on comprend bien que les deux conditions doivent \u00eatre remplies. Si la boulangerie est ouverte mais qu'on n'a pas assez d'argent, on ne pourra pas acheter le pain. De m\u00eame si on a suffisamment de monnaie mais que la boulangerie est, h\u00e9las, d\u00e9j\u00e0 ferm\u00e9e. Exemple avec OU Pour rentrer chez moi, je peux prendre le bus de la ligne 28 OU le tramway . Deux choix possibles s'offrent \u00e0 cette personne. Qu'importe le moyen choisi, elle pourra rentrer chez elle m\u00eame si les deux arrivent en m\u00eame temps. Ouf, nous voil\u00e0 rassur\u00e9s ! Exemple avec OU EXCLUSIF Mince, je n'ai plus assez d'argent sur moi. Je dois choisir entre les bonbons OU les biscuits . Ici aussi, on a deux choix. Cependant, il sera impossible de satisfaire les deux \u00e0 la fois. On ne rentrera \u00e0 la maison que soit avec le paquet de bonbons, soit celui de biscuits.","title":"Exemples en fran\u00e7ais"},{"location":"bases/data/types/booleans/#comment-obtenir-des-booleens-en-informatique","text":"La premi\u00e8re fa\u00e7on d'avoir une valeur bool\u00e9enne en informatique est tout simplement de l'\u00e9crire comme \u00e9tant VRAIE ou FAUSSE. Mais c'est loin d'\u00eatre la seule ! Au-del\u00e0 de l'utilisation des op\u00e9rateurs logiques que nous venons de voir, l'ordinateur est aussi apte \u00e0 faire des comparaisons entre deux nombres. Ainsi, si on demande \u00e0 savoir si 2 est strictement inf\u00e9rieur \u00e0 3, on pourra r\u00e9cup\u00e9rer VRAI. A l'inverse, si on veut savoir si 1/3 est sup\u00e9rieur ou \u00e9gal \u00e0 Pi, il nous indiquera FAUX. Etant donn\u00e9 que le texte se base sur des associations entre les caract\u00e8res et des nombres, l'ordinateur est l\u00e0 encore capable de v\u00e9rifier si deux textes sont identiques : il v\u00e9rifiera que chaque lettre est, une \u00e0 une, identique \u00e0 position \u00e9gale entre les deux cha\u00eenes de caract\u00e8res. Si on prend les deux paronymes douceur et douleur , tous deux contiennent le m\u00eame nombre de lettres. Cependant, si le d\u00e9but est identique, ils se diff\u00e9rencient \u00e0 la quatri\u00e8me lettre : l'un contient un c quand l'autre contient un l . Les deux lettres n'ont pas la m\u00eame valeur num\u00e9rique pour l'ordinateur, les mots sont donc diff\u00e9rents. A noter que la comparaison entre deux anagrammes donnera FAUX car les lettres, bien qu'identiques mais m\u00e9lang\u00e9es, ne sont pas \u00e0 la m\u00eame position. Ainsi imaginer et migraine seront bien vus comme deux mots diff\u00e9rents d\u00e8s la premi\u00e8re lettre : i et m ne sont pas les m\u00eames caract\u00e8res ! Remarque sur la sensibilit\u00e9 \u00e0 la casse Dans un programme informatique, comparer deux mots identiques mais \u00e9crits avec une casse diff\u00e9rente (majuscule ou minuscule) donnera FAUX. En effet, le code associ\u00e9 \u00e0 une lettre en majuscule est diff\u00e9rent de celui pour la m\u00eame lettre en minuscule. Le caract\u00e8re A est diff\u00e9rent du caract\u00e8re a pour un ordinateur ! On parle de sensibilit\u00e9 \u00e0 la casse , ou case sensitivity en anglais. Pour s'affranchir de cette diff\u00e9rence si on en a besoin, on pourra basculer les textes \u00e0 comparer tout en minuscules, par exemple, avant de v\u00e9rifier s'ils sont identiques. Les syst\u00e8mes d'exploitation Microsoft Windows appliquent cette solution pour les chemins des fichiers : on peut les \u00e9crire aussi bien avec ou sans les majuscules. A l'inverse, les syst\u00e8mes comme Linux sont, eux, sensibles \u00e0 la casse.","title":"Comment obtenir des bool\u00e9ens en informatique ?"},{"location":"bases/data/types/exercises/","text":"Exercices Voici le moment tant redout\u00e9, celui o\u00f9 il va falloir faire chauffer les neurones ! Pour la correction, clique sur \"Corrections\" afin de r\u00e9v\u00e9ler les r\u00e9ponses aux exercices. Je compte sur toi pour ne pas tricher !! Nombres entiers Exercices sur les nombres entiers Calculer la valeur maximale d'un short, d'un integer et d'un long non sign\u00e9s. Calculer les valeurs minimale et maximale d'un short, d'un integer et d'un long sign\u00e9. Repr\u00e9senter en binaire sur un byte les nombres suivants exprim\u00e9s en base 10 : 65, 132, -24. Calculer les valeurs sur un byte non sign\u00e9 (8 bits, toujours positif) suivantes en base 10 : 00000110 , 00011011 , 11110000 , 10110110 Trouver un moyen simple de calculer ces valeurs (indice : la puissance de 2). Calculer les valeurs pr\u00e9c\u00e9dentes sur byte sign\u00e9 (8 bits, pouvant \u00eatre n\u00e9gatif ou positif) en base 10. Allez, un peu d'aide si jamais tu bloques. Aide pour les questions sur les nombres entiers relatifs Une astuce pour trouver les nombres n\u00e9gatifs facilement est d'inverser les bits (les 0 deviennent des 1 et vice versa), calculer le nombre obtenu, y ajouter + 1 et placer le signe n\u00e9gatif. Par exemple, pour (11111001)~2 : On inverse les bits : (00000110) 2 ; On calcule la valeur en base 10 : on obtient 6 en base 10 ; On l'incr\u00e9mente pour obtenir 7 ; On n'oublie pas le signe (-), ce qui donne la solution recherch\u00e9e de -7 en base 10 ! Corrections des exercices sur les nombres entiers Calculer la valeur maximale d'un short, d'un integer et d'un long non sign\u00e9s. Un short non sign\u00e9 occupe 2 octets, soit 16 bits. Il peut coder les nombres allant de 0 \u00e0 2 16 - 1 = 65 535 . Un integer non sign\u00e9 occupe 4 octets, soit 32 bits. Il peut coder les nombres allant de 0 \u00e0 2 32 - 1 = 4 294 967 295 . Un long non sign\u00e9 occupe 8 octets, soit 64 bits. Il peut coder les nombres allant de 0 \u00e0 2 64 - 1 = 18 446 744 073 709 551 615 . Calculer les valeurs minimale et maximale d'un short, d'un integer et d'un long sign\u00e9. Un short sign\u00e9 occupe 2 octets, soit 16 bits. Il peut coder les nombres allant de -2 15 = -32 768 \u00e0 2 15 - 1 = 32 767 . Un integer sign\u00e9 occupe 4 octets, soit 32 bits. Il peut coder les nombres allant de -2 31 = -2 147 483 648 \u00e0 2 31 - 1 = 2 147 483 647 . Un long sign\u00e9 occupe 8 octets, soit 64 bits. Il peut coder les nombres allant de -2 63 = -9 223 372 036 854 775 808 \u00e0 2 63 - 1 = 9 223 372 036 854 775 807 . Repr\u00e9senter en binaire sur un byte les nombres suivants exprim\u00e9s en base 10 : 65, 132, -24. 65 = (01000001) 2 132 = (10000100) 2 (byte non sign\u00e9) -24 = (11101000) 2 Calculer les valeurs sur un byte non sign\u00e9 (8 bits, toujours positif) suivantes en base 10 : 00000110 , 00011011 , 11110000 , 10110110 (00000110) 2 = 6 (00011011) 2 = 27 (11110000) 2 = 240 (10110110) 2 = 182 Trouver un moyen simple de calculer ces valeurs (indice : la puissance de 2). On attribue une position p \u00e0 chaque bit, en partant de 0 pour le bit le plus \u00e0 droite jusqu'\u00e0 7 pour le bit le plus \u00e0 gauche. On fait la somme des 2 p 1 pour les positions p 1 o\u00f9 le bit vaut 1 afin d'obtenir la valeur du nombre en d\u00e9cimal. Dans le cas de (00011011) 2 , les bits \u00e0 1 sont en positions 0, 1, 3 et 4. On calcule donc 2 0 + 2 1 + 2 3 + 2 4 = 1 + 2 + 8 + 16 = 27 . Calculer les valeurs pr\u00e9c\u00e9dentes sur byte sign\u00e9 (8 bits, pouvant \u00eatre n\u00e9gatif ou positif) en base 10. (00000110) 2 = 6 (00011011) 2 = 27 (11110000) 2 = -16 (10110110) 2 = -74 Logique bool\u00e9enne Exercices sur la logique bool\u00e9enne Pour chaque combinaison de valeur des bool\u00e9ens a, b et c, donne le r\u00e9sultat de l'op\u00e9ration logique suivante : a ET (b OU NON c) Pour chaque combinaison de valeur des bool\u00e9ens a, b et c, donne le r\u00e9sultat de l'op\u00e9ration logique suivante : a XOR (b XOR c) Pour chaque combinaison de valeur des bool\u00e9ens a, b et c, donne le r\u00e9sultat de l'op\u00e9ration logique suivante : (a ET b) XOR NON(b OU c) Dans la question pr\u00e9c\u00e9dente, compare le r\u00e9sultat de NON(b OU c) avec NON(b) ET NON(c) . Que peux-tu en d\u00e9duire ? Aide pour les op\u00e9rations logiques complexes Proc\u00e8de par \u00e9tape ! Corrections des exercices sur la logique bool\u00e9enne Pour chaque combinaison de valeur des bool\u00e9ens a, b et c, donne le r\u00e9sultat de l'op\u00e9ration logique suivante : a ET (b OU NON c) a b c NON c b OU NON c a ET (b OU NON c) 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 Pour chaque combinaison de valeur des bool\u00e9ens a, b et c, donne le r\u00e9sultat de l'op\u00e9ration logique suivante : a XOR (b XOR c) a b c b XOR c a XOR (b XOR c) NOT(a XOR (b XOR c)) 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 Pour chaque combinaison de valeur des bool\u00e9ens a, b et c, donne le r\u00e9sultat de l'op\u00e9ration logique suivante : (a ET b) XOR NON(b OU c) a b c b OU c NON(b OU c) (a ET b) (a ET b) XOR NON(b OU c) 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 Dans la question pr\u00e9c\u00e9dente, compare le r\u00e9sultat de NON(b OU c) avec NON(b) ET NON(c) . Que peux-tu en d\u00e9duire ? b c NON(b) NON(c) NON(b) ET NON(c) NON(b OU c) 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 Le r\u00e9sultat obtenu est identique pour NON(b OU c) et NON(b) ET NON(c) . On peut en conclure que la n\u00e9gation de la proposition b OU c est proposition NON b ET NON c .","title":"Exercices"},{"location":"bases/data/types/exercises/#exercices","text":"Voici le moment tant redout\u00e9, celui o\u00f9 il va falloir faire chauffer les neurones ! Pour la correction, clique sur \"Corrections\" afin de r\u00e9v\u00e9ler les r\u00e9ponses aux exercices. Je compte sur toi pour ne pas tricher !!","title":"Exercices"},{"location":"bases/data/types/exercises/#nombres-entiers","text":"Exercices sur les nombres entiers Calculer la valeur maximale d'un short, d'un integer et d'un long non sign\u00e9s. Calculer les valeurs minimale et maximale d'un short, d'un integer et d'un long sign\u00e9. Repr\u00e9senter en binaire sur un byte les nombres suivants exprim\u00e9s en base 10 : 65, 132, -24. Calculer les valeurs sur un byte non sign\u00e9 (8 bits, toujours positif) suivantes en base 10 : 00000110 , 00011011 , 11110000 , 10110110 Trouver un moyen simple de calculer ces valeurs (indice : la puissance de 2). Calculer les valeurs pr\u00e9c\u00e9dentes sur byte sign\u00e9 (8 bits, pouvant \u00eatre n\u00e9gatif ou positif) en base 10. Allez, un peu d'aide si jamais tu bloques. Aide pour les questions sur les nombres entiers relatifs Une astuce pour trouver les nombres n\u00e9gatifs facilement est d'inverser les bits (les 0 deviennent des 1 et vice versa), calculer le nombre obtenu, y ajouter + 1 et placer le signe n\u00e9gatif. Par exemple, pour (11111001)~2 : On inverse les bits : (00000110) 2 ; On calcule la valeur en base 10 : on obtient 6 en base 10 ; On l'incr\u00e9mente pour obtenir 7 ; On n'oublie pas le signe (-), ce qui donne la solution recherch\u00e9e de -7 en base 10 ! Corrections des exercices sur les nombres entiers Calculer la valeur maximale d'un short, d'un integer et d'un long non sign\u00e9s. Un short non sign\u00e9 occupe 2 octets, soit 16 bits. Il peut coder les nombres allant de 0 \u00e0 2 16 - 1 = 65 535 . Un integer non sign\u00e9 occupe 4 octets, soit 32 bits. Il peut coder les nombres allant de 0 \u00e0 2 32 - 1 = 4 294 967 295 . Un long non sign\u00e9 occupe 8 octets, soit 64 bits. Il peut coder les nombres allant de 0 \u00e0 2 64 - 1 = 18 446 744 073 709 551 615 . Calculer les valeurs minimale et maximale d'un short, d'un integer et d'un long sign\u00e9. Un short sign\u00e9 occupe 2 octets, soit 16 bits. Il peut coder les nombres allant de -2 15 = -32 768 \u00e0 2 15 - 1 = 32 767 . Un integer sign\u00e9 occupe 4 octets, soit 32 bits. Il peut coder les nombres allant de -2 31 = -2 147 483 648 \u00e0 2 31 - 1 = 2 147 483 647 . Un long sign\u00e9 occupe 8 octets, soit 64 bits. Il peut coder les nombres allant de -2 63 = -9 223 372 036 854 775 808 \u00e0 2 63 - 1 = 9 223 372 036 854 775 807 . Repr\u00e9senter en binaire sur un byte les nombres suivants exprim\u00e9s en base 10 : 65, 132, -24. 65 = (01000001) 2 132 = (10000100) 2 (byte non sign\u00e9) -24 = (11101000) 2 Calculer les valeurs sur un byte non sign\u00e9 (8 bits, toujours positif) suivantes en base 10 : 00000110 , 00011011 , 11110000 , 10110110 (00000110) 2 = 6 (00011011) 2 = 27 (11110000) 2 = 240 (10110110) 2 = 182 Trouver un moyen simple de calculer ces valeurs (indice : la puissance de 2). On attribue une position p \u00e0 chaque bit, en partant de 0 pour le bit le plus \u00e0 droite jusqu'\u00e0 7 pour le bit le plus \u00e0 gauche. On fait la somme des 2 p 1 pour les positions p 1 o\u00f9 le bit vaut 1 afin d'obtenir la valeur du nombre en d\u00e9cimal. Dans le cas de (00011011) 2 , les bits \u00e0 1 sont en positions 0, 1, 3 et 4. On calcule donc 2 0 + 2 1 + 2 3 + 2 4 = 1 + 2 + 8 + 16 = 27 . Calculer les valeurs pr\u00e9c\u00e9dentes sur byte sign\u00e9 (8 bits, pouvant \u00eatre n\u00e9gatif ou positif) en base 10. (00000110) 2 = 6 (00011011) 2 = 27 (11110000) 2 = -16 (10110110) 2 = -74","title":"Nombres entiers"},{"location":"bases/data/types/exercises/#logique-booleenne","text":"Exercices sur la logique bool\u00e9enne Pour chaque combinaison de valeur des bool\u00e9ens a, b et c, donne le r\u00e9sultat de l'op\u00e9ration logique suivante : a ET (b OU NON c) Pour chaque combinaison de valeur des bool\u00e9ens a, b et c, donne le r\u00e9sultat de l'op\u00e9ration logique suivante : a XOR (b XOR c) Pour chaque combinaison de valeur des bool\u00e9ens a, b et c, donne le r\u00e9sultat de l'op\u00e9ration logique suivante : (a ET b) XOR NON(b OU c) Dans la question pr\u00e9c\u00e9dente, compare le r\u00e9sultat de NON(b OU c) avec NON(b) ET NON(c) . Que peux-tu en d\u00e9duire ? Aide pour les op\u00e9rations logiques complexes Proc\u00e8de par \u00e9tape ! Corrections des exercices sur la logique bool\u00e9enne Pour chaque combinaison de valeur des bool\u00e9ens a, b et c, donne le r\u00e9sultat de l'op\u00e9ration logique suivante : a ET (b OU NON c) a b c NON c b OU NON c a ET (b OU NON c) 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 Pour chaque combinaison de valeur des bool\u00e9ens a, b et c, donne le r\u00e9sultat de l'op\u00e9ration logique suivante : a XOR (b XOR c) a b c b XOR c a XOR (b XOR c) NOT(a XOR (b XOR c)) 0 0 0 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 0 Pour chaque combinaison de valeur des bool\u00e9ens a, b et c, donne le r\u00e9sultat de l'op\u00e9ration logique suivante : (a ET b) XOR NON(b OU c) a b c b OU c NON(b OU c) (a ET b) (a ET b) XOR NON(b OU c) 0 0 0 0 1 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 Dans la question pr\u00e9c\u00e9dente, compare le r\u00e9sultat de NON(b OU c) avec NON(b) ET NON(c) . Que peux-tu en d\u00e9duire ? b c NON(b) NON(c) NON(b) ET NON(c) NON(b OU c) 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 Le r\u00e9sultat obtenu est identique pour NON(b OU c) et NON(b) ET NON(c) . On peut en conclure que la n\u00e9gation de la proposition b OU c est proposition NON b ET NON c .","title":"Logique bool\u00e9enne"},{"location":"bases/data/types/floating/","text":"Les nombres \u00e0 virgule flottante Les nombres entiers permettent des calculs basiques sur un ordinateur mais d'autres nombres sont tr\u00e8s utilis\u00e9s \u00e9galement, les nombres \u00e0 virgule . Il existe deux types de nombres \u00e0 virgule : les simples (ou float ) qui occupent 4 octets ; les doubles qui occupent 8 octets. Plus il y a d'octets, plus le nombre sera pr\u00e9cis : il pourra repr\u00e9senter plus de chiffres fiables apr\u00e8s la virgule. G\u00e9n\u00e9ralement, on consid\u00e8re pouvoir aller jusqu'\u00e0 environ 6-7 chiffres apr\u00e8s la virgule de fa\u00e7on fiable avec un float, et jusqu'\u00e0 13-16 chiffres apr\u00e8s la virgule pour un double. Au-del\u00e0, il commence \u00e0 y avoir une trop grande impr\u00e9cision et on n\u00e9glige les chiffres suivants. Par exemple, pour un float valant 3.14159266712, on arrondira \u00e0 3.1415926 car les chiffres suivants sont faux pour la valeur du nombre Pi. Leur repr\u00e9sentation binaire est plus complexe \u00e0 comprendre et \u00e0 calculer que pour les nombres entiers. Cependant, repr\u00e9senter un nombre \u00e0 virgule en binaire n'a rien d'\u00e9vident. A l'int\u00e9rieur de la repr\u00e9sentation binaire d'un nombre \u00e0 virgule flottante, on retrouve trois \u00e9l\u00e9ments : le signe, la mantisse et l'exposant. Tous ces \u00e9l\u00e9ments peuvent \u00eatre eux-m\u00eames repr\u00e9sent\u00e9s par des nombres entiers, ce qui fonctionne bien avec le binaire comme nous l'avons vu juste avant ! L'exposant est l\u00e0 pour positionner la virgule \u00e0 l'int\u00e9rieur de la mantisse et donne tout son sens au qualificatif de virgule \"flottante\". La norme IEEE 754 d\u00e9finit le nombre de bits occup\u00e9s par chacun de ces \u00e9l\u00e9ments pour les floats et pour les doubles.","title":"Les nombres \u00e0 virgule flottante"},{"location":"bases/data/types/floating/#les-nombres-a-virgule-flottante","text":"Les nombres entiers permettent des calculs basiques sur un ordinateur mais d'autres nombres sont tr\u00e8s utilis\u00e9s \u00e9galement, les nombres \u00e0 virgule . Il existe deux types de nombres \u00e0 virgule : les simples (ou float ) qui occupent 4 octets ; les doubles qui occupent 8 octets. Plus il y a d'octets, plus le nombre sera pr\u00e9cis : il pourra repr\u00e9senter plus de chiffres fiables apr\u00e8s la virgule. G\u00e9n\u00e9ralement, on consid\u00e8re pouvoir aller jusqu'\u00e0 environ 6-7 chiffres apr\u00e8s la virgule de fa\u00e7on fiable avec un float, et jusqu'\u00e0 13-16 chiffres apr\u00e8s la virgule pour un double. Au-del\u00e0, il commence \u00e0 y avoir une trop grande impr\u00e9cision et on n\u00e9glige les chiffres suivants. Par exemple, pour un float valant 3.14159266712, on arrondira \u00e0 3.1415926 car les chiffres suivants sont faux pour la valeur du nombre Pi. Leur repr\u00e9sentation binaire est plus complexe \u00e0 comprendre et \u00e0 calculer que pour les nombres entiers. Cependant, repr\u00e9senter un nombre \u00e0 virgule en binaire n'a rien d'\u00e9vident. A l'int\u00e9rieur de la repr\u00e9sentation binaire d'un nombre \u00e0 virgule flottante, on retrouve trois \u00e9l\u00e9ments : le signe, la mantisse et l'exposant. Tous ces \u00e9l\u00e9ments peuvent \u00eatre eux-m\u00eames repr\u00e9sent\u00e9s par des nombres entiers, ce qui fonctionne bien avec le binaire comme nous l'avons vu juste avant ! L'exposant est l\u00e0 pour positionner la virgule \u00e0 l'int\u00e9rieur de la mantisse et donne tout son sens au qualificatif de virgule \"flottante\". La norme IEEE 754 d\u00e9finit le nombre de bits occup\u00e9s par chacun de ces \u00e9l\u00e9ments pour les floats et pour les doubles.","title":"Les nombres \u00e0 virgule flottante"},{"location":"bases/data/types/integers/","text":"Les nombres entiers naturels Un groupe de bits tr\u00e8s connu est l' octet . Comme son nom l'indique, il s'agit d'un groupe de 8 bits. Par exemple, le nombre 157 peut \u00eatre repr\u00e9sent\u00e9 en binaire par (10011101) 2 . Au total, un octet permet de repr\u00e9senter 2 8 = 256 valeurs diff\u00e9rentes dont le 0. Cela commence \u00e0 devenir plus amusant pour programmer ! Cependant, \u00e7a reste encore tr\u00e8s peu pour faire de gros calculs math\u00e9matiques ! Alors on peut grouper les octets par paquets eux aussi, chacun avec leur nom. Voici la liste des groupements d'octets, appel\u00e9s types , g\u00e9n\u00e9ralement utilisables dans les langages informatiques : le byte (1 octet = 8 bits) ; le short (2 octets = 16 bits) ; le integer (4 octets = 32 bits) ; le long (8 octets = 64 bits). La valeur maximale d'un nombre entier naturel est de 2 n - 1, o\u00f9 n est le nombre de bits utilis\u00e9s pour le coder. Remarque En utilisant la base 2, un ordinateur utilise toujours des nombres d'octets et de bits qui sont des puissances de 2 ! Nous venons de voir comment coder des nombres entiers naturels sur un ordinateur. Ils sont toujours positifs ou nuls et donc n'ont pas besoin d'un signe devant eux. En informatique, on parle de types non sign\u00e9s pour cette raison. Une question pourrait toutefois nous venir \u00e0 l'esprit : pourquoi donc avons nous des nombres qui sont repr\u00e9sent\u00e9s sur un certain nombre d'octets ? Apr\u00e8s tout, le langage binaire permet de repr\u00e9senter toute l'infinit\u00e9 des nombres entiers au m\u00eame titre que notre base 10 habituelle. Et bien, il se trouve que le processeur - le \"cerveau\" de l'ordinateur - utilise de petites cases de m\u00e9moire pour ses calculs. Or, cette m\u00e9moire a une taille extr\u00eamement limit\u00e9e. Nous avons tous d\u00e9j\u00e0 entendu parl\u00e9 de processeurs 32 et 64 bits. Ce nombre de bits fait r\u00e9f\u00e9rence \u00e0 la taille des petites cases de m\u00e9moire \u00e0 l'int\u00e9rieur du processeur pour stocker des nombres entiers. Cela a un impact assez inattendu sur certains calculs qu'on appelle le d\u00e9passement d'entier . Prenons un byte non sign\u00e9 (8 bits) valant 11111111 . C'est la valeur maximale qu'il peut prendre, autrement dit 255 en base 10. Que se passe-t-il si nous lui additionnons 1 ? Nous devrions obtenir 100000000 qui ajoute un neuvi\u00e8me bit, mais ce n'est pas possible puisque notre byte ne peut contenir que 8 bits ! La retenue est donc tronqu\u00e9e et nous revenons \u00e0 00000000 , soit 0 en base 10. Et oui, comme tout compteur tel que dans une voiture ou un compteur d'eau, la limitation dans la taille des chiffres implique un retour \u00e0 z\u00e9ro \u00e0 cause du d\u00e9passement d'entier. Pour une voiture qui arriverait \u00e0 999 999km, son compteur retomberait \u00e0 0km apr\u00e8s le prochain kilom\u00e8tre parcouru tout simplement parce que ce compteur n'a que 6 chiffres ! Et les nombres entiers relatifs ? Un autre souci se pose : dans nos calculs, nous avons des nombres positifs mais parfois aussi n\u00e9gatifs ! On parle alors d'entier relatif en math\u00e9matiques ou de type sign\u00e9 en informatique. Or, comment repr\u00e9senter un nombre n\u00e9gatif avec uniquement des 0 et des 1 ? Justement, si un bit est capable de repr\u00e9senter deux \u00e9tats, il est \u00e9galement possible de repr\u00e9senter deux signes possibles pour un nombre : le signe positif et le signe n\u00e9gatif. Un peu comme nous pla\u00e7ons le signe (-) devant un nombre n\u00e9gatif, nous utilisons le bit de poids fort pour indiquer le signe d'un nombre en binaire. Le bit de poids fort est le bit le plus \u00e0 gauche d'un byte, short, integer ou long : Si le bit de poids fort vaut 0, le nombre est positif ; Si le bit de poids fort vaut 1, le nombre est n\u00e9gatif. Cependant, si nous utilisons un bit pour repr\u00e9senter le signe, il ne peut plus servir \u00e0 obtenir des valeurs aussi grandes qu'avant ! De fait, un type de nombres entiers sign\u00e9 ne peut pas repr\u00e9senter tous les nombres positifs disponibles avec le m\u00eame type non sign\u00e9 : Valeur n\u00e9gative minimale = -2 (n-1) ; Valeur positive maximale = 2 (n-1) - 1. Il y a une autre complexit\u00e9 qui s'ajoute. Comme nous l'avons vu pour les nombres entiers naturels, chaque valeur qui se suit est incr\u00e9ment\u00e9e de +1 en binaire. C'est un calcul vraiment tr\u00e8s simple et peu couteux pour le processeur. Il n'est donc pas possible de repr\u00e9senter la valeur -1 par 10000001 puisque si nous incr\u00e9mentons pour passer \u00e0 0, nous obtiendrions 10000010 qui est bien s\u00fbr diff\u00e9rent de 00000000 . Il se trouve que nous avons vu, dans la partie pr\u00e9c\u00e9dente, qu'en ajoutant 1 \u00e0 11111111 , nous revenions \u00e0 00000000 . De fait, nous pouvons en d\u00e9duire que si nous signions cette valeur 11111111 , elle ferait la candidate parfaite pour repr\u00e9senter -1 ! Toujours en pensant \u00e0 la succession des valeurs en binaire, nous obtiendrions -2 avec 11111110 , ainsi de suite jusqu'\u00e0 10000000 (-128 en base 10) en faisant des soustractions de -1 \u00e0 chaque \u00e9tape. Pour r\u00e9sumer, un ordinateur peut coder une quantit\u00e9 finie de valeurs enti\u00e8res sign\u00e9es et non sign\u00e9es . Plus le type contient d'octets (1, 2, 4 ou 8 octets), plus il pourra repr\u00e9senter de valeurs diff\u00e9rentes. Les valeurs sign\u00e9es sont amput\u00e9e de leur bit de poids fort pour repr\u00e9senter le signe et ne peuvent permettre d'avoir un nombre positif aussi grand que les valeurs non sign\u00e9es (uniquement positives ou nulles).","title":"Les nombres entiers naturels"},{"location":"bases/data/types/integers/#les-nombres-entiers-naturels","text":"Un groupe de bits tr\u00e8s connu est l' octet . Comme son nom l'indique, il s'agit d'un groupe de 8 bits. Par exemple, le nombre 157 peut \u00eatre repr\u00e9sent\u00e9 en binaire par (10011101) 2 . Au total, un octet permet de repr\u00e9senter 2 8 = 256 valeurs diff\u00e9rentes dont le 0. Cela commence \u00e0 devenir plus amusant pour programmer ! Cependant, \u00e7a reste encore tr\u00e8s peu pour faire de gros calculs math\u00e9matiques ! Alors on peut grouper les octets par paquets eux aussi, chacun avec leur nom. Voici la liste des groupements d'octets, appel\u00e9s types , g\u00e9n\u00e9ralement utilisables dans les langages informatiques : le byte (1 octet = 8 bits) ; le short (2 octets = 16 bits) ; le integer (4 octets = 32 bits) ; le long (8 octets = 64 bits). La valeur maximale d'un nombre entier naturel est de 2 n - 1, o\u00f9 n est le nombre de bits utilis\u00e9s pour le coder. Remarque En utilisant la base 2, un ordinateur utilise toujours des nombres d'octets et de bits qui sont des puissances de 2 ! Nous venons de voir comment coder des nombres entiers naturels sur un ordinateur. Ils sont toujours positifs ou nuls et donc n'ont pas besoin d'un signe devant eux. En informatique, on parle de types non sign\u00e9s pour cette raison. Une question pourrait toutefois nous venir \u00e0 l'esprit : pourquoi donc avons nous des nombres qui sont repr\u00e9sent\u00e9s sur un certain nombre d'octets ? Apr\u00e8s tout, le langage binaire permet de repr\u00e9senter toute l'infinit\u00e9 des nombres entiers au m\u00eame titre que notre base 10 habituelle. Et bien, il se trouve que le processeur - le \"cerveau\" de l'ordinateur - utilise de petites cases de m\u00e9moire pour ses calculs. Or, cette m\u00e9moire a une taille extr\u00eamement limit\u00e9e. Nous avons tous d\u00e9j\u00e0 entendu parl\u00e9 de processeurs 32 et 64 bits. Ce nombre de bits fait r\u00e9f\u00e9rence \u00e0 la taille des petites cases de m\u00e9moire \u00e0 l'int\u00e9rieur du processeur pour stocker des nombres entiers. Cela a un impact assez inattendu sur certains calculs qu'on appelle le d\u00e9passement d'entier . Prenons un byte non sign\u00e9 (8 bits) valant 11111111 . C'est la valeur maximale qu'il peut prendre, autrement dit 255 en base 10. Que se passe-t-il si nous lui additionnons 1 ? Nous devrions obtenir 100000000 qui ajoute un neuvi\u00e8me bit, mais ce n'est pas possible puisque notre byte ne peut contenir que 8 bits ! La retenue est donc tronqu\u00e9e et nous revenons \u00e0 00000000 , soit 0 en base 10. Et oui, comme tout compteur tel que dans une voiture ou un compteur d'eau, la limitation dans la taille des chiffres implique un retour \u00e0 z\u00e9ro \u00e0 cause du d\u00e9passement d'entier. Pour une voiture qui arriverait \u00e0 999 999km, son compteur retomberait \u00e0 0km apr\u00e8s le prochain kilom\u00e8tre parcouru tout simplement parce que ce compteur n'a que 6 chiffres !","title":"Les nombres entiers naturels"},{"location":"bases/data/types/integers/#et-les-nombres-entiers-relatifs","text":"Un autre souci se pose : dans nos calculs, nous avons des nombres positifs mais parfois aussi n\u00e9gatifs ! On parle alors d'entier relatif en math\u00e9matiques ou de type sign\u00e9 en informatique. Or, comment repr\u00e9senter un nombre n\u00e9gatif avec uniquement des 0 et des 1 ? Justement, si un bit est capable de repr\u00e9senter deux \u00e9tats, il est \u00e9galement possible de repr\u00e9senter deux signes possibles pour un nombre : le signe positif et le signe n\u00e9gatif. Un peu comme nous pla\u00e7ons le signe (-) devant un nombre n\u00e9gatif, nous utilisons le bit de poids fort pour indiquer le signe d'un nombre en binaire. Le bit de poids fort est le bit le plus \u00e0 gauche d'un byte, short, integer ou long : Si le bit de poids fort vaut 0, le nombre est positif ; Si le bit de poids fort vaut 1, le nombre est n\u00e9gatif. Cependant, si nous utilisons un bit pour repr\u00e9senter le signe, il ne peut plus servir \u00e0 obtenir des valeurs aussi grandes qu'avant ! De fait, un type de nombres entiers sign\u00e9 ne peut pas repr\u00e9senter tous les nombres positifs disponibles avec le m\u00eame type non sign\u00e9 : Valeur n\u00e9gative minimale = -2 (n-1) ; Valeur positive maximale = 2 (n-1) - 1. Il y a une autre complexit\u00e9 qui s'ajoute. Comme nous l'avons vu pour les nombres entiers naturels, chaque valeur qui se suit est incr\u00e9ment\u00e9e de +1 en binaire. C'est un calcul vraiment tr\u00e8s simple et peu couteux pour le processeur. Il n'est donc pas possible de repr\u00e9senter la valeur -1 par 10000001 puisque si nous incr\u00e9mentons pour passer \u00e0 0, nous obtiendrions 10000010 qui est bien s\u00fbr diff\u00e9rent de 00000000 . Il se trouve que nous avons vu, dans la partie pr\u00e9c\u00e9dente, qu'en ajoutant 1 \u00e0 11111111 , nous revenions \u00e0 00000000 . De fait, nous pouvons en d\u00e9duire que si nous signions cette valeur 11111111 , elle ferait la candidate parfaite pour repr\u00e9senter -1 ! Toujours en pensant \u00e0 la succession des valeurs en binaire, nous obtiendrions -2 avec 11111110 , ainsi de suite jusqu'\u00e0 10000000 (-128 en base 10) en faisant des soustractions de -1 \u00e0 chaque \u00e9tape. Pour r\u00e9sumer, un ordinateur peut coder une quantit\u00e9 finie de valeurs enti\u00e8res sign\u00e9es et non sign\u00e9es . Plus le type contient d'octets (1, 2, 4 ou 8 octets), plus il pourra repr\u00e9senter de valeurs diff\u00e9rentes. Les valeurs sign\u00e9es sont amput\u00e9e de leur bit de poids fort pour repr\u00e9senter le signe et ne peuvent permettre d'avoir un nombre positif aussi grand que les valeurs non sign\u00e9es (uniquement positives ou nulles).","title":"Et les nombres entiers relatifs ?"},{"location":"bases/data/types/texts/","text":"Des chiffres et des lettres L'ordinateur - et avant lui le calculateur - a \u00e9t\u00e9 con\u00e7u par l'humain pour effectuer des calculs longs et r\u00e9p\u00e9titifs \u00e0 sa place et plus rapidement. Il est donc tout naturel de penser \u00e0 lui fournir des valeurs num\u00e9riques pour faire ces calculs. Avec l'expansion de son utilisation, les nombres n'ont plus suffit et le texte est devenu une n\u00e9cessit\u00e9, ne serait-ce que pour qu'un programme demande des choses \u00e0 l'utilisateur. Une nouvelle fois, le probl\u00e8me de la repr\u00e9sentation d'une lettre ou d'un texte complet par un ordinateur se pose quand il ne peut utiliser que des 0 et des 1. Nous avons vu pr\u00e9c\u00e9demment qu'il \u00e9tait possible de repr\u00e9senter plusieurs centaines de nombres entiers sur un octet. Cela repr\u00e9sente bien assez de possibilit\u00e9s pour les lettres de l'alphabet et quelques symboles de ponctuation. Dans les ann\u00e9es 60, la norme ASCII est apparue pour associer des symboles \u00e0 des valeurs num\u00e9riques sur 7 bits, permettant de coder 128 caract\u00e8res diff\u00e9rents : les lettres (minuscules et majuscules), la ponctuation, les signes math\u00e9matiques de base, les dix chiffres et quelques autres symboles imprimables ou non. Pour l'anecdote : depuis les ann\u00e9es 70, les processeurs utilisent des octets (8 bits) et le bit de poids fort d'un caract\u00e8re ASCII est d\u00e9finit \u00e0 0. Cependant, la table ASCII est tr\u00e8s limit\u00e9e puisqu'elle ne permet de repr\u00e9senter que 2 7 = 128 caract\u00e8res diff\u00e9rents. On ne peut pas \u00e9crire convenablement en fran\u00e7ais par exemple car il manque, entre autres, les lettres accentu\u00e9es. Et que dire de langues qui ne s'\u00e9crivent pas avec l'alphabet latin ? Il a donc fallu cr\u00e9er une nouvelle association entre nombres et symboles, c'est ainsi que le code UTF-8 s'est peu \u00e0 peu impos\u00e9. Celui-ci reprend la table ASCII pour les 128 premiers caract\u00e8res - ce qui le rend r\u00e9trocompatible - et associe de 2 \u00e0 4 octets pour coder les autres caract\u00e8res utilis\u00e9s dans le monde entier. Il dispose de tellement de possibilit\u00e9s qu'on en utilise certaines pour les emojis ! Les ordinateurs, les programmes et donc les langages de programmation sont tous aptes de nos jours \u00e0 supporter le code UTF-8 pour \u00e9crire du texte. Mais alors qu'on a compris le principe d'association de chaque lettre \u00e0 une valeur num\u00e9rique, comment assembler les lettres pour faire des phrases ? Un texte est repr\u00e9sent\u00e9 par ce qu'on appelle une cha\u00eene de caract\u00e8res par un ordinateur. Le nom est important et trouve son sens dans ce qu'il repr\u00e9sente. Une cha\u00eene du monde r\u00e9el est une succession de maillons les uns \u00e0 la suite des autres. Une cha\u00eene de caract\u00e8res est une succession de caract\u00e8res dans la m\u00e9moire de l'ordinateur. Quand nous \u00e9crivons un mot comme Bonjour , nous pla\u00e7ons le B puis juste \u00e0 c\u00f4t\u00e9 le o , encore \u00e0 c\u00f4t\u00e9 le n , etc. Dans la m\u00e9moire de l'ordinateur, ce sera exactement pareil : o sera plac\u00e9e directement entre B et n . La m\u00e9moire d'un ordinateur Un aparte sur la m\u00e9moire de l'ordinateur dont la m\u00e9moire vive, ou RAM pour Random Access Memory en anglais. Il s'agit d'une succession de petites cases de m\u00e9moire stockant chacune un seul octet. L'ensemble de la m\u00e9moire centrale peut faire plusieurs milliards d'octets de nos jours que nous mesurons de fa\u00e7on plus pratique en gigaoctets (Go). On peut voir chaque petite case m\u00e9moire comme une maison dans une ville immense. Or le processeur doit chercher les donn\u00e9es dans les cases m\u00e9moire durant son fonctionnement. Il a besoin de savoir o\u00f9 est stock\u00e9e une donn\u00e9e pour la r\u00e9cup\u00e9rer et faire ses calculs avec. Comme dans une ville, chaque case m\u00e9moire a une adresse qui lui est propre. Dans la m\u00e9moire, l'adresse est un nombre entier qui s'incr\u00e9mente de 1 pour passer de case en case. Pour r\u00e9cup\u00e9rer une donn\u00e9e, le processeur indique donc l'adresse de la (ou des) case(s) qu'il veut r\u00e9cup\u00e8rer. Dans le cas de notre texte Bonjour (en ASCII, chaque lettre occupant un octet), si la lettre B est stock\u00e9e dans la case m\u00e9moire 1500, la lettre o sera dans la case m\u00e9moire 1501, le n dans la case m\u00e9moire 1502, ainsi de suite. La fin d'un texte Le souci avec ce que nous venons de voir, c'est que le processeur va aller chercher les lettres une \u00e0 une dans les cases successives de la m\u00e9moire centrale. Or, comment peut-il savoir que notre mot Bonjour se termine \u00e0 la lettre r ? Va-t-il continuer \u00e0 chercher d'autres lettres apr\u00e8s le r ? Que se passe-t-il s'il le fait ? Tant de questions auxquelles il est possible de r\u00e9pondre, fort heureusement ! Si notre texte Bonjour \u00e9tait repr\u00e9sent\u00e9 de cette fa\u00e7on dans la m\u00e9moire de l'ordinateur, le processeur n'aurait absolument aucun moyen de s'arr\u00eater quand il le faut et poursuivrait b\u00eatement en parcourant tous les gigaoctets de la RAM ! N'oublions pas que pour lui, tout est binaire, la distinction entre les types de donn\u00e9es est donc impossible. En fait, le processeur n'a qu'une seule et unique fa\u00e7on de s'arr\u00eater de lire une cha\u00eene de caract\u00e8res. Il doit atteindre un caract\u00e8re sp\u00e9cial appel\u00e9 caract\u00e8re NUL (ou \\0 ) qui fait office de drapeau pour signaler la fin d'une cha\u00eene de caract\u00e8res. Le caract\u00e8re NUL porte bien son nom puisqu'il est associ\u00e9 \u00e0 la valeur num\u00e9rique 0 . D\u00e8s qu'il rencontre cette valeur, le processeur sait qu'il doit arr\u00eater la lecture de la cha\u00eene de caract\u00e8res. Les langages de programmation ne nous obligent pas \u00e0 penser \u00e0 mettre ce caract\u00e8re NUL \u00e0 la fin de nos textes car un outil le fait automatiquement pour nous (le caract\u00e8re NUL est cach\u00e9). Sinon cela serait non seulement p\u00e9nible mais aussi source d'innombrables bugs ! Alors que se passerait-il s'il n'y avait pas la caract\u00e8re NUL \u00e0 la fin d'une cha\u00eene ? Comme la m\u00e9moire peut contenir du texte et des nombres avec leur repr\u00e9sentation binaire, il est probable que le processeur affiche quelques symboles \u00e9tranges sans aucune signification, jusqu'\u00e0 rencontrer un 0 en m\u00e9moire. Mais si jamais il n'y avait vraiment aucun z\u00e9ro en m\u00e9moire, le programme finirait pas planter car le syst\u00e8me d'exploitation veille \u00e0 ce qu'il ne se passe pas n'importe quoi dans les programmes ! Nous aurons peut-\u00eatre l'occasion de parler plus en d\u00e9tail de ce genre de situation.","title":"Des chiffres et des lettres"},{"location":"bases/data/types/texts/#des-chiffres-et-des-lettres","text":"L'ordinateur - et avant lui le calculateur - a \u00e9t\u00e9 con\u00e7u par l'humain pour effectuer des calculs longs et r\u00e9p\u00e9titifs \u00e0 sa place et plus rapidement. Il est donc tout naturel de penser \u00e0 lui fournir des valeurs num\u00e9riques pour faire ces calculs. Avec l'expansion de son utilisation, les nombres n'ont plus suffit et le texte est devenu une n\u00e9cessit\u00e9, ne serait-ce que pour qu'un programme demande des choses \u00e0 l'utilisateur. Une nouvelle fois, le probl\u00e8me de la repr\u00e9sentation d'une lettre ou d'un texte complet par un ordinateur se pose quand il ne peut utiliser que des 0 et des 1. Nous avons vu pr\u00e9c\u00e9demment qu'il \u00e9tait possible de repr\u00e9senter plusieurs centaines de nombres entiers sur un octet. Cela repr\u00e9sente bien assez de possibilit\u00e9s pour les lettres de l'alphabet et quelques symboles de ponctuation. Dans les ann\u00e9es 60, la norme ASCII est apparue pour associer des symboles \u00e0 des valeurs num\u00e9riques sur 7 bits, permettant de coder 128 caract\u00e8res diff\u00e9rents : les lettres (minuscules et majuscules), la ponctuation, les signes math\u00e9matiques de base, les dix chiffres et quelques autres symboles imprimables ou non. Pour l'anecdote : depuis les ann\u00e9es 70, les processeurs utilisent des octets (8 bits) et le bit de poids fort d'un caract\u00e8re ASCII est d\u00e9finit \u00e0 0. Cependant, la table ASCII est tr\u00e8s limit\u00e9e puisqu'elle ne permet de repr\u00e9senter que 2 7 = 128 caract\u00e8res diff\u00e9rents. On ne peut pas \u00e9crire convenablement en fran\u00e7ais par exemple car il manque, entre autres, les lettres accentu\u00e9es. Et que dire de langues qui ne s'\u00e9crivent pas avec l'alphabet latin ? Il a donc fallu cr\u00e9er une nouvelle association entre nombres et symboles, c'est ainsi que le code UTF-8 s'est peu \u00e0 peu impos\u00e9. Celui-ci reprend la table ASCII pour les 128 premiers caract\u00e8res - ce qui le rend r\u00e9trocompatible - et associe de 2 \u00e0 4 octets pour coder les autres caract\u00e8res utilis\u00e9s dans le monde entier. Il dispose de tellement de possibilit\u00e9s qu'on en utilise certaines pour les emojis ! Les ordinateurs, les programmes et donc les langages de programmation sont tous aptes de nos jours \u00e0 supporter le code UTF-8 pour \u00e9crire du texte. Mais alors qu'on a compris le principe d'association de chaque lettre \u00e0 une valeur num\u00e9rique, comment assembler les lettres pour faire des phrases ? Un texte est repr\u00e9sent\u00e9 par ce qu'on appelle une cha\u00eene de caract\u00e8res par un ordinateur. Le nom est important et trouve son sens dans ce qu'il repr\u00e9sente. Une cha\u00eene du monde r\u00e9el est une succession de maillons les uns \u00e0 la suite des autres. Une cha\u00eene de caract\u00e8res est une succession de caract\u00e8res dans la m\u00e9moire de l'ordinateur. Quand nous \u00e9crivons un mot comme Bonjour , nous pla\u00e7ons le B puis juste \u00e0 c\u00f4t\u00e9 le o , encore \u00e0 c\u00f4t\u00e9 le n , etc. Dans la m\u00e9moire de l'ordinateur, ce sera exactement pareil : o sera plac\u00e9e directement entre B et n . La m\u00e9moire d'un ordinateur Un aparte sur la m\u00e9moire de l'ordinateur dont la m\u00e9moire vive, ou RAM pour Random Access Memory en anglais. Il s'agit d'une succession de petites cases de m\u00e9moire stockant chacune un seul octet. L'ensemble de la m\u00e9moire centrale peut faire plusieurs milliards d'octets de nos jours que nous mesurons de fa\u00e7on plus pratique en gigaoctets (Go). On peut voir chaque petite case m\u00e9moire comme une maison dans une ville immense. Or le processeur doit chercher les donn\u00e9es dans les cases m\u00e9moire durant son fonctionnement. Il a besoin de savoir o\u00f9 est stock\u00e9e une donn\u00e9e pour la r\u00e9cup\u00e9rer et faire ses calculs avec. Comme dans une ville, chaque case m\u00e9moire a une adresse qui lui est propre. Dans la m\u00e9moire, l'adresse est un nombre entier qui s'incr\u00e9mente de 1 pour passer de case en case. Pour r\u00e9cup\u00e9rer une donn\u00e9e, le processeur indique donc l'adresse de la (ou des) case(s) qu'il veut r\u00e9cup\u00e8rer. Dans le cas de notre texte Bonjour (en ASCII, chaque lettre occupant un octet), si la lettre B est stock\u00e9e dans la case m\u00e9moire 1500, la lettre o sera dans la case m\u00e9moire 1501, le n dans la case m\u00e9moire 1502, ainsi de suite.","title":"Des chiffres et des lettres"},{"location":"bases/data/types/texts/#la-fin-dun-texte","text":"Le souci avec ce que nous venons de voir, c'est que le processeur va aller chercher les lettres une \u00e0 une dans les cases successives de la m\u00e9moire centrale. Or, comment peut-il savoir que notre mot Bonjour se termine \u00e0 la lettre r ? Va-t-il continuer \u00e0 chercher d'autres lettres apr\u00e8s le r ? Que se passe-t-il s'il le fait ? Tant de questions auxquelles il est possible de r\u00e9pondre, fort heureusement ! Si notre texte Bonjour \u00e9tait repr\u00e9sent\u00e9 de cette fa\u00e7on dans la m\u00e9moire de l'ordinateur, le processeur n'aurait absolument aucun moyen de s'arr\u00eater quand il le faut et poursuivrait b\u00eatement en parcourant tous les gigaoctets de la RAM ! N'oublions pas que pour lui, tout est binaire, la distinction entre les types de donn\u00e9es est donc impossible. En fait, le processeur n'a qu'une seule et unique fa\u00e7on de s'arr\u00eater de lire une cha\u00eene de caract\u00e8res. Il doit atteindre un caract\u00e8re sp\u00e9cial appel\u00e9 caract\u00e8re NUL (ou \\0 ) qui fait office de drapeau pour signaler la fin d'une cha\u00eene de caract\u00e8res. Le caract\u00e8re NUL porte bien son nom puisqu'il est associ\u00e9 \u00e0 la valeur num\u00e9rique 0 . D\u00e8s qu'il rencontre cette valeur, le processeur sait qu'il doit arr\u00eater la lecture de la cha\u00eene de caract\u00e8res. Les langages de programmation ne nous obligent pas \u00e0 penser \u00e0 mettre ce caract\u00e8re NUL \u00e0 la fin de nos textes car un outil le fait automatiquement pour nous (le caract\u00e8re NUL est cach\u00e9). Sinon cela serait non seulement p\u00e9nible mais aussi source d'innombrables bugs ! Alors que se passerait-il s'il n'y avait pas la caract\u00e8re NUL \u00e0 la fin d'une cha\u00eene ? Comme la m\u00e9moire peut contenir du texte et des nombres avec leur repr\u00e9sentation binaire, il est probable que le processeur affiche quelques symboles \u00e9tranges sans aucune signification, jusqu'\u00e0 rencontrer un 0 en m\u00e9moire. Mais si jamais il n'y avait vraiment aucun z\u00e9ro en m\u00e9moire, le programme finirait pas planter car le syst\u00e8me d'exploitation veille \u00e0 ce qu'il ne se passe pas n'importe quoi dans les programmes ! Nous aurons peut-\u00eatre l'occasion de parler plus en d\u00e9tail de ce genre de situation.","title":"La fin d'un texte"},{"location":"bases/hardware/cpu/","text":"Le microprocesseur Note importante Il ne s'agit pas d'un descriptif complet de l'int\u00e9rieur d'un processeur. Cette page s'adresse un public large et le but est de vulgariser autant que possible le fonctionnement d'un processeur sans rentrer dans des d\u00e9tails trop techniques. Des mots-cl\u00e9s sont donn\u00e9s pour aider les personnes souhaitant en savoir plus \u00e0 faire leurs propres recherches sur le sujet. Le microprocesseur, Unit\u00e9 Centrale de Traitement ou Central Processing Unit (CPU) en anglais, est souvent appel\u00e9 le \"cerveau\" de l'ordinateur. Il est vrai que ce composant informatique sert \u00e0 effectuer tous les calculs et la logique tels que d\u00e9crits dans les programmes qu'il ex\u00e9cute. Quand un programme est \u00e9crit, il contient une suite d'instructions basiques \u00e0 faire au processeur. On parle alors de programmation imp\u00e9rative . La plupart des processeurs actuels sont de nature imp\u00e9rative en ce sens qu'ils sont faits pour ex\u00e9cuter une succession d'op\u00e9rations basiques. Nous pouvons imager cela comme une recette de cuisine o\u00f9 chaque \u00e9tape \u00e0 r\u00e9aliser est une instruction. Programme et processus Deux mots sont employ\u00e9s \u00e0 partir de maintenant : programme et processus . Ils d\u00e9signent deux choses l\u00e9g\u00e8rement diff\u00e9rentes. Un programme est l'ensemble des instructions. Il n'est pas en cours d'ex\u00e9cution mais se trouve uniquement sur un support de m\u00e9moire de stockage comme le disque dur. Par exemple un .exe sous Microsoft Windows. Un processus est une instance d'un programme en cours d'ex\u00e9cution. Il peut y avoir plusieurs instances d'un m\u00eame programme en cours d'ex\u00e9cution, donc plusieurs processus pour un m\u00eame programme. Le processeur fonctionne \u00e0 l'aide d'\u00e9lectricit\u00e9 et de transistors. Un transistor est un semi-conducteur, c'est-\u00e0-dire qu'on peut contr\u00f4ler s'il laisse ou non passer le courant. Le CPU utilise alors le langage binaire avec uniquement deux valeurs possibles, les bits valant 0 (pas de courant) ou 1 (il y a du courant). Le langage machine , c'est-\u00e0-dire les instructions et les donn\u00e9es qu'il traite, est donc constitu\u00e9 de 0 et de 1. Chaque instruction est cod\u00e9e par une suite de bits unique. Ce code est ce qu'on appelle tout simplement l' opcode ou operation code . L'ensemble des opcodes forme le jeu d'instructions . Ils sont d\u00e9chiffr\u00e9s par le s\u00e9quenceur . Le s\u00e9quenceur Une instruction consiste g\u00e9n\u00e9ralement \u00e0 prendre une ou des donn\u00e9es pour effectuer une op\u00e9ration dessus. Le s\u00e9quenceur du processeur a plusieurs r\u00f4les en lien avec le traitement des op\u00e9rations. Il va commencer par d\u00e9coder l'instruction, c'est-\u00e0-dire voir laquelle dont il s'agit. Une instruction poss\u00e8dant un opcode unique en langage machine, le s\u00e9quenceur va donc diriger le traitement des donn\u00e9es vers une section du processeur sp\u00e9cifique \u00e0 cette instruction, souvent \u00e0 l'int\u00e9rieur d'une des unit\u00e9s arithm\u00e9tiques et logiques . Les unit\u00e9s arithm\u00e9tiques et logiques L'unit\u00e9 arithm\u00e9tique et logique (UAL ou ALU en anglais) est la partie qui va servir \u00e0 faire les calculs de base en math\u00e9matiques (addition, soustraction, division et mulitplication) sur les nombres entiers, des comparaisons entre ces nombres (plus grand que, \u00e9gal \u00e0, diff\u00e9rent de, etc). Elle va aussi effectuer des op\u00e9rations de logique (bool\u00e9enne). Elle peut servir \u00e0 faire du d\u00e9calage de bits que nous aborderons plus tard. A noter qu'un processeur (ou un c\u0153ur de processeur) peut contenir plusieurs ALU. D'autres unit\u00e9s arithm\u00e9thiques sont quant \u00e0 elles sp\u00e9cialis\u00e9es sur les calculs de nombres \u00e0 virgule. On parle alors d'unit\u00e9 de calcul en virgule flottante, UVF ou FPU en anglais pour Floating-Point Unit . D'abord pr\u00e9sentes optionnellement dans les ordinateurs via un coprocesseur sp\u00e9cialis\u00e9 dans ces calculs, elles sont depuis les ann\u00e9es 90 int\u00e9gr\u00e9es directement dans le CPU. L\u00e0 aussi, il est possible d'en avoir plusieurs par c\u0153ur de processeur pour parall\u00e9liser les traitements. Enfin, des unit\u00e9s de calcul sp\u00e9cialis\u00e9es dans les calculs vectoriels vont permettre de faire des calculs sur plusieurs valeurs, des vecteurs, simultan\u00e9ment. Elles sont tr\u00e8s utilis\u00e9es en multim\u00e9dia comme dans les jeux vid\u00e9o (calculs acc\u00e9l\u00e9r\u00e9s sur des vecteurs 2D ou 3D, matrices, etc). Logique bool\u00e9enne Un petit aparte sur la logique bool\u00e9enne, sur laquelle nous reviendrons plus tard. La logique bool\u00e9enne doit son nom au math\u00e9maticien britannique George Bool (1815-1864). Aussi appel\u00e9e alg\u00e8bre de Bool, il s'agit donc d'une approche alg\u00e9brique de la logique. Elle met en sc\u00e8ne deux valeurs possibles ( VRAI ou FAUX ) et quelques op\u00e9rateurs logiques ( ET , OU , OU EXCLUSIF , NON ). Effectuer une op\u00e9ration logique revient, comme en math\u00e9matiques, \u00e0 prendre un op\u00e9rateur et, selon cet op\u00e9rateur, un ou deux op\u00e9randes retournant un r\u00e9sultat suivant des r\u00e8gles d\u00e9finies par la logique bool\u00e9enne. Par exemple, NON VRAI = FAUX en toutes circonstances. De la logique math\u00e9matique d\u00e9coulent d'autres champs comme le calcul de propositions. L'ALU peut \u00eatre d\u00e9coup\u00e9e en plusieurs parties. Chacune de ces parties, d\u00e9di\u00e9e \u00e0 une op\u00e9ration donn\u00e9e, est compos\u00e9e de portes logiques (comme le reste du processeur), elles-m\u00eames constitu\u00e9es de transistors. Une porte logique prend un ou deux bits en entr\u00e9e et sort le r\u00e9sultat de l'op\u00e9rateur bool\u00e9en qu'elle repr\u00e9sente. La succession et le branchement uniques de ces portes logiques pour chaque type d'op\u00e9ration va permettre d'obtenir le r\u00e9sultat d'une addition, d'une multiplication, d'une comparaison, etc. Comme les portes logiques ne fournissent le r\u00e9sultat que pour un bit, si le calcul est r\u00e9alis\u00e9 sur 32 bits, il faudra dupliquer 32 fois en parall\u00e8le le cheminement pour arriver au r\u00e9sultat du nombre entier. Certaines op\u00e9rations peuvent \u00eatre plus longues que d'autres. Il est important de pouvoir synchroniser l'ensemble de ces op\u00e9rations avec une horloge . Horloge Les processeurs que nous utilisons quotidiennement poss\u00e8dent une horloge interne. On parle de processeurs synchrones . G\u00e9n\u00e9ralement, l'horloge est un quartz , un composant \u00e9lectronique dont la particularit\u00e9 est qu'il oscille \u00e0 une fr\u00e9quence stable d\u00e8s qu'on le stimule \u00e9lectriquement. Cette horloge peut effectuer des tics jusqu'\u00e0 plusieurs gigahertz (GHz) dans les processeurs modernes, ce qui fait \u00e9cho \u00e0 leur fr\u00e9quence de fonctionnement. L'horloge est essentielle au fonctionnement du processeur car elle permet d'en synchroniser l'ensemble : \u00e0 chaque cycles, les milliards de transistors au sein du processeur s'ouvrent et se ferment. En effet, chaque instruction va s'effectuer en un nombre pr\u00e9cis de tics d'horloge. Il sera possible d'ex\u00e9cuter plusieurs instructions en un seul cycle pour les plus rapides ; certaines instructions pourront n\u00e9cessiter un cycle \u00e0 elles seules quand les plus lentes n\u00e9cessiteront m\u00eame plusieurs cycles. Il est indispensable de pr\u00e9dire pr\u00e9cis\u00e9ment le nombre de tics n\u00e9cessaires \u00e0 l'obtention d'un r\u00e9sultat pour pouvoir aller le r\u00e9cup\u00e9rer quand il est pr\u00eat. Sans horloge et donc sans synchronisation, il serait difficile de savoir si une op\u00e9ration a rendu son r\u00e9sultat ou si une autre a \u00e9crit une autre valeur par dessus ! En effet, pour traiter rapidement les donn\u00e9es et les calculs, chaque c\u0153ur d'un processeur poss\u00e8de ses propres cases de m\u00e9moire extr\u00eamement rapides pour manipuler les donn\u00e9es, les registres . Les registres Les registres sont donc des cases de m\u00e9moire tr\u00e8s petites. Chaque registre ne peut contenir qu'une seule donn\u00e9e et poss\u00e8de un nom pour l'identifier dans une instruction. En plus des registres g\u00e9n\u00e9raux servant \u00e0 stocker des valeurs pour les calculs, d'autres types de registres existent. Registres g\u00e9n\u00e9raux Les registres g\u00e9n\u00e9raux contiennent les donn\u00e9es \u00e0 traiter en tant qu'op\u00e9randes mais aussi les r\u00e9sultats des op\u00e9rations. Lorsque le s\u00e9quenceur re\u00e7oit une instruction \u00e0 d\u00e9coder, celle-ci contient non seulement son opcode mais aussi les registres o\u00f9 r\u00e9cup\u00e9rer les donn\u00e9es et/ou les \u00e9crire. Les donn\u00e9es d'un registre y restent si elles sont utilis\u00e9es dans les instructions qui viennent tout prochainement, cela \u00e9vite d'avoir \u00e0 aller les chercher de nouveau et donc perdre du temps. Elles sont en revanche stock\u00e9es et \u00e9cras\u00e9es par d'autres valeurs si elles ne sont pas r\u00e9utilis\u00e9es par les quelques instructions suivantes. La m\u00e9moire cache Le processeur ne contient pas un tr\u00e8s grand nombre de registres. Il s'agit d'une m\u00e9moire volatile extr\u00eamement rapide mais aussi extr\u00eamement ch\u00e8re. Les donn\u00e9es vont et viennent \u00e0 un rythme tr\u00e8s soutenu. Il faut donc aussi pouvoir stocker ces valeurs pour pouvoir les r\u00e9utiliser plus tard. Certaines instructions ne sont donc pas d\u00e9di\u00e9es au calcul mais au stockage des valeurs depuis les registres vers une m\u00e9moire \u00e0 plus long terme. On pourrait penser \u00e0 la m\u00e9moire principale (RAM) de l'ordinateur mais celle-ci est externe au processeur et donc son acc\u00e8s est tr\u00e8s lent. A moins d'avoir une bonne raison de le faire (comme un manque de place), il est pr\u00e9f\u00e9rable pour un processeur moderne d'utiliser sa m\u00e9moire cache . C'est une m\u00e9moire faisant office d'interm\u00e9diaire entre les registres et la RAM. Elle se situe \u00e0 l'int\u00e9rieur du processeur, donc facilement accessible et est plus rapide que la RAM. Les processeurs ont acquis de plus en plus de m\u00e9moire cache. De nos jours, elle se d\u00e9coupe en trois couches nomm\u00e9es L1, L2 et L3 - \"L\" pour level (niveau) en anglais. Le cache L1, le plus proche du processeur, le plus rapide et le plus cher, est souvent d\u00e9di\u00e9 \u00e0 un c\u0153ur de processeur et ne fait que quelques centaines de kilo-octets. Le cache L2 est plus grand en taille et g\u00e9n\u00e9ralement commun \u00e0 tous les c\u0153urs. Enfin le cache L3 est la plus grosse m\u00e9moire actuellement pr\u00e9sente dans la majorit\u00e9 des processeurs, lui aussi commun \u00e0 tous les c\u0153urs. Plus un processeur poss\u00e8de de m\u00e9moire cache, plus il pourra \u00eatre performant et fonctionner \u00e0 son plein potentiel. Un d\u00e9faut de cache entra\u00eene des ralentissements car il doit faire beaucoup d'aller-retour avec la RAM. Cela permet de conserver les donn\u00e9es plus longtemps mais toujours de fa\u00e7on volatile : elles sont perdues quand le processus se ferme et/ou l'ordinateur s'arr\u00eate. Quand des valeurs stock\u00e9es en cache (ou en RAM) ont besoin d'\u00eatre r\u00e9cup\u00e9r\u00e9es par le processeur, des instructions servent \u00e0 aller les chercher. Pour ces op\u00e9rations consistant \u00e0 lire et \u00e0 \u00e9crire des donn\u00e9es, les registres peuvent contenir des valeurs repr\u00e9sentant des adresses m\u00e9moire. Nous aurons l'occasion de reparler de l' adressage m\u00e9moire . Il existe encore plein d'autres types d'instructions servant au bon fonctionnement du processeur et de l'ordinateur au sens large. Accumulateur L'ALU va prendre en entr\u00e9e un ou deux op\u00e9randes pour effectuer une op\u00e9ration dessus. L'un de ces op\u00e9randes sera plac\u00e9 dans l' accumulateur et l'autre venant d'un registre g\u00e9n\u00e9ral par exemple. A la fin de l'op\u00e9ration, l'ALU placera le r\u00e9sultat dans l'accumulateur. Ainsi, s'il y a un besoin imm\u00e9diat de ce r\u00e9sultat pour une autre op\u00e9ration, il sera d\u00e9j\u00e0 pr\u00eat pour cha\u00eener les op\u00e9rations. S'il n'y a plus besoin de cette valeur, elle pourra \u00eatre stock\u00e9e dans un registre g\u00e9n\u00e9ral jusqu'\u00e0 en avoir \u00e9ventuellement de nouveau besoin pour un prochain calcul. L'accumulateur sert donc \u00e0 stocker des valeurs interm\u00e9diaires pour des calculs en plusieurs \u00e9tapes. Compteur ordinal et registre d'instruction Le compteur ordinal , aussi abr\u00e9g\u00e9 en PC pour Program Counter en anglais, contient l' adresse de la prochaine instruction qui doit \u00eatre ex\u00e9cut\u00e9e dans le processus (et non la prochaine instruction elle-m\u00eame). A chaque d\u00e9but de cycle d'ex\u00e9cution, l'instruction \u00e0 l'emplacement indiqu\u00e9 par le PC est charg\u00e9e dans le registre d'instruction (IR). La valeur du PC est quant \u00e0 elle incr\u00e9ment\u00e9e pour indiquer l'adresse de l'instruction suivante. Le PC permet donc de savoir o\u00f9 en est l'ex\u00e9cution du processus et l'IR de savoir quelle instruction est \u00e0 ex\u00e9cuter. Cela est tr\u00e8s utile en cas de commutation de contexte , par exemple lorsque le processeur doit ex\u00e9cuter plusieurs processus \u00e0 la fois. Commutation de contexte La commutation de contexte a lieu lorsque le processeur ex\u00e9cute plusieurs processus. De notre point de vue, il ex\u00e9cute tous les processus en m\u00eame temps. La r\u00e9alit\u00e9 pour le processeur est bien s\u00fbr tr\u00e8s diff\u00e9rente. Un processeur avec une fr\u00e9quence de plusieurs GHz va beaucoup trop vite pour notre perception du temps si bien qu'il nous semble faire tout \u00e0 la fois ! Quand un c\u0153ur de processeur est amen\u00e9 \u00e0 ex\u00e9cuter trois processus A, B et C, il va y avoir un ordonnancement \u00e9tablit par le syst\u00e8me d'exploitation (s'il est multit\u00e2che). Cet ordonnancement va indiquer au processeur l'ordre et la p\u00e9riode de temps pour ex\u00e9cuter trois processus. Par exemple : A pendant 2 millisecondes, B pendant 5 millisecondes, C pendant 3 millisecondes, B pendant 6 millisecondes, A pendant 2 millisecondes, etc. L'ordre et la dur\u00e9e d'ex\u00e9cution des processus par intervalle d\u00e9pendent de l'algorithme de l'ordonnanceur. Cependant, le c\u0153ur d'un processeur ne peut contenir l'\u00e9tat que d'un seul processus \u00e0 la fois. Pour passer de A \u00e0 B, il faut alors sauvegarder l'\u00e9tat du processeur pour le processus A (dans le noyau du syst\u00e8me d'exploitation), charger l'\u00e9tat qu'il avait pour le processus B pour ensuite ex\u00e9cuter B. Ces commutations peuvent prendre plus ou moins de temps suivant le processeur et le syst\u00e8me d'exploitation utilis\u00e9. Ainsi, plus un processeur ex\u00e9cutera de processus en parall\u00e8le, plus il sera ralenti car il aura plus de commutation de contexte \u00e0 effectuer. Pointeur de pile Un programme informatique est une succession d'instructions simples. Cependant, pour structurer le code du programme, les langages de programmation offrent une fa\u00e7on simple de le rendre plus lisible et surtout de le rendre r\u00e9utilisable : les fonctions . Une fonction est donc un bout de code ind\u00e9pendant qui peut prendre des valeurs d'entr\u00e9e et qui peut retourner une valeur en retour. Lorsqu'une fonction se termine, il faut revenir \u00e0 l'endroit o\u00f9 elle a \u00e9t\u00e9 appel\u00e9e. De fa\u00e7on plus imag\u00e9e, on peut imaginer un livre de recettes o\u00f9 pour r\u00e9aliser un entremet \u00e0 la page 98, il nous est demand\u00e9 de r\u00e9aliser une g\u00e9noise. La recette de l'entremet lui-m\u00eame ne nous explique pas comment faire une g\u00e9noise mais nous renvoie \u00e0 la page 150. Une fois que la g\u00e9noise est r\u00e9alis\u00e9e, nous revenons \u00e0 la recette d'entremet pour suivre les instructions \u00e0 partir de l\u00e0 o\u00f9 nous nous \u00e9tions arr\u00eat\u00e9s. A noter que la page 150 pour r\u00e9aliser une g\u00e9noise peut-\u00eatre r\u00e9utilis\u00e9e dans plusieurs recettes du livre o\u00f9 il en faut une ! Ce n'est pas la peine de r\u00e9\u00e9crire autant de fois la m\u00eame recette, un des gros int\u00e9r\u00eats des fonctions en informatique. Du fait que les fonctions sont ind\u00e9pendantes, il est possible de les appeler \u00e0 plusieurs endroits dans le programme. En allant plus loin, il est m\u00eame possible d'appeler des fonctions dans d'autres fonctions en les imbriquant les unes dans les autres. Pour notre entremet, on peut voir la fonction realiser_genoise() contenant elle-m\u00eame une fonction battre_oeufs() . Pour en revenir au processeur, nous avons vu qu'il poss\u00e8de un compteur ordinal pour savoir quelle est la prochaine instruction \u00e0 ex\u00e9cuter. Un probl\u00e8me avec les fonctions, c'est que le programme ne peut plus \u00eatre suivi instruction apr\u00e8s instruction : il n'est plus lin\u00e9aire car il faut faire des aller-retours dans le code ! Reprenons le cas de notre entremet dont la recette est expliqu\u00e9e \u00e9tape par \u00e9tape \u00e0 la page 98. Sauf que nous devons suivre la recette pour faire une g\u00e9noise. Nous allons donc \u00e0 la page 150 et nous suivons toutes les instructions pour confectionner la g\u00e9noise jusqu'\u00e0 la derni\u00e8re. A ce stade, si nous \u00e9tions un processeur uniquement dot\u00e9 d'un compteur ordinal, il nous serait totalement impossible de savoir o\u00f9 revenir car nous n'avons pas m\u00e9moris\u00e9 la page de la recette de l'entremet ! C'est l\u00e0 qu'intervient le pointeur de pile . Quand une fonction est appel\u00e9e, nous avons une pile d'ex\u00e9cution . Le but de cette pile est de m\u00e9moriser o\u00f9 revenir dans le programme (adresse m\u00e9moire) quand chaque fonction appel\u00e9e se termine. Le mot pile fait sens dans le sens o\u00f9 il s'agit d'une pile d'adresses m\u00e9moire : la derni\u00e8re adresse ajout\u00e9e au sommet de la pile est aussi la premi\u00e8re \u00e0 en \u00eatre retir\u00e9e. Le pointeur de pile conserve l'endroit o\u00f9 nous nous trouvons dans cette pile. D\u00e9passement de la pile d'ex\u00e9cution Comme tout ce qui a trait \u00e0 la m\u00e9moire, la pile d'ex\u00e9cution a une taille limit\u00e9e. Ainsi, le nombre d'appels de fonction imbriqu\u00e9s ne peut d\u00e9passer un certain nombre d\u00e9pendant du processeur. Si la pile vient \u00e0 d\u00e9border, il va y avoir une \u00e9criture des donn\u00e9es au-del\u00e0 de ce qu'il est permis pouvant compromettre l'ex\u00e9cution du programme. Une erreur se produit alors et le programme se termine sous la forme d'un crash . On parle de d\u00e9passement de la pile d'ex\u00e9cution ou de stack overflow en anglais. Registre d'\u00e9tat Contrairement aux autres registres, les bits du registre d'\u00e9tat sont ind\u00e9pendants les uns des autres. Il ne servent donc pas \u00e0 repr\u00e9senter une valeur ensemble, on les lit de fa\u00e7on unitaire pour conna\u00eetre un \u00e9tat pr\u00e9cis du processeur. On parle de drapeaux ( flags en anglais). Par exemple, pour savoir si le r\u00e9sultat d'une soustraction a donn\u00e9 un r\u00e9sultat n\u00e9gatif on va regarder si le bit correspondant dans le registre d'\u00e9tat vaut 0 (NON) ou 1 (OUI). Cet exemple est tr\u00e8s utilis\u00e9 pour effectuer des branchements conditionnels, par exemple pour ex\u00e9cuter une portion de code uniquement si la valeur A est plus grande que la valeur B. Il existe au minimum quatre drapeaux dans le registre d'\u00e9tat d'un processeur actuel, d'autres peuvent exister suivant l'architecture : Z\u00e9ro ( Zero ), pour savoir si le r\u00e9sultat d'une op\u00e9ration est nul ; Retenue ( Carry ), pour savoir si le r\u00e9sultat d'une op\u00e9ration a d\u00e9gag\u00e9 une retenue que le processeur n'est pas capable de g\u00e9rer. Par exemple, pour un processeur 8 bits qui d\u00e9tecte une retenue devant s'effectuer sur un neuvi\u00e8me bit inexistant. Ce flag permet d'\u00e9muler des calculs de nombres sur plus de bits, par exemple sur 16 bits ici, en propageant la retenue ; Signe ( Sign ), pour savoir si le r\u00e9sultat d'une op\u00e9ration est n\u00e9gatif ; D\u00e9passement de capacit\u00e9 ( Overflow ), pour savoir si la valeur d'une op\u00e9ration devrait \u00eatre cod\u00e9e sur plus de bits que le processeur peut supporter. Autres \u00e9l\u00e9ments Nous venons de voir ce qui pourrait \u00eatre la base commune \u00e0 tout processeur un minimum moderne. Il existe bien d'autres structures \u00e0 l'int\u00e9rieur d'un processeur pour \u00e9tendre ses possibilit\u00e9s, optimiser son fonctionnement, etc. Nous n'allons pas d\u00e9tailler l'enti\u00e8ret\u00e9 de ce qui compose un processeur moderne car cette page pourrait faire la taille d'un immeuble ! Le bon fonctionnement du processeur ne peut \u00eatre assur\u00e9 sans une m\u00e9moire qui contient les instructions et les donn\u00e9es \u00e0 traiter par ces instructions. Nous allons donc voir un peu comment celle-ci s'organise et fonctionne \u00e0 son tour dans la prochaine partie. Intel explique le fonctionnement d'un processeur Partie 1 : Partie 2 : Sources https://c9x.me/x86/ https://fr.wikibooks.org/wiki/Fonctionnement_d%27un_ordinateur/L%27unit%C3%A9_de_contr%C3%B4le http://www.courstechinfo.be/Techno/CPU.html http://igm.univ-mlv.fr/~dr/XPOSE2011/archi7/proc.html https://ecariou.perso.univ-pau.fr/cours/archi/cours-7-cpu.pdf","title":"Le microprocesseur"},{"location":"bases/hardware/cpu/#le-microprocesseur","text":"Note importante Il ne s'agit pas d'un descriptif complet de l'int\u00e9rieur d'un processeur. Cette page s'adresse un public large et le but est de vulgariser autant que possible le fonctionnement d'un processeur sans rentrer dans des d\u00e9tails trop techniques. Des mots-cl\u00e9s sont donn\u00e9s pour aider les personnes souhaitant en savoir plus \u00e0 faire leurs propres recherches sur le sujet. Le microprocesseur, Unit\u00e9 Centrale de Traitement ou Central Processing Unit (CPU) en anglais, est souvent appel\u00e9 le \"cerveau\" de l'ordinateur. Il est vrai que ce composant informatique sert \u00e0 effectuer tous les calculs et la logique tels que d\u00e9crits dans les programmes qu'il ex\u00e9cute. Quand un programme est \u00e9crit, il contient une suite d'instructions basiques \u00e0 faire au processeur. On parle alors de programmation imp\u00e9rative . La plupart des processeurs actuels sont de nature imp\u00e9rative en ce sens qu'ils sont faits pour ex\u00e9cuter une succession d'op\u00e9rations basiques. Nous pouvons imager cela comme une recette de cuisine o\u00f9 chaque \u00e9tape \u00e0 r\u00e9aliser est une instruction. Programme et processus Deux mots sont employ\u00e9s \u00e0 partir de maintenant : programme et processus . Ils d\u00e9signent deux choses l\u00e9g\u00e8rement diff\u00e9rentes. Un programme est l'ensemble des instructions. Il n'est pas en cours d'ex\u00e9cution mais se trouve uniquement sur un support de m\u00e9moire de stockage comme le disque dur. Par exemple un .exe sous Microsoft Windows. Un processus est une instance d'un programme en cours d'ex\u00e9cution. Il peut y avoir plusieurs instances d'un m\u00eame programme en cours d'ex\u00e9cution, donc plusieurs processus pour un m\u00eame programme. Le processeur fonctionne \u00e0 l'aide d'\u00e9lectricit\u00e9 et de transistors. Un transistor est un semi-conducteur, c'est-\u00e0-dire qu'on peut contr\u00f4ler s'il laisse ou non passer le courant. Le CPU utilise alors le langage binaire avec uniquement deux valeurs possibles, les bits valant 0 (pas de courant) ou 1 (il y a du courant). Le langage machine , c'est-\u00e0-dire les instructions et les donn\u00e9es qu'il traite, est donc constitu\u00e9 de 0 et de 1. Chaque instruction est cod\u00e9e par une suite de bits unique. Ce code est ce qu'on appelle tout simplement l' opcode ou operation code . L'ensemble des opcodes forme le jeu d'instructions . Ils sont d\u00e9chiffr\u00e9s par le s\u00e9quenceur .","title":"Le microprocesseur"},{"location":"bases/hardware/cpu/#le-sequenceur","text":"Une instruction consiste g\u00e9n\u00e9ralement \u00e0 prendre une ou des donn\u00e9es pour effectuer une op\u00e9ration dessus. Le s\u00e9quenceur du processeur a plusieurs r\u00f4les en lien avec le traitement des op\u00e9rations. Il va commencer par d\u00e9coder l'instruction, c'est-\u00e0-dire voir laquelle dont il s'agit. Une instruction poss\u00e8dant un opcode unique en langage machine, le s\u00e9quenceur va donc diriger le traitement des donn\u00e9es vers une section du processeur sp\u00e9cifique \u00e0 cette instruction, souvent \u00e0 l'int\u00e9rieur d'une des unit\u00e9s arithm\u00e9tiques et logiques .","title":"Le s\u00e9quenceur"},{"location":"bases/hardware/cpu/#les-unites-arithmetiques-et-logiques","text":"L'unit\u00e9 arithm\u00e9tique et logique (UAL ou ALU en anglais) est la partie qui va servir \u00e0 faire les calculs de base en math\u00e9matiques (addition, soustraction, division et mulitplication) sur les nombres entiers, des comparaisons entre ces nombres (plus grand que, \u00e9gal \u00e0, diff\u00e9rent de, etc). Elle va aussi effectuer des op\u00e9rations de logique (bool\u00e9enne). Elle peut servir \u00e0 faire du d\u00e9calage de bits que nous aborderons plus tard. A noter qu'un processeur (ou un c\u0153ur de processeur) peut contenir plusieurs ALU. D'autres unit\u00e9s arithm\u00e9thiques sont quant \u00e0 elles sp\u00e9cialis\u00e9es sur les calculs de nombres \u00e0 virgule. On parle alors d'unit\u00e9 de calcul en virgule flottante, UVF ou FPU en anglais pour Floating-Point Unit . D'abord pr\u00e9sentes optionnellement dans les ordinateurs via un coprocesseur sp\u00e9cialis\u00e9 dans ces calculs, elles sont depuis les ann\u00e9es 90 int\u00e9gr\u00e9es directement dans le CPU. L\u00e0 aussi, il est possible d'en avoir plusieurs par c\u0153ur de processeur pour parall\u00e9liser les traitements. Enfin, des unit\u00e9s de calcul sp\u00e9cialis\u00e9es dans les calculs vectoriels vont permettre de faire des calculs sur plusieurs valeurs, des vecteurs, simultan\u00e9ment. Elles sont tr\u00e8s utilis\u00e9es en multim\u00e9dia comme dans les jeux vid\u00e9o (calculs acc\u00e9l\u00e9r\u00e9s sur des vecteurs 2D ou 3D, matrices, etc). Logique bool\u00e9enne Un petit aparte sur la logique bool\u00e9enne, sur laquelle nous reviendrons plus tard. La logique bool\u00e9enne doit son nom au math\u00e9maticien britannique George Bool (1815-1864). Aussi appel\u00e9e alg\u00e8bre de Bool, il s'agit donc d'une approche alg\u00e9brique de la logique. Elle met en sc\u00e8ne deux valeurs possibles ( VRAI ou FAUX ) et quelques op\u00e9rateurs logiques ( ET , OU , OU EXCLUSIF , NON ). Effectuer une op\u00e9ration logique revient, comme en math\u00e9matiques, \u00e0 prendre un op\u00e9rateur et, selon cet op\u00e9rateur, un ou deux op\u00e9randes retournant un r\u00e9sultat suivant des r\u00e8gles d\u00e9finies par la logique bool\u00e9enne. Par exemple, NON VRAI = FAUX en toutes circonstances. De la logique math\u00e9matique d\u00e9coulent d'autres champs comme le calcul de propositions. L'ALU peut \u00eatre d\u00e9coup\u00e9e en plusieurs parties. Chacune de ces parties, d\u00e9di\u00e9e \u00e0 une op\u00e9ration donn\u00e9e, est compos\u00e9e de portes logiques (comme le reste du processeur), elles-m\u00eames constitu\u00e9es de transistors. Une porte logique prend un ou deux bits en entr\u00e9e et sort le r\u00e9sultat de l'op\u00e9rateur bool\u00e9en qu'elle repr\u00e9sente. La succession et le branchement uniques de ces portes logiques pour chaque type d'op\u00e9ration va permettre d'obtenir le r\u00e9sultat d'une addition, d'une multiplication, d'une comparaison, etc. Comme les portes logiques ne fournissent le r\u00e9sultat que pour un bit, si le calcul est r\u00e9alis\u00e9 sur 32 bits, il faudra dupliquer 32 fois en parall\u00e8le le cheminement pour arriver au r\u00e9sultat du nombre entier. Certaines op\u00e9rations peuvent \u00eatre plus longues que d'autres. Il est important de pouvoir synchroniser l'ensemble de ces op\u00e9rations avec une horloge .","title":"Les unit\u00e9s arithm\u00e9tiques et logiques"},{"location":"bases/hardware/cpu/#horloge","text":"Les processeurs que nous utilisons quotidiennement poss\u00e8dent une horloge interne. On parle de processeurs synchrones . G\u00e9n\u00e9ralement, l'horloge est un quartz , un composant \u00e9lectronique dont la particularit\u00e9 est qu'il oscille \u00e0 une fr\u00e9quence stable d\u00e8s qu'on le stimule \u00e9lectriquement. Cette horloge peut effectuer des tics jusqu'\u00e0 plusieurs gigahertz (GHz) dans les processeurs modernes, ce qui fait \u00e9cho \u00e0 leur fr\u00e9quence de fonctionnement. L'horloge est essentielle au fonctionnement du processeur car elle permet d'en synchroniser l'ensemble : \u00e0 chaque cycles, les milliards de transistors au sein du processeur s'ouvrent et se ferment. En effet, chaque instruction va s'effectuer en un nombre pr\u00e9cis de tics d'horloge. Il sera possible d'ex\u00e9cuter plusieurs instructions en un seul cycle pour les plus rapides ; certaines instructions pourront n\u00e9cessiter un cycle \u00e0 elles seules quand les plus lentes n\u00e9cessiteront m\u00eame plusieurs cycles. Il est indispensable de pr\u00e9dire pr\u00e9cis\u00e9ment le nombre de tics n\u00e9cessaires \u00e0 l'obtention d'un r\u00e9sultat pour pouvoir aller le r\u00e9cup\u00e9rer quand il est pr\u00eat. Sans horloge et donc sans synchronisation, il serait difficile de savoir si une op\u00e9ration a rendu son r\u00e9sultat ou si une autre a \u00e9crit une autre valeur par dessus ! En effet, pour traiter rapidement les donn\u00e9es et les calculs, chaque c\u0153ur d'un processeur poss\u00e8de ses propres cases de m\u00e9moire extr\u00eamement rapides pour manipuler les donn\u00e9es, les registres .","title":"Horloge"},{"location":"bases/hardware/cpu/#les-registres","text":"Les registres sont donc des cases de m\u00e9moire tr\u00e8s petites. Chaque registre ne peut contenir qu'une seule donn\u00e9e et poss\u00e8de un nom pour l'identifier dans une instruction. En plus des registres g\u00e9n\u00e9raux servant \u00e0 stocker des valeurs pour les calculs, d'autres types de registres existent.","title":"Les registres"},{"location":"bases/hardware/cpu/#registres-generaux","text":"Les registres g\u00e9n\u00e9raux contiennent les donn\u00e9es \u00e0 traiter en tant qu'op\u00e9randes mais aussi les r\u00e9sultats des op\u00e9rations. Lorsque le s\u00e9quenceur re\u00e7oit une instruction \u00e0 d\u00e9coder, celle-ci contient non seulement son opcode mais aussi les registres o\u00f9 r\u00e9cup\u00e9rer les donn\u00e9es et/ou les \u00e9crire. Les donn\u00e9es d'un registre y restent si elles sont utilis\u00e9es dans les instructions qui viennent tout prochainement, cela \u00e9vite d'avoir \u00e0 aller les chercher de nouveau et donc perdre du temps. Elles sont en revanche stock\u00e9es et \u00e9cras\u00e9es par d'autres valeurs si elles ne sont pas r\u00e9utilis\u00e9es par les quelques instructions suivantes. La m\u00e9moire cache Le processeur ne contient pas un tr\u00e8s grand nombre de registres. Il s'agit d'une m\u00e9moire volatile extr\u00eamement rapide mais aussi extr\u00eamement ch\u00e8re. Les donn\u00e9es vont et viennent \u00e0 un rythme tr\u00e8s soutenu. Il faut donc aussi pouvoir stocker ces valeurs pour pouvoir les r\u00e9utiliser plus tard. Certaines instructions ne sont donc pas d\u00e9di\u00e9es au calcul mais au stockage des valeurs depuis les registres vers une m\u00e9moire \u00e0 plus long terme. On pourrait penser \u00e0 la m\u00e9moire principale (RAM) de l'ordinateur mais celle-ci est externe au processeur et donc son acc\u00e8s est tr\u00e8s lent. A moins d'avoir une bonne raison de le faire (comme un manque de place), il est pr\u00e9f\u00e9rable pour un processeur moderne d'utiliser sa m\u00e9moire cache . C'est une m\u00e9moire faisant office d'interm\u00e9diaire entre les registres et la RAM. Elle se situe \u00e0 l'int\u00e9rieur du processeur, donc facilement accessible et est plus rapide que la RAM. Les processeurs ont acquis de plus en plus de m\u00e9moire cache. De nos jours, elle se d\u00e9coupe en trois couches nomm\u00e9es L1, L2 et L3 - \"L\" pour level (niveau) en anglais. Le cache L1, le plus proche du processeur, le plus rapide et le plus cher, est souvent d\u00e9di\u00e9 \u00e0 un c\u0153ur de processeur et ne fait que quelques centaines de kilo-octets. Le cache L2 est plus grand en taille et g\u00e9n\u00e9ralement commun \u00e0 tous les c\u0153urs. Enfin le cache L3 est la plus grosse m\u00e9moire actuellement pr\u00e9sente dans la majorit\u00e9 des processeurs, lui aussi commun \u00e0 tous les c\u0153urs. Plus un processeur poss\u00e8de de m\u00e9moire cache, plus il pourra \u00eatre performant et fonctionner \u00e0 son plein potentiel. Un d\u00e9faut de cache entra\u00eene des ralentissements car il doit faire beaucoup d'aller-retour avec la RAM. Cela permet de conserver les donn\u00e9es plus longtemps mais toujours de fa\u00e7on volatile : elles sont perdues quand le processus se ferme et/ou l'ordinateur s'arr\u00eate. Quand des valeurs stock\u00e9es en cache (ou en RAM) ont besoin d'\u00eatre r\u00e9cup\u00e9r\u00e9es par le processeur, des instructions servent \u00e0 aller les chercher. Pour ces op\u00e9rations consistant \u00e0 lire et \u00e0 \u00e9crire des donn\u00e9es, les registres peuvent contenir des valeurs repr\u00e9sentant des adresses m\u00e9moire. Nous aurons l'occasion de reparler de l' adressage m\u00e9moire . Il existe encore plein d'autres types d'instructions servant au bon fonctionnement du processeur et de l'ordinateur au sens large.","title":"Registres g\u00e9n\u00e9raux"},{"location":"bases/hardware/cpu/#accumulateur","text":"L'ALU va prendre en entr\u00e9e un ou deux op\u00e9randes pour effectuer une op\u00e9ration dessus. L'un de ces op\u00e9randes sera plac\u00e9 dans l' accumulateur et l'autre venant d'un registre g\u00e9n\u00e9ral par exemple. A la fin de l'op\u00e9ration, l'ALU placera le r\u00e9sultat dans l'accumulateur. Ainsi, s'il y a un besoin imm\u00e9diat de ce r\u00e9sultat pour une autre op\u00e9ration, il sera d\u00e9j\u00e0 pr\u00eat pour cha\u00eener les op\u00e9rations. S'il n'y a plus besoin de cette valeur, elle pourra \u00eatre stock\u00e9e dans un registre g\u00e9n\u00e9ral jusqu'\u00e0 en avoir \u00e9ventuellement de nouveau besoin pour un prochain calcul. L'accumulateur sert donc \u00e0 stocker des valeurs interm\u00e9diaires pour des calculs en plusieurs \u00e9tapes.","title":"Accumulateur"},{"location":"bases/hardware/cpu/#compteur-ordinal-et-registre-dinstruction","text":"Le compteur ordinal , aussi abr\u00e9g\u00e9 en PC pour Program Counter en anglais, contient l' adresse de la prochaine instruction qui doit \u00eatre ex\u00e9cut\u00e9e dans le processus (et non la prochaine instruction elle-m\u00eame). A chaque d\u00e9but de cycle d'ex\u00e9cution, l'instruction \u00e0 l'emplacement indiqu\u00e9 par le PC est charg\u00e9e dans le registre d'instruction (IR). La valeur du PC est quant \u00e0 elle incr\u00e9ment\u00e9e pour indiquer l'adresse de l'instruction suivante. Le PC permet donc de savoir o\u00f9 en est l'ex\u00e9cution du processus et l'IR de savoir quelle instruction est \u00e0 ex\u00e9cuter. Cela est tr\u00e8s utile en cas de commutation de contexte , par exemple lorsque le processeur doit ex\u00e9cuter plusieurs processus \u00e0 la fois. Commutation de contexte La commutation de contexte a lieu lorsque le processeur ex\u00e9cute plusieurs processus. De notre point de vue, il ex\u00e9cute tous les processus en m\u00eame temps. La r\u00e9alit\u00e9 pour le processeur est bien s\u00fbr tr\u00e8s diff\u00e9rente. Un processeur avec une fr\u00e9quence de plusieurs GHz va beaucoup trop vite pour notre perception du temps si bien qu'il nous semble faire tout \u00e0 la fois ! Quand un c\u0153ur de processeur est amen\u00e9 \u00e0 ex\u00e9cuter trois processus A, B et C, il va y avoir un ordonnancement \u00e9tablit par le syst\u00e8me d'exploitation (s'il est multit\u00e2che). Cet ordonnancement va indiquer au processeur l'ordre et la p\u00e9riode de temps pour ex\u00e9cuter trois processus. Par exemple : A pendant 2 millisecondes, B pendant 5 millisecondes, C pendant 3 millisecondes, B pendant 6 millisecondes, A pendant 2 millisecondes, etc. L'ordre et la dur\u00e9e d'ex\u00e9cution des processus par intervalle d\u00e9pendent de l'algorithme de l'ordonnanceur. Cependant, le c\u0153ur d'un processeur ne peut contenir l'\u00e9tat que d'un seul processus \u00e0 la fois. Pour passer de A \u00e0 B, il faut alors sauvegarder l'\u00e9tat du processeur pour le processus A (dans le noyau du syst\u00e8me d'exploitation), charger l'\u00e9tat qu'il avait pour le processus B pour ensuite ex\u00e9cuter B. Ces commutations peuvent prendre plus ou moins de temps suivant le processeur et le syst\u00e8me d'exploitation utilis\u00e9. Ainsi, plus un processeur ex\u00e9cutera de processus en parall\u00e8le, plus il sera ralenti car il aura plus de commutation de contexte \u00e0 effectuer.","title":"Compteur ordinal et registre d'instruction"},{"location":"bases/hardware/cpu/#pointeur-de-pile","text":"Un programme informatique est une succession d'instructions simples. Cependant, pour structurer le code du programme, les langages de programmation offrent une fa\u00e7on simple de le rendre plus lisible et surtout de le rendre r\u00e9utilisable : les fonctions . Une fonction est donc un bout de code ind\u00e9pendant qui peut prendre des valeurs d'entr\u00e9e et qui peut retourner une valeur en retour. Lorsqu'une fonction se termine, il faut revenir \u00e0 l'endroit o\u00f9 elle a \u00e9t\u00e9 appel\u00e9e. De fa\u00e7on plus imag\u00e9e, on peut imaginer un livre de recettes o\u00f9 pour r\u00e9aliser un entremet \u00e0 la page 98, il nous est demand\u00e9 de r\u00e9aliser une g\u00e9noise. La recette de l'entremet lui-m\u00eame ne nous explique pas comment faire une g\u00e9noise mais nous renvoie \u00e0 la page 150. Une fois que la g\u00e9noise est r\u00e9alis\u00e9e, nous revenons \u00e0 la recette d'entremet pour suivre les instructions \u00e0 partir de l\u00e0 o\u00f9 nous nous \u00e9tions arr\u00eat\u00e9s. A noter que la page 150 pour r\u00e9aliser une g\u00e9noise peut-\u00eatre r\u00e9utilis\u00e9e dans plusieurs recettes du livre o\u00f9 il en faut une ! Ce n'est pas la peine de r\u00e9\u00e9crire autant de fois la m\u00eame recette, un des gros int\u00e9r\u00eats des fonctions en informatique. Du fait que les fonctions sont ind\u00e9pendantes, il est possible de les appeler \u00e0 plusieurs endroits dans le programme. En allant plus loin, il est m\u00eame possible d'appeler des fonctions dans d'autres fonctions en les imbriquant les unes dans les autres. Pour notre entremet, on peut voir la fonction realiser_genoise() contenant elle-m\u00eame une fonction battre_oeufs() . Pour en revenir au processeur, nous avons vu qu'il poss\u00e8de un compteur ordinal pour savoir quelle est la prochaine instruction \u00e0 ex\u00e9cuter. Un probl\u00e8me avec les fonctions, c'est que le programme ne peut plus \u00eatre suivi instruction apr\u00e8s instruction : il n'est plus lin\u00e9aire car il faut faire des aller-retours dans le code ! Reprenons le cas de notre entremet dont la recette est expliqu\u00e9e \u00e9tape par \u00e9tape \u00e0 la page 98. Sauf que nous devons suivre la recette pour faire une g\u00e9noise. Nous allons donc \u00e0 la page 150 et nous suivons toutes les instructions pour confectionner la g\u00e9noise jusqu'\u00e0 la derni\u00e8re. A ce stade, si nous \u00e9tions un processeur uniquement dot\u00e9 d'un compteur ordinal, il nous serait totalement impossible de savoir o\u00f9 revenir car nous n'avons pas m\u00e9moris\u00e9 la page de la recette de l'entremet ! C'est l\u00e0 qu'intervient le pointeur de pile . Quand une fonction est appel\u00e9e, nous avons une pile d'ex\u00e9cution . Le but de cette pile est de m\u00e9moriser o\u00f9 revenir dans le programme (adresse m\u00e9moire) quand chaque fonction appel\u00e9e se termine. Le mot pile fait sens dans le sens o\u00f9 il s'agit d'une pile d'adresses m\u00e9moire : la derni\u00e8re adresse ajout\u00e9e au sommet de la pile est aussi la premi\u00e8re \u00e0 en \u00eatre retir\u00e9e. Le pointeur de pile conserve l'endroit o\u00f9 nous nous trouvons dans cette pile. D\u00e9passement de la pile d'ex\u00e9cution Comme tout ce qui a trait \u00e0 la m\u00e9moire, la pile d'ex\u00e9cution a une taille limit\u00e9e. Ainsi, le nombre d'appels de fonction imbriqu\u00e9s ne peut d\u00e9passer un certain nombre d\u00e9pendant du processeur. Si la pile vient \u00e0 d\u00e9border, il va y avoir une \u00e9criture des donn\u00e9es au-del\u00e0 de ce qu'il est permis pouvant compromettre l'ex\u00e9cution du programme. Une erreur se produit alors et le programme se termine sous la forme d'un crash . On parle de d\u00e9passement de la pile d'ex\u00e9cution ou de stack overflow en anglais.","title":"Pointeur de pile"},{"location":"bases/hardware/cpu/#registre-detat","text":"Contrairement aux autres registres, les bits du registre d'\u00e9tat sont ind\u00e9pendants les uns des autres. Il ne servent donc pas \u00e0 repr\u00e9senter une valeur ensemble, on les lit de fa\u00e7on unitaire pour conna\u00eetre un \u00e9tat pr\u00e9cis du processeur. On parle de drapeaux ( flags en anglais). Par exemple, pour savoir si le r\u00e9sultat d'une soustraction a donn\u00e9 un r\u00e9sultat n\u00e9gatif on va regarder si le bit correspondant dans le registre d'\u00e9tat vaut 0 (NON) ou 1 (OUI). Cet exemple est tr\u00e8s utilis\u00e9 pour effectuer des branchements conditionnels, par exemple pour ex\u00e9cuter une portion de code uniquement si la valeur A est plus grande que la valeur B. Il existe au minimum quatre drapeaux dans le registre d'\u00e9tat d'un processeur actuel, d'autres peuvent exister suivant l'architecture : Z\u00e9ro ( Zero ), pour savoir si le r\u00e9sultat d'une op\u00e9ration est nul ; Retenue ( Carry ), pour savoir si le r\u00e9sultat d'une op\u00e9ration a d\u00e9gag\u00e9 une retenue que le processeur n'est pas capable de g\u00e9rer. Par exemple, pour un processeur 8 bits qui d\u00e9tecte une retenue devant s'effectuer sur un neuvi\u00e8me bit inexistant. Ce flag permet d'\u00e9muler des calculs de nombres sur plus de bits, par exemple sur 16 bits ici, en propageant la retenue ; Signe ( Sign ), pour savoir si le r\u00e9sultat d'une op\u00e9ration est n\u00e9gatif ; D\u00e9passement de capacit\u00e9 ( Overflow ), pour savoir si la valeur d'une op\u00e9ration devrait \u00eatre cod\u00e9e sur plus de bits que le processeur peut supporter.","title":"Registre d'\u00e9tat"},{"location":"bases/hardware/cpu/#autres-elements","text":"Nous venons de voir ce qui pourrait \u00eatre la base commune \u00e0 tout processeur un minimum moderne. Il existe bien d'autres structures \u00e0 l'int\u00e9rieur d'un processeur pour \u00e9tendre ses possibilit\u00e9s, optimiser son fonctionnement, etc. Nous n'allons pas d\u00e9tailler l'enti\u00e8ret\u00e9 de ce qui compose un processeur moderne car cette page pourrait faire la taille d'un immeuble ! Le bon fonctionnement du processeur ne peut \u00eatre assur\u00e9 sans une m\u00e9moire qui contient les instructions et les donn\u00e9es \u00e0 traiter par ces instructions. Nous allons donc voir un peu comment celle-ci s'organise et fonctionne \u00e0 son tour dans la prochaine partie. Intel explique le fonctionnement d'un processeur Partie 1 : Partie 2 : Sources https://c9x.me/x86/ https://fr.wikibooks.org/wiki/Fonctionnement_d%27un_ordinateur/L%27unit%C3%A9_de_contr%C3%B4le http://www.courstechinfo.be/Techno/CPU.html http://igm.univ-mlv.fr/~dr/XPOSE2011/archi7/proc.html https://ecariou.perso.univ-pau.fr/cours/archi/cours-7-cpu.pdf","title":"Autres \u00e9l\u00e9ments"},{"location":"bases/hardware/memory/","text":"La m\u00e9moire Il existe plusieurs types de m\u00e9moire dans un ordinateur. Nous allons suivre le cheminement d'un programme du moment o\u00f9 on double-clique dessus jusqu'\u00e0 son ex\u00e9cution par le processeur. Tout d'abord, le programme est contenu sur une m\u00e9moire qui est permanente y compris quand l'ordinateur est \u00e9teint. Il peut s'agir d'un disque dur magn\u00e9tique ou de m\u00e9moire flash comme dans un SSD, une cl\u00e9 USB ou une puce de m\u00e9moire flash \u00e0 l'int\u00e9rieur d'un smartphone. Un disque dur magn\u00e9tique ou de la m\u00e9moire flash est ce qu'on appelle de la m\u00e9moire de masse . Elle est abondante dans un ordinateur, actuellement plus t\u00e9raoctets, et relativement peu ch\u00e8re en comparaison des autres types de m\u00e9moires. Plus la m\u00e9moire est rapide et, g\u00e9n\u00e9ralement, plus elle est ch\u00e8re et donc moins abondante. Lorsqu'on souhaite ex\u00e9cuter un programme, il est charg\u00e9 tout ou partie depuis son emplacement sur la m\u00e9moire de masse vers la m\u00e9moire vive (RAM). Le programme va, au fur et \u00e0 mesure de son ex\u00e9cution, avoir besoin de donn\u00e9es encore pr\u00e9sentes sur le disque et devra donc demander leur chargement en m\u00e9moire si n\u00e9cessaire. Cette op\u00e9ration peut prendre plus ou moins de temps, notamment en fonction de la vitesse du disque et le d\u00e9bit disponible sur le bus (SATA, PCI-Express). La RAM est disponible pour le grand public \u00e0 hauteur de plusieurs gigaoctets. Comme nous l'avons vu pr\u00e9c\u00e9demment, l'ex\u00e9cution du programme se d\u00e9roule \u00e0 l'int\u00e9rieur du processeur lequel est dot\u00e9 de registres . Avant de leur parvenir, le processeur va charger une partie du programme dans ses diff\u00e9rents niveaux de cache pour s'alimenter plus rapidement en instructions et en donn\u00e9es \u00e0 traiter. Il met r\u00e9guli\u00e8rement \u00e0 jour son cache depuis ou vers la m\u00e9moire vive pour poursuivre l'ex\u00e9cution du programme. Plus la quantit\u00e9 de cache est grande, moins les aller-retours seront fr\u00e9quents et donc plus le processeur pourra travailler efficacement. Suivant le mod\u00e8le du processeur et le niveau du cache, la quantit\u00e9 de m\u00e9moire pourra aller de plusieurs m\u00e9gaoctets (cache L3) \u00e0 quelques centaines de kilooctets (cache L1). Le registres ferment la marche en ne faisant que quelques octets. Chargement depuis un p\u00e9riph\u00e9rique de stockage Pour un syst\u00e8me multit\u00e2che, attendre que des donn\u00e9es se chargent depuis un p\u00e9riph\u00e9rique (disque dur, CD, cl\u00e9 USB, etc) vers la m\u00e9moire principale monopolise inutilement le microprocesseur. Il existe donc, pour certains bus de donn\u00e9es largement utilis\u00e9s de nos jours, des chargements de donn\u00e9es n'impliquant pas directement le processeur. Celui-ci va seulement initier et terminer le transfert des donn\u00e9es et c'est un contr\u00f4leur annexe qui va s'occuper de faire transf\u00e9rer les donn\u00e9es depuis le p\u00e9riph\u00e9rique. Pendant ce temps, le CPU peut s'adonner \u00e0 d'autres t\u00e2ches comme ex\u00e9cuter un ou plusieurs autres processus. Il en va exactement de m\u00eame pour \u00e9crire les donn\u00e9es vers l'un de ces p\u00e9riph\u00e9riques. Les d\u00e9tails \u00e0 ce sujet sortent totalement de la port\u00e9e des tutoriels \u00e0 venir donc ils ne seront pas davantage expliqu\u00e9s ici. Cependant, un exemple de contr\u00f4leur qui assiste le microprocesseur nous pouvons \u00e9voquer l' acc\u00e8s direct \u00e0 la m\u00e9moire , ou DMA pour Direct Memory Access en anglais. Adressage m\u00e9moire La m\u00e9moire principale de l'ordinateur peut-\u00eatre vue comme une immense rue dans une ville o\u00f9 une case-m\u00e9moire serait une maison. Chaque case-m\u00e9moire peut accueillir une unique valeur de 8 bits, ce qu'on appelle un octet . Un ordinateur gamer moyen poss\u00e8de g\u00e9n\u00e9ralement 16 gigaoctets de RAM en 2022, soit 16 milliards d'octets. Comme dans une ville, chaque maison a une adresse unique. Dans la m\u00e9moire, c'est pareil car une case-m\u00e9moire poss\u00e8de sa propre adresse. Ici, l' adresse m\u00e9moire est un nombre, qui s'incr\u00e9mente pour chaque case-m\u00e9moire successive. On a donc une case-m\u00e9moire \u00e0 l'adresse 0, puis 1, ensuite 2, et ainsi de suite jusqu'\u00e0 la derni\u00e8re. De nos jours, le CPU de nos ordinateurs personnels n'acc\u00e8de plus directement \u00e0 la m\u00e9moire vive par les adresses physiques , c'est-\u00e0-dire le v\u00e9ritable num\u00e9ro de l'adresse dans la m\u00e9moire. En effet, pour \u00e9viter qu'un processus \u00e9crive ou acc\u00e8de \u00e0 la zone de la m\u00e9moire utilis\u00e9e par un autre processus, un composant vient s'intercaler entre le microprocesseur et la RAM. Ce composant est l' unit\u00e9 de gestion de la m\u00e9moire , abr\u00e9g\u00e9 en anglais par MMU pour memory management unit . La MMU est int\u00e9gr\u00e9e au CPU bien qu'initialement dans un circuit int\u00e9gr\u00e9 d\u00e9di\u00e9. Le processeur ne manipule alors plus des adresses physiques lorsqu'il ex\u00e9cute un processus mais des adresses virtuelles . Un des r\u00f4les de la MMU est de traduire les adresses virtuelles en adresses physiques pour r\u00e9cup\u00e9rer ou stocker des donn\u00e9es dans la RAM. Par le biais de la MMU, le syst\u00e8me d'exploitation peut effectuer plusieurs choses int\u00e9ressantes : Tout d'abord, il peut prot\u00e9ger l'acc\u00e8s et l'\u00e9criture de donn\u00e9es dans des r\u00e9gions de la m\u00e9moire vive qui sont occup\u00e9es par d'autres processus. Cela \u00e9vite de pouvoir r\u00e9cup\u00e9rer les donn\u00e9es d'un autre processus ou de corrompre/injecter des donn\u00e9es dans l'ex\u00e9cution d'un autre processus. Par exemple si un programme vient \u00e0 consommer toute la m\u00e9moire vive du syst\u00e8me ; Comme pour un disque dur, la m\u00e9moire vive peut \u00eatre fragment\u00e9e. Gr\u00e2ce \u00e0 la MMU, le processeur n'a pas \u00e0 se pr\u00e9occuper de cette fragmentation et agit comme la m\u00e9moire \u00e9tait contigu\u00eb ; D'un point de vue d'un processus (et du processeur), la m\u00e9moire vive est illimit\u00e9e gr\u00e2ce \u00e0 la m\u00e9moire virtuelle. Comment fonctionne un d\u00e9bogueur ? Un d\u00e9bogueur est un processus qui s'attache \u00e0 un autre processus. Il permet d'y d\u00e9tecter les erreurs et probl\u00e8mes durant son ex\u00e9cution et facilite ainsi la correction de bugs. Il a un acc\u00e8s total \u00e0 la m\u00e9moire du processus attach\u00e9 pour en inspecter les valeurs voire les modifier au cours de son ex\u00e9cution. Cela vient contredire ce qui a \u00e9t\u00e9 d\u00e9crit pr\u00e9c\u00e9demment quant \u00e0 la protection de la m\u00e9moire des processus \u00e0 l'aide de la MMU ! Il ne faut pas oublier que c'est le syst\u00e8me d'exploitation qui dicte le fonctionnement de la MMU. Or, un d\u00e9bogueur utilise une interface de programmation (API) fournie par le syst\u00e8me d'exploitation pour fonctionner.","title":"La m\u00e9moire"},{"location":"bases/hardware/memory/#la-memoire","text":"Il existe plusieurs types de m\u00e9moire dans un ordinateur. Nous allons suivre le cheminement d'un programme du moment o\u00f9 on double-clique dessus jusqu'\u00e0 son ex\u00e9cution par le processeur. Tout d'abord, le programme est contenu sur une m\u00e9moire qui est permanente y compris quand l'ordinateur est \u00e9teint. Il peut s'agir d'un disque dur magn\u00e9tique ou de m\u00e9moire flash comme dans un SSD, une cl\u00e9 USB ou une puce de m\u00e9moire flash \u00e0 l'int\u00e9rieur d'un smartphone. Un disque dur magn\u00e9tique ou de la m\u00e9moire flash est ce qu'on appelle de la m\u00e9moire de masse . Elle est abondante dans un ordinateur, actuellement plus t\u00e9raoctets, et relativement peu ch\u00e8re en comparaison des autres types de m\u00e9moires. Plus la m\u00e9moire est rapide et, g\u00e9n\u00e9ralement, plus elle est ch\u00e8re et donc moins abondante. Lorsqu'on souhaite ex\u00e9cuter un programme, il est charg\u00e9 tout ou partie depuis son emplacement sur la m\u00e9moire de masse vers la m\u00e9moire vive (RAM). Le programme va, au fur et \u00e0 mesure de son ex\u00e9cution, avoir besoin de donn\u00e9es encore pr\u00e9sentes sur le disque et devra donc demander leur chargement en m\u00e9moire si n\u00e9cessaire. Cette op\u00e9ration peut prendre plus ou moins de temps, notamment en fonction de la vitesse du disque et le d\u00e9bit disponible sur le bus (SATA, PCI-Express). La RAM est disponible pour le grand public \u00e0 hauteur de plusieurs gigaoctets. Comme nous l'avons vu pr\u00e9c\u00e9demment, l'ex\u00e9cution du programme se d\u00e9roule \u00e0 l'int\u00e9rieur du processeur lequel est dot\u00e9 de registres . Avant de leur parvenir, le processeur va charger une partie du programme dans ses diff\u00e9rents niveaux de cache pour s'alimenter plus rapidement en instructions et en donn\u00e9es \u00e0 traiter. Il met r\u00e9guli\u00e8rement \u00e0 jour son cache depuis ou vers la m\u00e9moire vive pour poursuivre l'ex\u00e9cution du programme. Plus la quantit\u00e9 de cache est grande, moins les aller-retours seront fr\u00e9quents et donc plus le processeur pourra travailler efficacement. Suivant le mod\u00e8le du processeur et le niveau du cache, la quantit\u00e9 de m\u00e9moire pourra aller de plusieurs m\u00e9gaoctets (cache L3) \u00e0 quelques centaines de kilooctets (cache L1). Le registres ferment la marche en ne faisant que quelques octets.","title":"La m\u00e9moire"},{"location":"bases/hardware/memory/#chargement-depuis-un-peripherique-de-stockage","text":"Pour un syst\u00e8me multit\u00e2che, attendre que des donn\u00e9es se chargent depuis un p\u00e9riph\u00e9rique (disque dur, CD, cl\u00e9 USB, etc) vers la m\u00e9moire principale monopolise inutilement le microprocesseur. Il existe donc, pour certains bus de donn\u00e9es largement utilis\u00e9s de nos jours, des chargements de donn\u00e9es n'impliquant pas directement le processeur. Celui-ci va seulement initier et terminer le transfert des donn\u00e9es et c'est un contr\u00f4leur annexe qui va s'occuper de faire transf\u00e9rer les donn\u00e9es depuis le p\u00e9riph\u00e9rique. Pendant ce temps, le CPU peut s'adonner \u00e0 d'autres t\u00e2ches comme ex\u00e9cuter un ou plusieurs autres processus. Il en va exactement de m\u00eame pour \u00e9crire les donn\u00e9es vers l'un de ces p\u00e9riph\u00e9riques. Les d\u00e9tails \u00e0 ce sujet sortent totalement de la port\u00e9e des tutoriels \u00e0 venir donc ils ne seront pas davantage expliqu\u00e9s ici. Cependant, un exemple de contr\u00f4leur qui assiste le microprocesseur nous pouvons \u00e9voquer l' acc\u00e8s direct \u00e0 la m\u00e9moire , ou DMA pour Direct Memory Access en anglais.","title":"Chargement depuis un p\u00e9riph\u00e9rique de stockage"},{"location":"bases/hardware/memory/#adressage-memoire","text":"La m\u00e9moire principale de l'ordinateur peut-\u00eatre vue comme une immense rue dans une ville o\u00f9 une case-m\u00e9moire serait une maison. Chaque case-m\u00e9moire peut accueillir une unique valeur de 8 bits, ce qu'on appelle un octet . Un ordinateur gamer moyen poss\u00e8de g\u00e9n\u00e9ralement 16 gigaoctets de RAM en 2022, soit 16 milliards d'octets. Comme dans une ville, chaque maison a une adresse unique. Dans la m\u00e9moire, c'est pareil car une case-m\u00e9moire poss\u00e8de sa propre adresse. Ici, l' adresse m\u00e9moire est un nombre, qui s'incr\u00e9mente pour chaque case-m\u00e9moire successive. On a donc une case-m\u00e9moire \u00e0 l'adresse 0, puis 1, ensuite 2, et ainsi de suite jusqu'\u00e0 la derni\u00e8re. De nos jours, le CPU de nos ordinateurs personnels n'acc\u00e8de plus directement \u00e0 la m\u00e9moire vive par les adresses physiques , c'est-\u00e0-dire le v\u00e9ritable num\u00e9ro de l'adresse dans la m\u00e9moire. En effet, pour \u00e9viter qu'un processus \u00e9crive ou acc\u00e8de \u00e0 la zone de la m\u00e9moire utilis\u00e9e par un autre processus, un composant vient s'intercaler entre le microprocesseur et la RAM. Ce composant est l' unit\u00e9 de gestion de la m\u00e9moire , abr\u00e9g\u00e9 en anglais par MMU pour memory management unit . La MMU est int\u00e9gr\u00e9e au CPU bien qu'initialement dans un circuit int\u00e9gr\u00e9 d\u00e9di\u00e9. Le processeur ne manipule alors plus des adresses physiques lorsqu'il ex\u00e9cute un processus mais des adresses virtuelles . Un des r\u00f4les de la MMU est de traduire les adresses virtuelles en adresses physiques pour r\u00e9cup\u00e9rer ou stocker des donn\u00e9es dans la RAM. Par le biais de la MMU, le syst\u00e8me d'exploitation peut effectuer plusieurs choses int\u00e9ressantes : Tout d'abord, il peut prot\u00e9ger l'acc\u00e8s et l'\u00e9criture de donn\u00e9es dans des r\u00e9gions de la m\u00e9moire vive qui sont occup\u00e9es par d'autres processus. Cela \u00e9vite de pouvoir r\u00e9cup\u00e9rer les donn\u00e9es d'un autre processus ou de corrompre/injecter des donn\u00e9es dans l'ex\u00e9cution d'un autre processus. Par exemple si un programme vient \u00e0 consommer toute la m\u00e9moire vive du syst\u00e8me ; Comme pour un disque dur, la m\u00e9moire vive peut \u00eatre fragment\u00e9e. Gr\u00e2ce \u00e0 la MMU, le processeur n'a pas \u00e0 se pr\u00e9occuper de cette fragmentation et agit comme la m\u00e9moire \u00e9tait contigu\u00eb ; D'un point de vue d'un processus (et du processeur), la m\u00e9moire vive est illimit\u00e9e gr\u00e2ce \u00e0 la m\u00e9moire virtuelle. Comment fonctionne un d\u00e9bogueur ? Un d\u00e9bogueur est un processus qui s'attache \u00e0 un autre processus. Il permet d'y d\u00e9tecter les erreurs et probl\u00e8mes durant son ex\u00e9cution et facilite ainsi la correction de bugs. Il a un acc\u00e8s total \u00e0 la m\u00e9moire du processus attach\u00e9 pour en inspecter les valeurs voire les modifier au cours de son ex\u00e9cution. Cela vient contredire ce qui a \u00e9t\u00e9 d\u00e9crit pr\u00e9c\u00e9demment quant \u00e0 la protection de la m\u00e9moire des processus \u00e0 l'aide de la MMU ! Il ne faut pas oublier que c'est le syst\u00e8me d'exploitation qui dicte le fonctionnement de la MMU. Or, un d\u00e9bogueur utilise une interface de programmation (API) fournie par le syst\u00e8me d'exploitation pour fonctionner.","title":"Adressage m\u00e9moire"},{"location":"bases/instructions/conditions/","text":"Les conditions Apr\u00e8s avoir d\u00e9finit les donn\u00e9es et les op\u00e9rations disponibles sur elles, il est temps de savoir ce que l'on peut en faire de fa\u00e7on plus avanc\u00e9e. En particulier, les valeurs et les op\u00e9rateurs bool\u00e9ens vont \u00eatre tr\u00e8s utiles pour ex\u00e9cuter des portions de code dans un cas mais pas dans un autre. On parle de condition ou de branchement . Imaginons un programme qui sert \u00e0 faire des divisions. Il demande le dividende \u00e0 l'utilisateur puis le diviseur. Une propri\u00e9t\u00e9 de la division est qu'il est impossible de diviser par z\u00e9ro . Dans le cadre d'un programme, sans contr\u00f4le justement, la division par z\u00e9ro conduit au mieux \u00e0 une erreur, au pire au plantage du programme selon le langage utilis\u00e9 pour le d\u00e9velopper. Pour \u00e9viter cette situation nous voudrions indiquer \u00e0 l'utilisateur que la division par z\u00e9ro est impossible et ne pas effectuer la division par z\u00e9ro. Nous pourrions avoir ce type de programmation. demander dividende demander diviseur si diviseur == 0, alors : \u00e9crire \"Attention, la division par z\u00e9ro est impossible !\" sinon : \u00e9crire \"Le r\u00e9sultat de la division est \" (dividende / diviseur) \".\" Remarque Il s'agit d'un programme \u00e9crit en pseudocode . Le pseudocode permet d'\u00e9crire un bout de programme sans avoir \u00e0 conna\u00eetre un langage de programmation particulier. On peut l'utiliser pour commencer \u00e0 d\u00e9velopper un programme avant m\u00eame de le faire sur un ordinateur, pour analyser un algorithme, etc. Le pseudocode peut servir \u00e9galement pour tout autre chose que l'informatique ! Comme nous le voyons avec ce bout de code, nous avons introduit deux mots importants : si et sinon . Cela va donc cr\u00e9er une bifurcation dans le code, ce ne seront pas les m\u00eames instructions qui seront ex\u00e9cut\u00e9es si le diviseur vaut z\u00e9ro ou pas. Dans d'autres situations, nous pourrions avoir besoin d'un troisi\u00e8me type de branchement, le sinon si . Prenons un autre exemple o\u00f9 nous devons r\u00e9aliser un g\u00e2teau. Nous voulons mettre du sucre ou une alternative selon ce que nous avons sous la main - ou arr\u00eater de pr\u00e9parer la recette si nous n'en avons aucune ! poss\u00e8de_sucre = faux poss\u00e8de_sirop_agave = faux poss\u00e8de_stevia = vrai si poss\u00e8de_sucre, alors : utiliser sucre sinon si poss\u00e8de_sirop_agave, alors : utiliser sirop_agave sinon si poss\u00e8de_stevia, alors : utiliser stevia sinon : arr\u00eater Avec les conditions, nous avons \u00e9galement la possibilit\u00e9 d'utiliser les op\u00e9rateurs bool\u00e9ens. vie_personnage = 100 magie_personnage = 100 si vie_personnage == 100 && magie_personnage == 100, alors : afficher \"Bravo, vous \u00eates une v\u00e9ritable l\u00e9gende !!!\" sinon si vie_personnage > 50 || magie_personnage > 50, alors : afficher \"C'est une belle performance !\" sinon si vie_personnage > 1, alors : afficher \"Ce n'\u00e9tait pas exceptionnel.\" sinon : afficher \"L'histoire retiendra peut-\u00eatre votre nom...\"","title":"Les conditions"},{"location":"bases/instructions/conditions/#les-conditions","text":"Apr\u00e8s avoir d\u00e9finit les donn\u00e9es et les op\u00e9rations disponibles sur elles, il est temps de savoir ce que l'on peut en faire de fa\u00e7on plus avanc\u00e9e. En particulier, les valeurs et les op\u00e9rateurs bool\u00e9ens vont \u00eatre tr\u00e8s utiles pour ex\u00e9cuter des portions de code dans un cas mais pas dans un autre. On parle de condition ou de branchement . Imaginons un programme qui sert \u00e0 faire des divisions. Il demande le dividende \u00e0 l'utilisateur puis le diviseur. Une propri\u00e9t\u00e9 de la division est qu'il est impossible de diviser par z\u00e9ro . Dans le cadre d'un programme, sans contr\u00f4le justement, la division par z\u00e9ro conduit au mieux \u00e0 une erreur, au pire au plantage du programme selon le langage utilis\u00e9 pour le d\u00e9velopper. Pour \u00e9viter cette situation nous voudrions indiquer \u00e0 l'utilisateur que la division par z\u00e9ro est impossible et ne pas effectuer la division par z\u00e9ro. Nous pourrions avoir ce type de programmation. demander dividende demander diviseur si diviseur == 0, alors : \u00e9crire \"Attention, la division par z\u00e9ro est impossible !\" sinon : \u00e9crire \"Le r\u00e9sultat de la division est \" (dividende / diviseur) \".\" Remarque Il s'agit d'un programme \u00e9crit en pseudocode . Le pseudocode permet d'\u00e9crire un bout de programme sans avoir \u00e0 conna\u00eetre un langage de programmation particulier. On peut l'utiliser pour commencer \u00e0 d\u00e9velopper un programme avant m\u00eame de le faire sur un ordinateur, pour analyser un algorithme, etc. Le pseudocode peut servir \u00e9galement pour tout autre chose que l'informatique ! Comme nous le voyons avec ce bout de code, nous avons introduit deux mots importants : si et sinon . Cela va donc cr\u00e9er une bifurcation dans le code, ce ne seront pas les m\u00eames instructions qui seront ex\u00e9cut\u00e9es si le diviseur vaut z\u00e9ro ou pas. Dans d'autres situations, nous pourrions avoir besoin d'un troisi\u00e8me type de branchement, le sinon si . Prenons un autre exemple o\u00f9 nous devons r\u00e9aliser un g\u00e2teau. Nous voulons mettre du sucre ou une alternative selon ce que nous avons sous la main - ou arr\u00eater de pr\u00e9parer la recette si nous n'en avons aucune ! poss\u00e8de_sucre = faux poss\u00e8de_sirop_agave = faux poss\u00e8de_stevia = vrai si poss\u00e8de_sucre, alors : utiliser sucre sinon si poss\u00e8de_sirop_agave, alors : utiliser sirop_agave sinon si poss\u00e8de_stevia, alors : utiliser stevia sinon : arr\u00eater Avec les conditions, nous avons \u00e9galement la possibilit\u00e9 d'utiliser les op\u00e9rateurs bool\u00e9ens. vie_personnage = 100 magie_personnage = 100 si vie_personnage == 100 && magie_personnage == 100, alors : afficher \"Bravo, vous \u00eates une v\u00e9ritable l\u00e9gende !!!\" sinon si vie_personnage > 50 || magie_personnage > 50, alors : afficher \"C'est une belle performance !\" sinon si vie_personnage > 1, alors : afficher \"Ce n'\u00e9tait pas exceptionnel.\" sinon : afficher \"L'histoire retiendra peut-\u00eatre votre nom...\"","title":"Les conditions"},{"location":"bases/instructions/loops/","text":"Les boucles Nous venons de voir comment ex\u00e9cuter diff\u00e9rents parties du code d'un programme suivant des conditions . Si le d\u00e9roulement d'un programme d\u00e9pendra des conditions satisfaites ou non, une chose reste s\u00fbre : le programme va se terminer. Dans le cas o\u00f9 nous voudrions r\u00e9p\u00e9ter plusieurs fois l'ex\u00e9cution du programme, par exemple un jeu, il nous faudrait relancer autant de fois le programme. Cela est non seulement p\u00e9nible mais en plus interdit tout comptage de points, car les donn\u00e9es d'un programme sont perdues quand il s'arr\u00eate. Heureusement, il existe un moyen de r\u00e9p\u00e9ter des portions de code dans un programme afin de les lui faire faire ex\u00e9cuter plusieurs fois : les boucles . Une boucle peut se r\u00e9p\u00e9ter un nombre pr\u00e9d\u00e9fini de fois. On rentre une valeur constante en guise de nombre de r\u00e9p\u00e9titions. Elle peut se r\u00e9p\u00e9ter ind\u00e9finiment. Dans le cas d'un jeu, ni l'ordinateur ni le joueur ne savent \u00e0 l'avance combien de parties seront jou\u00e9es. Elle peut aussi se r\u00e9p\u00e9ter un nombre de fois d\u00e9termin\u00e9 mais avec un nombre variable. En reprenant un exemple de recette de cuisine, nous ne casserons pas autant d'oeufs, un \u00e0 un, pour un g\u00e2teau suivant que nous le pr\u00e9parions pour 2, 4 ou 6 personnes. Il nous faudra plus ou moins d'oeufs selon le nombre de parts. Il existe diff\u00e9rents type de boucles. Elles s'utilisent de fa\u00e7on similaire et nous choisirons la plus pratique \u00e0 \u00e9crire suivant la situation. En g\u00e9n\u00e9ral, quand nous avons un nombre - constant ou variable - de r\u00e9p\u00e9titions \u00e0 effectuer, nous utilisons une boucle de type pour une valeur de tant \u00e0 tant . Pour se traduisant par for en anglais, nous parlerons de boucle for . Quand nous voulons arr\u00eater une boucle quand une condition devient fausse, nous utilisons la boucle tant que , qui se traduit par while en anglais. Une alternative \u00e0 la boucle while est la boucle do ... while dont l'utilisation est plus rare. while d\u00e9bute en v\u00e9rifiant si la condition est vraie. Elle ne lance donc le premier tour de boucle que si cette condition est v\u00e9rifi\u00e9e, sinon tout son code n'est pas ex\u00e9cut\u00e9 du tout. do ... while ne v\u00e9rifie la condition qu'\u00e0 la fin de l'ex\u00e9cution du code qu'elle contient. Elle nous assure donc d'ex\u00e9cuter au moins une fois ce bout de code. Boucles infinies L'utilisation de boucle est sujette aux boucles infinies. Cela arrive quand la condition pour laquelle la boucle doit s'arr\u00eater ne peut jamais valoir FAUX. Il y a diff\u00e9rentes situations possibles comme oublier de modifier la valeur de condition d'une boucle while ou attendre une valeur n\u00e9gative d'un nombre entier non sign\u00e9.","title":"Les boucles"},{"location":"bases/instructions/loops/#les-boucles","text":"Nous venons de voir comment ex\u00e9cuter diff\u00e9rents parties du code d'un programme suivant des conditions . Si le d\u00e9roulement d'un programme d\u00e9pendra des conditions satisfaites ou non, une chose reste s\u00fbre : le programme va se terminer. Dans le cas o\u00f9 nous voudrions r\u00e9p\u00e9ter plusieurs fois l'ex\u00e9cution du programme, par exemple un jeu, il nous faudrait relancer autant de fois le programme. Cela est non seulement p\u00e9nible mais en plus interdit tout comptage de points, car les donn\u00e9es d'un programme sont perdues quand il s'arr\u00eate. Heureusement, il existe un moyen de r\u00e9p\u00e9ter des portions de code dans un programme afin de les lui faire faire ex\u00e9cuter plusieurs fois : les boucles . Une boucle peut se r\u00e9p\u00e9ter un nombre pr\u00e9d\u00e9fini de fois. On rentre une valeur constante en guise de nombre de r\u00e9p\u00e9titions. Elle peut se r\u00e9p\u00e9ter ind\u00e9finiment. Dans le cas d'un jeu, ni l'ordinateur ni le joueur ne savent \u00e0 l'avance combien de parties seront jou\u00e9es. Elle peut aussi se r\u00e9p\u00e9ter un nombre de fois d\u00e9termin\u00e9 mais avec un nombre variable. En reprenant un exemple de recette de cuisine, nous ne casserons pas autant d'oeufs, un \u00e0 un, pour un g\u00e2teau suivant que nous le pr\u00e9parions pour 2, 4 ou 6 personnes. Il nous faudra plus ou moins d'oeufs selon le nombre de parts. Il existe diff\u00e9rents type de boucles. Elles s'utilisent de fa\u00e7on similaire et nous choisirons la plus pratique \u00e0 \u00e9crire suivant la situation. En g\u00e9n\u00e9ral, quand nous avons un nombre - constant ou variable - de r\u00e9p\u00e9titions \u00e0 effectuer, nous utilisons une boucle de type pour une valeur de tant \u00e0 tant . Pour se traduisant par for en anglais, nous parlerons de boucle for . Quand nous voulons arr\u00eater une boucle quand une condition devient fausse, nous utilisons la boucle tant que , qui se traduit par while en anglais. Une alternative \u00e0 la boucle while est la boucle do ... while dont l'utilisation est plus rare. while d\u00e9bute en v\u00e9rifiant si la condition est vraie. Elle ne lance donc le premier tour de boucle que si cette condition est v\u00e9rifi\u00e9e, sinon tout son code n'est pas ex\u00e9cut\u00e9 du tout. do ... while ne v\u00e9rifie la condition qu'\u00e0 la fin de l'ex\u00e9cution du code qu'elle contient. Elle nous assure donc d'ex\u00e9cuter au moins une fois ce bout de code. Boucles infinies L'utilisation de boucle est sujette aux boucles infinies. Cela arrive quand la condition pour laquelle la boucle doit s'arr\u00eater ne peut jamais valoir FAUX. Il y a diff\u00e9rentes situations possibles comme oublier de modifier la valeur de condition d'une boucle while ou attendre une valeur n\u00e9gative d'un nombre entier non sign\u00e9.","title":"Les boucles"},{"location":"bases/instructions/operators/logic/","text":"Les op\u00e9rations logiques Nous avons vu pour les bool\u00e9ens la possibilit\u00e9 de faire de l'alg\u00e8bre bool\u00e9enne. Elle fait, elle aussi, intervenir plusieurs op\u00e9rateurs . Nous pouvons par ailleurs s\u00e9parer ces op\u00e9rateurs en deux cat\u00e9gories : les op\u00e9rateurs logiques et les op\u00e9rateurs bit-\u00e0-bit. Les op\u00e9rateurs logiques Nous les avons d\u00e9j\u00e0 vu dans la section sur les bool\u00e9ens. Les revoici avec les symboles utilis\u00e9s dans les langages de programmation pour les repr\u00e9senter : ET ( && ou plus rarement and ) ; OU ( || ou plus rarement or ) ; NON ( ! ou plus rarement not ) ; OU EXCLUSIF ( ^ ou plus rarement xor ). Ces op\u00e9rateurs s'effectuent sur deux valeurs bool\u00e9ennes et donnent VRAI ou FAUX . On peut en r\u00e9cup\u00e9rer ce r\u00e9sultat avec l'op\u00e9rateur d'affectation = comme nous l'avons vu auparavant pour les op\u00e9rations math\u00e9matiques. Les op\u00e9rateurs bit-\u00e0-bit Les op\u00e9rateurs bit-\u00e0-bit s'effectuent sur des valeurs qui ne sont pas forc\u00e9ment bool\u00e9ennes , comme les nombres. Ils doivent leur nom au fait qu'il s'effectuent bit par bit, un peu comme si chaque bit composant une valeur binaire \u00e9tait un bool\u00e9en. Ils sont tr\u00e8s proches en terme de repr\u00e9sentation dans le code mais leur effet est tr\u00e8s diff\u00e9rent. Cela peut \u00eatre la source de nombreuses erreurs de programmation, attention ! ET bit-\u00e0-bit ( & ) ; OU bit-\u00e0-bit ( | ) ; OU EXCLUSIF ( ^ ) ; inversion de bit ( ~ ). On va voir ce que font ces op\u00e9rateurs par l'exemple. Prenons deux valeurs, a = 1100 et b = 0110 . ET bit-\u00e0-bit On applique la r\u00e8gle de l'op\u00e9rateur ET sur les deux bits en position 0, sur les bits en position 1, etc. P.bit indique la position des bits dans l'exemple ci-dessous. P.bit = 3 2 1 0 a = 1 1 0 0 b = 0 1 1 0 _______________ a & b = 0 1 0 0 OU bit-\u00e0-bit On applique la r\u00e8gle de l'op\u00e9rateur OU sur les deux bits en position 0, sur les bits en position 1, etc. P.bit indique la position des bits dans l'exemple ci-dessous. P.bit = 3 2 1 0 a = 1 1 0 0 b = 0 1 1 0 _______________ a | b = 1 1 1 0 OU EXCLUSIF (bit-\u00e0-bit) On applique la r\u00e8gle de l'op\u00e9rateur OU EXCLUSIF sur les deux bits en position 0, sur les bits en position 1, etc. P.bit indique la position des bits dans l'exemple ci-dessous. P.bit = 3 2 1 0 a = 1 1 0 0 b = 0 1 1 0 _______________ a ^ b = 1 0 1 0 Inversion de bit L'inversion de bit inverse la valeur de tous les bits : les 0 deviennent des 1 et les 1 deviennent des 0. P.bit = 3 2 1 0 a = 1 1 0 0 _______________ ~a = 0 0 1 1","title":"Les op\u00e9rations logiques"},{"location":"bases/instructions/operators/logic/#les-operations-logiques","text":"Nous avons vu pour les bool\u00e9ens la possibilit\u00e9 de faire de l'alg\u00e8bre bool\u00e9enne. Elle fait, elle aussi, intervenir plusieurs op\u00e9rateurs . Nous pouvons par ailleurs s\u00e9parer ces op\u00e9rateurs en deux cat\u00e9gories : les op\u00e9rateurs logiques et les op\u00e9rateurs bit-\u00e0-bit.","title":"Les op\u00e9rations logiques"},{"location":"bases/instructions/operators/logic/#les-operateurs-logiques","text":"Nous les avons d\u00e9j\u00e0 vu dans la section sur les bool\u00e9ens. Les revoici avec les symboles utilis\u00e9s dans les langages de programmation pour les repr\u00e9senter : ET ( && ou plus rarement and ) ; OU ( || ou plus rarement or ) ; NON ( ! ou plus rarement not ) ; OU EXCLUSIF ( ^ ou plus rarement xor ). Ces op\u00e9rateurs s'effectuent sur deux valeurs bool\u00e9ennes et donnent VRAI ou FAUX . On peut en r\u00e9cup\u00e9rer ce r\u00e9sultat avec l'op\u00e9rateur d'affectation = comme nous l'avons vu auparavant pour les op\u00e9rations math\u00e9matiques.","title":"Les op\u00e9rateurs logiques"},{"location":"bases/instructions/operators/logic/#les-operateurs-bit-a-bit","text":"Les op\u00e9rateurs bit-\u00e0-bit s'effectuent sur des valeurs qui ne sont pas forc\u00e9ment bool\u00e9ennes , comme les nombres. Ils doivent leur nom au fait qu'il s'effectuent bit par bit, un peu comme si chaque bit composant une valeur binaire \u00e9tait un bool\u00e9en. Ils sont tr\u00e8s proches en terme de repr\u00e9sentation dans le code mais leur effet est tr\u00e8s diff\u00e9rent. Cela peut \u00eatre la source de nombreuses erreurs de programmation, attention ! ET bit-\u00e0-bit ( & ) ; OU bit-\u00e0-bit ( | ) ; OU EXCLUSIF ( ^ ) ; inversion de bit ( ~ ). On va voir ce que font ces op\u00e9rateurs par l'exemple. Prenons deux valeurs, a = 1100 et b = 0110 . ET bit-\u00e0-bit On applique la r\u00e8gle de l'op\u00e9rateur ET sur les deux bits en position 0, sur les bits en position 1, etc. P.bit indique la position des bits dans l'exemple ci-dessous. P.bit = 3 2 1 0 a = 1 1 0 0 b = 0 1 1 0 _______________ a & b = 0 1 0 0 OU bit-\u00e0-bit On applique la r\u00e8gle de l'op\u00e9rateur OU sur les deux bits en position 0, sur les bits en position 1, etc. P.bit indique la position des bits dans l'exemple ci-dessous. P.bit = 3 2 1 0 a = 1 1 0 0 b = 0 1 1 0 _______________ a | b = 1 1 1 0 OU EXCLUSIF (bit-\u00e0-bit) On applique la r\u00e8gle de l'op\u00e9rateur OU EXCLUSIF sur les deux bits en position 0, sur les bits en position 1, etc. P.bit indique la position des bits dans l'exemple ci-dessous. P.bit = 3 2 1 0 a = 1 1 0 0 b = 0 1 1 0 _______________ a ^ b = 1 0 1 0 Inversion de bit L'inversion de bit inverse la valeur de tous les bits : les 0 deviennent des 1 et les 1 deviennent des 0. P.bit = 3 2 1 0 a = 1 1 0 0 _______________ ~a = 0 0 1 1","title":"Les op\u00e9rateurs bit-\u00e0-bit"},{"location":"bases/instructions/operators/maths/","text":"Les op\u00e9rations math\u00e9matiques Comme nous venons de le voir, un ordinateur est apte \u00e0 utiliser des nombres. Avec ces nombres, nous pouvons r\u00e9aliser des calculs math\u00e9matiques. Les op\u00e9rations de base sont directement cabl\u00e9es dans les processeurs. On parle alors d' impl\u00e9mentation mat\u00e9rielle , ce qui offre les meilleures performances possible et donc qui permet \u00e0 ces op\u00e9rations d'\u00eatre r\u00e9alis\u00e9es tr\u00e8s rapidement. Les voici avec le symbole, qu'on appelle op\u00e9rateur , g\u00e9n\u00e9ralement utilis\u00e9 pour les repr\u00e9senter dans du code : l' addition ( + ) ; la soustraction ( - ) ; la multiplication ( * ) ; la division ( / ) donnant le quotient ; le modulo ( % ) repr\u00e9sentant le reste d'une division enti\u00e8re. Si on a besoin de stocker une valeur, on pourra compter sur l'op\u00e9rateur d' affectation ( = ) qui permet de donner une valeur \u00e0 une variable. Exemple de division et de modulo Pour mieux comprendre le modulo, prenons l'exemple de la division 216 \u00f7 7 , o\u00f9 le dividence est 216 et le diviseur est 7 . Posons-la et faisons le calcul \u00e0 la main : Le r\u00e9sultat que nous obtenons est un quotient valant 30 et un reste valant 6 . En faisant le calcul avec des nombres entiers dans un programme informatique, la division 216/7 nous donnera donc 30 . L'op\u00e9ration 216%7 nous fournira le reste, c'est-\u00e0-dire 6 . Toutes les autres op\u00e9rations plus complexes devront \u00eatre cod\u00e9es \u00e0 partir de ces op\u00e9rations-ci. On parlera donc d' impl\u00e9mentation logicielle . Bien que plus flexible car on peut facilement modifier le code source d'un programme, l'impl\u00e9mentation logicielle est \u00e9galement plus lente. Les performances d'une telle impl\u00e9mentation d\u00e9pendra essentiellement de la complexit\u00e9 avec laquelle elle est mise en oeuvre. Par exemple, pour calculer une valeur v au carr\u00e9, on fera la multiplication v * v . Cela reste tr\u00e8s rapide ! Pour calculer une racine carr\u00e9, il existe diff\u00e9rentes fa\u00e7ons de proc\u00e9der mais toutes se baseront sur ces op\u00e9rations basiques et le calcul fera intervenir beaucoup plus d'\u00e9tapes que pour celui du carr\u00e9. La racine carr\u00e9 est donc plus lente \u00e0 calculer que le carr\u00e9. Il faut cependant relativiser avec la rapidit\u00e9 de nos processeurs modernes ! On peut donc dire que pour faire un calcul complexe, un ordinateur le d\u00e9composera en une multitude d'op\u00e9rations simples qu'il sera \u00e0 m\u00eame de r\u00e9aliser mat\u00e9riellement.","title":"Les op\u00e9rations math\u00e9matiques"},{"location":"bases/instructions/operators/maths/#les-operations-mathematiques","text":"Comme nous venons de le voir, un ordinateur est apte \u00e0 utiliser des nombres. Avec ces nombres, nous pouvons r\u00e9aliser des calculs math\u00e9matiques. Les op\u00e9rations de base sont directement cabl\u00e9es dans les processeurs. On parle alors d' impl\u00e9mentation mat\u00e9rielle , ce qui offre les meilleures performances possible et donc qui permet \u00e0 ces op\u00e9rations d'\u00eatre r\u00e9alis\u00e9es tr\u00e8s rapidement. Les voici avec le symbole, qu'on appelle op\u00e9rateur , g\u00e9n\u00e9ralement utilis\u00e9 pour les repr\u00e9senter dans du code : l' addition ( + ) ; la soustraction ( - ) ; la multiplication ( * ) ; la division ( / ) donnant le quotient ; le modulo ( % ) repr\u00e9sentant le reste d'une division enti\u00e8re. Si on a besoin de stocker une valeur, on pourra compter sur l'op\u00e9rateur d' affectation ( = ) qui permet de donner une valeur \u00e0 une variable. Exemple de division et de modulo Pour mieux comprendre le modulo, prenons l'exemple de la division 216 \u00f7 7 , o\u00f9 le dividence est 216 et le diviseur est 7 . Posons-la et faisons le calcul \u00e0 la main : Le r\u00e9sultat que nous obtenons est un quotient valant 30 et un reste valant 6 . En faisant le calcul avec des nombres entiers dans un programme informatique, la division 216/7 nous donnera donc 30 . L'op\u00e9ration 216%7 nous fournira le reste, c'est-\u00e0-dire 6 . Toutes les autres op\u00e9rations plus complexes devront \u00eatre cod\u00e9es \u00e0 partir de ces op\u00e9rations-ci. On parlera donc d' impl\u00e9mentation logicielle . Bien que plus flexible car on peut facilement modifier le code source d'un programme, l'impl\u00e9mentation logicielle est \u00e9galement plus lente. Les performances d'une telle impl\u00e9mentation d\u00e9pendra essentiellement de la complexit\u00e9 avec laquelle elle est mise en oeuvre. Par exemple, pour calculer une valeur v au carr\u00e9, on fera la multiplication v * v . Cela reste tr\u00e8s rapide ! Pour calculer une racine carr\u00e9, il existe diff\u00e9rentes fa\u00e7ons de proc\u00e9der mais toutes se baseront sur ces op\u00e9rations basiques et le calcul fera intervenir beaucoup plus d'\u00e9tapes que pour celui du carr\u00e9. La racine carr\u00e9 est donc plus lente \u00e0 calculer que le carr\u00e9. Il faut cependant relativiser avec la rapidit\u00e9 de nos processeurs modernes ! On peut donc dire que pour faire un calcul complexe, un ordinateur le d\u00e9composera en une multitude d'op\u00e9rations simples qu'il sera \u00e0 m\u00eame de r\u00e9aliser mat\u00e9riellement.","title":"Les op\u00e9rations math\u00e9matiques"},{"location":"bases/instructions/operators/shift/","text":"Les d\u00e9calages de bits Les op\u00e9rateurs de d\u00e9calage de bits servent, comme le nom l'indique, \u00e0 d\u00e9caler les bits d'une valeur. Il y en a deux, l'un pour un d\u00e9calage vers la gauche, l'autre pour un d\u00e9calage vers la droite. Tous deux prennent aussi le nombre de positions qui sont d\u00e9cal\u00e9es. Leur fonctionnement respectif est l\u00e9g\u00e8rement diff\u00e9rent. D\u00e9calage \u00e0 gauche Les bits sont d\u00e9cal\u00e9s vers la gauche, c'est-\u00e0-dire vers le bit de poids fort. Dans le cas suivant 0010'1111 << 2 = 1011'1100 , le d\u00e9calage nous fait passer de la valeur 47 \u00e0 188 (en base 10). D'un point de vue math\u00e9matique, on peut calculer ce d\u00e9calage de bits en posant 47 \u00d7 2 2 = 47 \u00d7 4 = 188. Pour g\u00e9n\u00e9raliser, on notera qu'un d\u00e9calage de bits \u00e0 gauche se calcule avec la formule a \u00d7 2 b , o\u00f9 a est la valeur initiale et b le nombre de bits d\u00e9cal\u00e9s \u00e0 gauche. Etant donn\u00e9 qu'une valeur cod\u00e9e sur un ordinateur a une taille limit\u00e9e en nombre de bits, si un bit d\u00e9passe le bit de poids fort, sa valeur est perdue . Les bits de poids faible sont quant \u00e0 eux mis \u00e0 z\u00e9ro . Par exemple, on obtiendrait ceci pour un d\u00e9calage \u00e0 gauche o\u00f9 les quatre bits de poids fort sont perdus apr\u00e8s le d\u00e9calage : 0010'1111 << 4 = 1111'0000 . Nous avons perdu les 4 bits de poids fort initiaux 0010 . Il va sans dire que dans cette situation, la formule pour calculer math\u00e9matiquement le r\u00e9sultat d'un d\u00e9calage \u00e0 gauche ne s'applique plus ! D\u00e9calage \u00e0 droite Les bits sont d\u00e9cal\u00e9s \u00e0 droite, vers le bit de poids faible. Le comportement de ce d\u00e9calage d\u00e9pendra de l'aspect sign\u00e9 ou non sign\u00e9 de la valeur. Valeur non sign\u00e9e Si la valeur sur laquelle on effectue le d\u00e9calage n'est pas sign\u00e9e, donc toujours positive ou nulle, les bits de poids fort sont mis \u00e0 z\u00e9ro . Le comportement est semblable \u00e0 celui que nous avons vu juste avant. Pour l'exemple 1101'1100 >> 2 = 0011'0111 , on passe de la valeur 220 \u00e0 55 (en base 10). Cela revient math\u00e9matiquement \u00e0 calculer 220 \u00f7 2 2 = 55. Pour g\u00e9n\u00e9raliser la formule, nous calculons a \u00f7 2 b , o\u00f9 a est la valeur initiale et b le nombre de bits d\u00e9cal\u00e9s \u00e0 droite. Ici aussi, cette formule ne s'applique que si les bits d\u00e9passent pas le bit de poids faible . Valeur sign\u00e9e Dans le cas o\u00f9 la valeur sur laquelle nous effectuons le d\u00e9calage \u00e0 droite est sign\u00e9e, la valeur des bits de poids fort ajout\u00e9s d\u00e9pendra du signe de la valeur. Si la valeur est positive, nous pla\u00e7ons toujours des z\u00e9ros. Par exemple 0101'1100 >> 2 = 0001'0111 . En revanche, si la valeur est n\u00e9gative, les bits de poids fort sont mis \u00e0 un. Dans ce nouvel exemple, 1101'0100 >> 2 = 1111'0101 , les deux bits de poids fort introduits valent tous les deux 1 . En base 10, on obtiendrait selon la formule -44 \u00f7 2 2 = -11. Il se trouve que c'est justement bien le cas en binaire aussi ! Remarque Un moyen simple de se souvenir du fonctionnement du d\u00e9calage \u00e0 droite, sur une valeur sign\u00e9e, c'est que le d\u00e9calage applique le bit de signe aux bits de poids fort ins\u00e9r\u00e9s. Pour r\u00e9sumer : la formule a \u00f7 2 b s'applique pour le d\u00e9calage \u00e0 droite dans toutes les situations rencontr\u00e9es (tant qu'il n'y a pas d\u00e9passement du bit de poids faible). Quelle utilit\u00e9 \u00e0 d\u00e9caler les bits ? Nous avons vu comment fonctionne le d\u00e9calage de bits. Cependant, il serait int\u00e9ressant de savoir \u00e0 quoi \u00e7a peut nous servir. Les op\u00e9rateurs logiques bit-\u00e0-bit combin\u00e9s aux op\u00e9rateurs de d\u00e9calage de bits sont tr\u00e8s puissants. Comme nous l'avons vu plus t\u00f4t, l'ordinateur n'est pas capable d'obtenir une valeur bool\u00e9enne qui serait stock\u00e9e sur un unique bit. La \"faute\" \u00e0 la fa\u00e7on dont la m\u00e9moire est organis\u00e9e, en octet, et donc comment le processeur peut aller y chercher des infos gr\u00e2ce \u00e0 l'adresse de l'octet en question. Si nous voulions stocker par exemple 5 bool\u00e9ens, nous aurions besoin de 8 octets soit 40 bits. Cela peut sembler inutile vis-\u00e0-vis de nos ordinateurs dot\u00e9s de plusieurs gigaoctets de m\u00e9moire, mais certains syst\u00e8mes informatiques ont une quantit\u00e9 extr\u00eamement limit\u00e9e de m\u00e9moire et ce type de gain est tr\u00e8s recherch\u00e9. Un autre aspect \u00e0 consid\u00e9rer pour ce type de stockage compress\u00e9, c'est le r\u00e9seau . Quand on envoie des donn\u00e9es sur le r\u00e9seau, elles mettent plus ou moins de temps \u00e0 arriver \u00e0 l'ordinateur distant suivant la taille qu'elles occupent. S'il y a un moyen de les compresser, nous aurons une communication plus rapide entre les deux machines. Qu'il s'agisse du jeu vid\u00e9o, en millisecondes, ou de transactions bancaires, en nanosecondes, chaque \u00e9conomie d'octet compte. Parmi les autres utilisations du d\u00e9calage de bits (et des op\u00e9rateurs bit-\u00e0-bit en g\u00e9n\u00e9ral), nous pouvons citer l'une des plus connues mais aussi \u00e9tonnante : le calcul de la racine carr\u00e9 inverse rapide x -1/2 , dont on sait qu'elle a \u00e9t\u00e9 utilis\u00e9e dans le jeu vid\u00e9o Quake III Arena .","title":"Les d\u00e9calages de bits"},{"location":"bases/instructions/operators/shift/#les-decalages-de-bits","text":"Les op\u00e9rateurs de d\u00e9calage de bits servent, comme le nom l'indique, \u00e0 d\u00e9caler les bits d'une valeur. Il y en a deux, l'un pour un d\u00e9calage vers la gauche, l'autre pour un d\u00e9calage vers la droite. Tous deux prennent aussi le nombre de positions qui sont d\u00e9cal\u00e9es. Leur fonctionnement respectif est l\u00e9g\u00e8rement diff\u00e9rent.","title":"Les d\u00e9calages de bits"},{"location":"bases/instructions/operators/shift/#decalage-a-gauche","text":"Les bits sont d\u00e9cal\u00e9s vers la gauche, c'est-\u00e0-dire vers le bit de poids fort. Dans le cas suivant 0010'1111 << 2 = 1011'1100 , le d\u00e9calage nous fait passer de la valeur 47 \u00e0 188 (en base 10). D'un point de vue math\u00e9matique, on peut calculer ce d\u00e9calage de bits en posant 47 \u00d7 2 2 = 47 \u00d7 4 = 188. Pour g\u00e9n\u00e9raliser, on notera qu'un d\u00e9calage de bits \u00e0 gauche se calcule avec la formule a \u00d7 2 b , o\u00f9 a est la valeur initiale et b le nombre de bits d\u00e9cal\u00e9s \u00e0 gauche. Etant donn\u00e9 qu'une valeur cod\u00e9e sur un ordinateur a une taille limit\u00e9e en nombre de bits, si un bit d\u00e9passe le bit de poids fort, sa valeur est perdue . Les bits de poids faible sont quant \u00e0 eux mis \u00e0 z\u00e9ro . Par exemple, on obtiendrait ceci pour un d\u00e9calage \u00e0 gauche o\u00f9 les quatre bits de poids fort sont perdus apr\u00e8s le d\u00e9calage : 0010'1111 << 4 = 1111'0000 . Nous avons perdu les 4 bits de poids fort initiaux 0010 . Il va sans dire que dans cette situation, la formule pour calculer math\u00e9matiquement le r\u00e9sultat d'un d\u00e9calage \u00e0 gauche ne s'applique plus !","title":"D\u00e9calage \u00e0 gauche"},{"location":"bases/instructions/operators/shift/#decalage-a-droite","text":"Les bits sont d\u00e9cal\u00e9s \u00e0 droite, vers le bit de poids faible. Le comportement de ce d\u00e9calage d\u00e9pendra de l'aspect sign\u00e9 ou non sign\u00e9 de la valeur.","title":"D\u00e9calage \u00e0 droite"},{"location":"bases/instructions/operators/shift/#valeur-non-signee","text":"Si la valeur sur laquelle on effectue le d\u00e9calage n'est pas sign\u00e9e, donc toujours positive ou nulle, les bits de poids fort sont mis \u00e0 z\u00e9ro . Le comportement est semblable \u00e0 celui que nous avons vu juste avant. Pour l'exemple 1101'1100 >> 2 = 0011'0111 , on passe de la valeur 220 \u00e0 55 (en base 10). Cela revient math\u00e9matiquement \u00e0 calculer 220 \u00f7 2 2 = 55. Pour g\u00e9n\u00e9raliser la formule, nous calculons a \u00f7 2 b , o\u00f9 a est la valeur initiale et b le nombre de bits d\u00e9cal\u00e9s \u00e0 droite. Ici aussi, cette formule ne s'applique que si les bits d\u00e9passent pas le bit de poids faible .","title":"Valeur non sign\u00e9e"},{"location":"bases/instructions/operators/shift/#valeur-signee","text":"Dans le cas o\u00f9 la valeur sur laquelle nous effectuons le d\u00e9calage \u00e0 droite est sign\u00e9e, la valeur des bits de poids fort ajout\u00e9s d\u00e9pendra du signe de la valeur. Si la valeur est positive, nous pla\u00e7ons toujours des z\u00e9ros. Par exemple 0101'1100 >> 2 = 0001'0111 . En revanche, si la valeur est n\u00e9gative, les bits de poids fort sont mis \u00e0 un. Dans ce nouvel exemple, 1101'0100 >> 2 = 1111'0101 , les deux bits de poids fort introduits valent tous les deux 1 . En base 10, on obtiendrait selon la formule -44 \u00f7 2 2 = -11. Il se trouve que c'est justement bien le cas en binaire aussi ! Remarque Un moyen simple de se souvenir du fonctionnement du d\u00e9calage \u00e0 droite, sur une valeur sign\u00e9e, c'est que le d\u00e9calage applique le bit de signe aux bits de poids fort ins\u00e9r\u00e9s. Pour r\u00e9sumer : la formule a \u00f7 2 b s'applique pour le d\u00e9calage \u00e0 droite dans toutes les situations rencontr\u00e9es (tant qu'il n'y a pas d\u00e9passement du bit de poids faible).","title":"Valeur sign\u00e9e"},{"location":"bases/instructions/operators/shift/#quelle-utilite-a-decaler-les-bits","text":"Nous avons vu comment fonctionne le d\u00e9calage de bits. Cependant, il serait int\u00e9ressant de savoir \u00e0 quoi \u00e7a peut nous servir. Les op\u00e9rateurs logiques bit-\u00e0-bit combin\u00e9s aux op\u00e9rateurs de d\u00e9calage de bits sont tr\u00e8s puissants. Comme nous l'avons vu plus t\u00f4t, l'ordinateur n'est pas capable d'obtenir une valeur bool\u00e9enne qui serait stock\u00e9e sur un unique bit. La \"faute\" \u00e0 la fa\u00e7on dont la m\u00e9moire est organis\u00e9e, en octet, et donc comment le processeur peut aller y chercher des infos gr\u00e2ce \u00e0 l'adresse de l'octet en question. Si nous voulions stocker par exemple 5 bool\u00e9ens, nous aurions besoin de 8 octets soit 40 bits. Cela peut sembler inutile vis-\u00e0-vis de nos ordinateurs dot\u00e9s de plusieurs gigaoctets de m\u00e9moire, mais certains syst\u00e8mes informatiques ont une quantit\u00e9 extr\u00eamement limit\u00e9e de m\u00e9moire et ce type de gain est tr\u00e8s recherch\u00e9. Un autre aspect \u00e0 consid\u00e9rer pour ce type de stockage compress\u00e9, c'est le r\u00e9seau . Quand on envoie des donn\u00e9es sur le r\u00e9seau, elles mettent plus ou moins de temps \u00e0 arriver \u00e0 l'ordinateur distant suivant la taille qu'elles occupent. S'il y a un moyen de les compresser, nous aurons une communication plus rapide entre les deux machines. Qu'il s'agisse du jeu vid\u00e9o, en millisecondes, ou de transactions bancaires, en nanosecondes, chaque \u00e9conomie d'octet compte. Parmi les autres utilisations du d\u00e9calage de bits (et des op\u00e9rateurs bit-\u00e0-bit en g\u00e9n\u00e9ral), nous pouvons citer l'une des plus connues mais aussi \u00e9tonnante : le calcul de la racine carr\u00e9 inverse rapide x -1/2 , dont on sait qu'elle a \u00e9t\u00e9 utilis\u00e9e dans le jeu vid\u00e9o Quake III Arena .","title":"Quelle utilit\u00e9 \u00e0 d\u00e9caler les bits ?"},{"location":"bases/instructions/operators/test/","text":"Les comparaisons Les comparaisons sont des op\u00e9rations beaucoup plus simples comprendre car on les utilise dans notre quotidien. Plusieurs op\u00e9rateurs sont l\u00e0 pour nous permettre de les r\u00e9aliser : strictement inf\u00e9rieur \u00e0 ( < ) et strictement sup\u00e9rieur \u00e0 ( > ) ; inf\u00e9rieur ou \u00e9gal \u00e0 ( <= ) et sup\u00e9rieur ou \u00e9gal \u00e0 ( >= ) ; est \u00e9gal \u00e0 ( == ) et est diff\u00e9rent de ( != ). Les op\u00e9rateurs de comparaison renvoient une valeur bool\u00e9enne .","title":"Les comparaisons"},{"location":"bases/instructions/operators/test/#les-comparaisons","text":"Les comparaisons sont des op\u00e9rations beaucoup plus simples comprendre car on les utilise dans notre quotidien. Plusieurs op\u00e9rateurs sont l\u00e0 pour nous permettre de les r\u00e9aliser : strictement inf\u00e9rieur \u00e0 ( < ) et strictement sup\u00e9rieur \u00e0 ( > ) ; inf\u00e9rieur ou \u00e9gal \u00e0 ( <= ) et sup\u00e9rieur ou \u00e9gal \u00e0 ( >= ) ; est \u00e9gal \u00e0 ( == ) et est diff\u00e9rent de ( != ). Les op\u00e9rateurs de comparaison renvoient une valeur bool\u00e9enne .","title":"Les comparaisons"}]}